{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOKBV2uWZ9U_"
      },
      "source": [
        "# 2023 COMP 4446 / 5046 Assignment 1\n",
        "\n",
        "Assingment 1 is an **individual** assessment. Please note the University's [Academic dishonesty and plagiarism policy](https://www.sydney.edu.au/students/academic-dishonesty.html).\n",
        "\n",
        "Submission Deadline: Friday, March 17th, 2023, 11:59pm\n",
        "\n",
        "Submit via Canvas:\n",
        "- Your notebook\n",
        "- Run all cells before saving the notebook, so we can see your output\n",
        "\n",
        "In this assignment, we will explore ways to predict the length of a Wikipedia article based on the first 100 tokens in the article. Such a model could be used to explore whether there are systematic biases in the types of articles that get more detail.\n",
        "\n",
        "If you are working in another language, please make sure to clearly indicate which part of your code is running which section of the assignment and produce output that provides all necessary information. Submit your code, example outputs, and instructions for executing it.\n",
        "\n",
        "Note: This assignment contains topics that are not covered at the time of release. Each section has information about which lectures and/or labs covered the relevant material. We are releasing it now so you can (1) start working on some parts early, and (2) know what will be in the assignment when you attend the relevant labs and lectures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FA3m7neId4ow"
      },
      "source": [
        "# **TODO: Copy and Name this File**\n",
        "Make a copy of this notebook in your own Google Drive (File -> Save a Copy in Drive) and change the filename, replacing `YOUR-UNIKEY`. For example, for a person with unikey `mcol1997`, the filename should be:\n",
        "\n",
        "`COMP-4446-5046_Assignment1_mcol1997.ipynb`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qut4Xg5mbYXe"
      },
      "source": [
        "# Readme\n",
        "*If there is something you want to tell the marker about your submission, please mention it here.* "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaX3ihzU7uDL"
      },
      "source": [
        "\n",
        "          \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ib68RAoatjk"
      },
      "source": [
        "# Data Download [DO NOT MODIFY THIS]\n",
        "\n",
        "We have already constructed a dataset for you using a recent dump of data from Wikipedia. Both the training and test datasets are provided in the form of csv files (training_data.csv, test_data.csv) and can be downloaded from Google Drive using the code below. Each row of the data contains:\n",
        "\n",
        "- The length of the article\n",
        "- The title of the article\n",
        "- The first 100 tokens of the article\n",
        "\n",
        "In case you are curious, we constructed this dataset as follows:\n",
        "1. Downloaded [a recent dump](https://dumps.wikimedia.org/) of English wikipedia.\n",
        "2. Ran [WikiExtractor](https://github.com/attardi/wikiextractor) to get the contents of the pages.\n",
        "3. Filtered out very short pages.\n",
        "4. Ran [SpaCy](https://spacy.io/) with the `en_core_web_lg` model to tokenise the pages (Note, SpaCy's development is led by an alumnus of USyd!).\n",
        "5. Counted the tokens and saved the relevant data in the format described above.\n",
        "\n",
        "This code will download the data. **DO NOT MODIFY IT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94u_ipMMZ6Cu",
        "outputId": "5f8fd8ea-3272-44ea-c932-986a14f574a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------\n",
            "Size of training data: 9859\n",
            "Size of development data: 994\n",
            "Size of test data: 991\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "Sample Data\n",
            "LABEL: 6453 / SENTENCE: ['Anarchism', 'Anarchism is a political philosophy and movement that is skeptical of all justifications for authority and seeks to abolish the institutions it claims maintain unnecessary coercion and hierarchy , typically including , though not necessarily limited to , governments , nation states , and capitalism . Anarchism advocates for the replacement of the state with stateless societies or other forms of free associations . As a historically left - wing movement , usually placed on the farthest left of the political spectrum , it is usually described alongside communalism and libertarian Marxism as the libertarian wing ( libertarian socialism )']\n",
            "------------------------------------\n",
            "6453\n",
            "Anarchism\n",
            "Anarchism is a political philosophy and movement that is skeptical of all justifications for authori...\n",
            "\n",
            "3528\n",
            "Albedo\n",
            "Albedo (; ) is the measure of the diffuse reflection of solar radiation out of the total solar radia...\n",
            "\n",
            "1265\n",
            "A\n",
            "A , or a , is the first letter and the first vowel of the Latin alphabet , used in the modern Englis...\n",
            "\n",
            "11591\n",
            "Alabama\n",
            "Alabama ( ) is a state in the Southeastern region of the United States , bordered by Tennessee to th...\n",
            "\n",
            "5865\n",
            "Achilles\n",
            "In Greek mythology , Achilles ( ) or Achilleus ( ) was a hero of the Trojan War , the greatest of al...\n",
            "\n",
            "13412\n",
            "Abraham Lincoln\n",
            "Abraham Lincoln ( ; February 12 , 1809   – April 15 , 1865 ) was an American lawyer , politician , a...\n",
            "\n",
            "9485\n",
            "Aristotle\n",
            "Aristotle (; \" Aristotélēs \" , ; 384–322   BC ) was a Greek philosopher and polymath during the Clas...\n",
            "\n",
            "1683\n",
            "An American in Paris\n",
            "An American in Paris is a jazz - influenced orchestral piece by American composer George Gershwin fi...\n",
            "\n",
            "149\n",
            "Academy Award for Best Production Design\n",
            "The Academy Award for Best Production Design recognizes achievement for art direction in film . The ...\n",
            "\n",
            "7178\n",
            "Academy Awards\n",
            "The Academy Awards , better known as the Oscars , are awards for artistic and technical merit for th...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## DO NOT MODIFY THIS CODE\n",
        "# Code to download files into Colaboratory\n",
        "\n",
        "# Install the PyDrive library\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "# Import libraries for accessing Google Drive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Function to read the file, save it on the machine this colab is running on, and then read it in\n",
        "import csv\n",
        "def read_file(file_id, filename):\n",
        "  downloaded = drive.CreateFile({'id':file_id})\n",
        "  downloaded.GetContentFile(filename)\n",
        "  with open(filename) as src:\n",
        "    reader = csv.reader(src)\n",
        "    data = [r for r in reader]\n",
        "  return data\n",
        "\n",
        "# Calls to get the data\n",
        "# If you need to access the data directly (e.g., you are running experiments on a local machine), use these links:\n",
        "# - Training, https://drive.google.com/file/d/1-UGFS8D-qglAX-czU38KaM4jQVCoNe0W/view?usp=share_link\n",
        "# - Dev, https://drive.google.com/file/d/1RWMEf0mdJMTkWc7dvN0ioks8bjujqZaN/view?usp=share_link\n",
        "# - Test, https://drive.google.com/file/d/1YVPNzdIFSMmVPeLBP-gf5DOIed3oRFyB/view?usp=share_link\n",
        "training_data = read_file('1-UGFS8D-qglAX-czU38KaM4jQVCoNe0W', \"/content/training_data.csv\")\n",
        "dev_data = read_file('1RWMEf0mdJMTkWc7dvN0ioks8bjujqZaN', \"/content/dev_data.csv\")\n",
        "test_data = read_file('1YVPNzdIFSMmVPeLBP-gf5DOIed3oRFyB', \"/content/test_data.csv\")\n",
        "\n",
        "print(\"------------------------------------\")\n",
        "print(\"Size of training data: {0}\".format(len(training_data)))\n",
        "print(\"Size of development data: {0}\".format(len(dev_data)))\n",
        "print(\"Size of test data: {0}\".format(len(test_data)))\n",
        "print(\"------------------------------------\")\n",
        "\n",
        "print(\"------------------------------------\")\n",
        "print(\"Sample Data\")\n",
        "print(\"LABEL: {0} / SENTENCE: {1}\".format(training_data[0][0], training_data[0][1:]))\n",
        "print(\"------------------------------------\")\n",
        "\n",
        "# Preview of the data in the csv file, which has three columns: \n",
        "# (1) length of article, (2) title of the article, (3) first 100 words in the article\n",
        "for v in training_data[:10]:\n",
        "  print(\"{}\\n{}\\n{}\\n\".format(v[0], v[1], v[2][:100] + \"...\"))\n",
        "\n",
        "# Store the data in lists and mofidy the length value to be in [0, 1]\n",
        "training_lengths = [min(1.0, int(r[0])/10000) for r in training_data]\n",
        "training_text = [r[2] for r in training_data]\n",
        "\n",
        "dev_lengths = [min(1.0, int(r[0])/10000) for r in dev_data]\n",
        "dev_text = [r[2] for r in dev_data]\n",
        "\n",
        "test_lengths = [min(1.0, int(r[0])/10000) for r in test_data]\n",
        "test_text = [r[2] for r in test_data]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwiKfKQtphIb"
      },
      "source": [
        "# 1 - Predicting article length from initial content\n",
        "\n",
        "This section relates to content from **the week 1 lecture and the week 2 lab**.\n",
        "\n",
        "In this section, you will implement training and evaluation of a linear model (as seen in the week 2 lab) to predict the length of a wikipedia article from its first 100 words. You will represent the text using a Bag of Words model (as seen in the week 1 lecture)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAGSol9qHIj5"
      },
      "source": [
        "## 1.1 Word Mapping [2pt]\n",
        "\n",
        "In the code block below, write code to go through the training data and for any word that occurs at least 10 times:\n",
        "- Assign it a unique ID (consecutive, starting at 0)\n",
        "- Place it in a dictionary that maps from the word to the ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6ifitbSj_QK",
        "outputId": "5e3fcb39-db36-43ae-e936-f98ec6ed76d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.1+cu116\n"
          ]
        }
      ],
      "source": [
        "# importing packages used in the assignment\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from collections import Counter\n",
        "import re\n",
        "import numpy\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords as sw\n",
        "import string\n",
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this function takes an input of a list of strings\n",
        "# returns text_tokenized: an array of words for each element in input\n",
        "# returns tokenized_set: an dictionary(word,occurence of word in string element) for each element in input\n",
        "def tokenization(data):\n",
        "  tokenized_set = []\n",
        "  text_tokenized = []\n",
        "  for x in data:\n",
        "    x_tokenized = [text.lower() for text in word_tokenize(x)]\n",
        "    text_tokenized.append(x_tokenized)\n",
        "    tokenized_set.append(dict(Counter(x_tokenized)))\n",
        "  return text_tokenized,tokenized_set"
      ],
      "metadata": {
        "id": "uK17aXDlSSmS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (dataset)_text_tokenized : each element of dataset stored as list of tokens\n",
        "# (dataset)_text_tokenized_set : each element of data stored as (word,occurences of word in element)\n",
        "training_text_tokenized, training_text_tokenized_set = tokenization(training_text)\n",
        "dev_text_tokenized, dev_text_tokenized_set = tokenization(dev_text)\n",
        "test_text_tokenized, test_text_tokenized_set = tokenization(test_text)\n",
        "\n",
        "####################################### Code for counting occurences of words in the training data set #######################################\n",
        "\n",
        "# training_text_tokenized is flattened so that it be used as a long list of word that will be treated as a vocabulary in this assignment \n",
        "training_text_tokenized_flat = [item for sublist in training_text_tokenized  for item in sublist]\n",
        "# Counter used to count the occurence of every unique token in above created vocabulary\n",
        "CounterDict = dict(Counter(training_text_tokenized_flat))\n",
        "\n",
        "\n",
        "####################################### Code for removing words occuring less than 10 times in the dataset #######################################\n",
        "\n",
        "# list comprehension to fiter and remove words that have occured less than 10 times in the training set\n",
        "CounterMap = {key:value for key, value in CounterDict.items() if value>10}\n",
        "\n",
        "\n",
        "####################################### Code for place words in a dictionary that maps from the word to its ID #######################################\n",
        "\n",
        "# list comprehension for assigning a index starting from 0 for each word in the vocabulary\n",
        "Vocabulary = {key:list(CounterMap.keys()).index(key) for key in CounterMap.keys()}\n",
        "Vocabulary"
      ],
      "metadata": {
        "id": "FKXWNVguTaKV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f575b5b-5a54-49a5-9c07-524383ff77bc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'anarchism': 0,\n",
              " 'is': 1,\n",
              " 'a': 2,\n",
              " 'political': 3,\n",
              " 'philosophy': 4,\n",
              " 'and': 5,\n",
              " 'movement': 6,\n",
              " 'that': 7,\n",
              " 'of': 8,\n",
              " 'all': 9,\n",
              " 'for': 10,\n",
              " 'authority': 11,\n",
              " 'seeks': 12,\n",
              " 'to': 13,\n",
              " 'the': 14,\n",
              " 'institutions': 15,\n",
              " 'it': 16,\n",
              " 'claims': 17,\n",
              " 'maintain': 18,\n",
              " 'hierarchy': 19,\n",
              " ',': 20,\n",
              " 'typically': 21,\n",
              " 'including': 22,\n",
              " 'though': 23,\n",
              " 'not': 24,\n",
              " 'necessarily': 25,\n",
              " 'limited': 26,\n",
              " 'governments': 27,\n",
              " 'nation': 28,\n",
              " 'states': 29,\n",
              " 'capitalism': 30,\n",
              " '.': 31,\n",
              " 'advocates': 32,\n",
              " 'replacement': 33,\n",
              " 'state': 34,\n",
              " 'with': 35,\n",
              " 'societies': 36,\n",
              " 'or': 37,\n",
              " 'other': 38,\n",
              " 'forms': 39,\n",
              " 'free': 40,\n",
              " 'associations': 41,\n",
              " 'as': 42,\n",
              " 'historically': 43,\n",
              " 'left': 44,\n",
              " '-': 45,\n",
              " 'wing': 46,\n",
              " 'usually': 47,\n",
              " 'placed': 48,\n",
              " 'on': 49,\n",
              " 'spectrum': 50,\n",
              " 'described': 51,\n",
              " 'alongside': 52,\n",
              " 'libertarian': 53,\n",
              " '(': 54,\n",
              " ')': 55,\n",
              " ';': 56,\n",
              " 'measure': 57,\n",
              " 'reflection': 58,\n",
              " 'solar': 59,\n",
              " 'radiation': 60,\n",
              " 'out': 61,\n",
              " 'total': 62,\n",
              " 'measured': 63,\n",
              " 'scale': 64,\n",
              " 'from': 65,\n",
              " '0': 66,\n",
              " 'corresponding': 67,\n",
              " 'black': 68,\n",
              " 'body': 69,\n",
              " 'incident': 70,\n",
              " '1': 71,\n",
              " 'reflects': 72,\n",
              " 'surface': 73,\n",
              " 'defined': 74,\n",
              " 'ratio': 75,\n",
              " '``': 76,\n",
              " 'j': 77,\n",
              " \"''\": 78,\n",
              " 'e': 79,\n",
              " 'per': 80,\n",
              " 'unit': 81,\n",
              " 'area': 82,\n",
              " 'received': 83,\n",
              " 'by': 84,\n",
              " 'proportion': 85,\n",
              " 'reflected': 86,\n",
              " 'only': 87,\n",
              " 'determined': 88,\n",
              " 'properties': 89,\n",
              " 'itself': 90,\n",
              " 'but': 91,\n",
              " 'also': 92,\n",
              " 'angular': 93,\n",
              " 'distribution': 94,\n",
              " 'first': 95,\n",
              " 'letter': 96,\n",
              " 'vowel': 97,\n",
              " 'latin': 98,\n",
              " 'alphabet': 99,\n",
              " 'used': 100,\n",
              " 'in': 101,\n",
              " 'modern': 102,\n",
              " 'english': 103,\n",
              " 'alphabets': 104,\n",
              " 'western': 105,\n",
              " 'european': 106,\n",
              " 'languages': 107,\n",
              " 'others': 108,\n",
              " 'worldwide': 109,\n",
              " 'its': 110,\n",
              " 'name': 111,\n",
              " 'pronounced': 112,\n",
              " 'plural': 113,\n",
              " 'similar': 114,\n",
              " 'shape': 115,\n",
              " 'ancient': 116,\n",
              " 'greek': 117,\n",
              " 'alpha': 118,\n",
              " 'which': 119,\n",
              " 'derives': 120,\n",
              " 'uppercase': 121,\n",
              " 'version': 122,\n",
              " 'consists': 123,\n",
              " 'two': 124,\n",
              " 'sides': 125,\n",
              " 'triangle': 126,\n",
              " 'middle': 127,\n",
              " 'horizontal': 128,\n",
              " 'bar': 129,\n",
              " 'lowercase': 130,\n",
              " 'can': 131,\n",
              " 'be': 132,\n",
              " 'written': 133,\n",
              " 'alabama': 134,\n",
              " 'southeastern': 135,\n",
              " 'region': 136,\n",
              " 'united': 137,\n",
              " 'bordered': 138,\n",
              " 'tennessee': 139,\n",
              " 'north': 140,\n",
              " 'georgia': 141,\n",
              " 'east': 142,\n",
              " 'florida': 143,\n",
              " 'gulf': 144,\n",
              " 'mexico': 145,\n",
              " 'south': 146,\n",
              " 'mississippi': 147,\n",
              " 'west': 148,\n",
              " 'largest': 149,\n",
              " 'most': 150,\n",
              " 'populous': 151,\n",
              " 'u.s.': 152,\n",
              " 'inland': 153,\n",
              " 'waterways': 154,\n",
              " 'has': 155,\n",
              " 'among': 156,\n",
              " 'any': 157,\n",
              " 'nicknamed': 158,\n",
              " 'after': 159,\n",
              " 'bird': 160,\n",
              " 'known': 161,\n",
              " 'heart': 162,\n",
              " 'mythology': 163,\n",
              " 'was': 164,\n",
              " 'hero': 165,\n",
              " 'trojan': 166,\n",
              " 'war': 167,\n",
              " 'greatest': 168,\n",
              " 'warriors': 169,\n",
              " 'central': 170,\n",
              " 'character': 171,\n",
              " 'homer': 172,\n",
              " \"'s\": 173,\n",
              " 'iliad': 174,\n",
              " 'he': 175,\n",
              " 'son': 176,\n",
              " 'king': 177,\n",
              " \"'\": 178,\n",
              " 'notable': 179,\n",
              " 'during': 180,\n",
              " 'prince': 181,\n",
              " 'outside': 182,\n",
              " 'gates': 183,\n",
              " 'troy': 184,\n",
              " 'although': 185,\n",
              " 'death': 186,\n",
              " 'presented': 187,\n",
              " 'sources': 188,\n",
              " 'killed': 189,\n",
              " 'near': 190,\n",
              " 'end': 191,\n",
              " 'abraham': 192,\n",
              " 'lincoln': 193,\n",
              " 'february': 194,\n",
              " '12': 195,\n",
              " '1809': 196,\n",
              " '–': 197,\n",
              " 'april': 198,\n",
              " '15': 199,\n",
              " '1865': 200,\n",
              " 'an': 201,\n",
              " 'american': 202,\n",
              " 'lawyer': 203,\n",
              " 'politician': 204,\n",
              " 'statesman': 205,\n",
              " 'who': 206,\n",
              " 'served': 207,\n",
              " '16th': 208,\n",
              " 'president': 209,\n",
              " '1861': 210,\n",
              " 'until': 211,\n",
              " 'his': 212,\n",
              " 'assassination': 213,\n",
              " 'led': 214,\n",
              " 'through': 215,\n",
              " 'civil': 216,\n",
              " 'succeeded': 217,\n",
              " 'preserving': 218,\n",
              " 'union': 219,\n",
              " 'slavery': 220,\n",
              " 'federal': 221,\n",
              " 'government': 222,\n",
              " 'economy': 223,\n",
              " 'born': 224,\n",
              " 'into': 225,\n",
              " 'poverty': 226,\n",
              " 'kentucky': 227,\n",
              " 'raised': 228,\n",
              " 'primarily': 229,\n",
              " 'indiana': 230,\n",
              " 'self': 231,\n",
              " 'educated': 232,\n",
              " 'aristotle': 233,\n",
              " 'bc': 234,\n",
              " 'philosopher': 235,\n",
              " 'polymath': 236,\n",
              " 'classical': 237,\n",
              " 'period': 238,\n",
              " 'greece': 239,\n",
              " 'taught': 240,\n",
              " 'plato': 241,\n",
              " 'founder': 242,\n",
              " 'school': 243,\n",
              " 'within': 244,\n",
              " 'wider': 245,\n",
              " 'tradition': 246,\n",
              " 'writings': 247,\n",
              " 'cover': 248,\n",
              " 'many': 249,\n",
              " 'subjects': 250,\n",
              " 'physics': 251,\n",
              " 'biology': 252,\n",
              " 'metaphysics': 253,\n",
              " 'logic': 254,\n",
              " 'ethics': 255,\n",
              " 'poetry': 256,\n",
              " 'theatre': 257,\n",
              " 'music': 258,\n",
              " 'psychology': 259,\n",
              " 'linguistics': 260,\n",
              " 'economics': 261,\n",
              " 'politics': 262,\n",
              " 'geology': 263,\n",
              " 'provided': 264,\n",
              " 'complex': 265,\n",
              " 'synthesis': 266,\n",
              " 'various': 267,\n",
              " 'paris': 268,\n",
              " 'jazz': 269,\n",
              " 'influenced': 270,\n",
              " 'piece': 271,\n",
              " 'composer': 272,\n",
              " 'george': 273,\n",
              " 'performed': 274,\n",
              " '1928': 275,\n",
              " 'inspired': 276,\n",
              " 'time': 277,\n",
              " 'had': 278,\n",
              " 'spent': 279,\n",
              " 'energy': 280,\n",
              " 'french': 281,\n",
              " 'capital': 282,\n",
              " 'standard': 283,\n",
              " 'instruments': 284,\n",
              " 'symphony': 285,\n",
              " 'orchestra': 286,\n",
              " 'plus': 287,\n",
              " 'automobile': 288,\n",
              " 'brought': 289,\n",
              " 'back': 290,\n",
              " 'four': 291,\n",
              " 'new': 292,\n",
              " 'york': 293,\n",
              " 'composition': 294,\n",
              " 'took': 295,\n",
              " 'place': 296,\n",
              " 'december': 297,\n",
              " '13': 298,\n",
              " 'hall': 299,\n",
              " 'walter': 300,\n",
              " 'academy': 301,\n",
              " 'award': 302,\n",
              " 'best': 303,\n",
              " 'production': 304,\n",
              " 'design': 305,\n",
              " 'achievement': 306,\n",
              " 'art': 307,\n",
              " 'direction': 308,\n",
              " 'film': 309,\n",
              " 'category': 310,\n",
              " 'original': 311,\n",
              " 'changed': 312,\n",
              " 'current': 313,\n",
              " '2012': 314,\n",
              " 'awards': 315,\n",
              " 'this': 316,\n",
              " 'change': 317,\n",
              " 'resulted': 318,\n",
              " 'directors': 319,\n",
              " 'branch': 320,\n",
              " 'motion': 321,\n",
              " 'picture': 322,\n",
              " 'arts': 323,\n",
              " 'sciences': 324,\n",
              " 'being': 325,\n",
              " 'renamed': 326,\n",
              " 'designers': 327,\n",
              " 'since': 328,\n",
              " '1947': 329,\n",
              " 'shared': 330,\n",
              " 'set': 331,\n",
              " 's': 332,\n",
              " 'awarded': 333,\n",
              " 'interior': 334,\n",
              " 'films': 335,\n",
              " 'below': 336,\n",
              " 'are': 337,\n",
              " 'listed': 338,\n",
              " 'their': 339,\n",
              " 'better': 340,\n",
              " 'artistic': 341,\n",
              " 'technical': 342,\n",
              " 'merit': 343,\n",
              " 'international': 344,\n",
              " 'industry': 345,\n",
              " 'regarded': 346,\n",
              " 'significant': 347,\n",
              " 'entertainment': 348,\n",
              " 'given': 349,\n",
              " 'annually': 350,\n",
              " 'recognition': 351,\n",
              " 'achievements': 352,\n",
              " 'voting': 353,\n",
              " 'membership': 354,\n",
              " 'winners': 355,\n",
              " 'copy': 356,\n",
              " 'golden': 357,\n",
              " 'officially': 358,\n",
              " 'called': 359,\n",
              " ':': 360,\n",
              " '1997': 361,\n",
              " 'language': 362,\n",
              " 'spanish': 363,\n",
              " 'drama': 364,\n",
              " 'produced': 365,\n",
              " 'directed': 366,\n",
              " 'based': 367,\n",
              " 'winning': 368,\n",
              " 'stage': 369,\n",
              " 'play': 370,\n",
              " 'maria': 371,\n",
              " 'i': 372,\n",
              " 'no': 373,\n",
              " 'male': 374,\n",
              " 'actors': 375,\n",
              " 'roles': 376,\n",
              " 'played': 377,\n",
              " '1996': 378,\n",
              " 'order': 379,\n",
              " 'role': 380,\n",
              " 'life': 381,\n",
              " 'legendary': 382,\n",
              " 'actress': 383,\n",
              " 'young': 384,\n",
              " 'three': 385,\n",
              " 'established': 386,\n",
              " 'been': 387,\n",
              " 'illustrated': 388,\n",
              " 'children': 389,\n",
              " 'book': 390,\n",
              " 'base': 391,\n",
              " 'originally': 392,\n",
              " 'published': 393,\n",
              " '1986': 394,\n",
              " 'followed': 395,\n",
              " 'tenth': 396,\n",
              " 'edition': 397,\n",
              " 'over': 398,\n",
              " 'million': 399,\n",
              " 'copies': 400,\n",
              " 'have': 401,\n",
              " 'sold': 402,\n",
              " 'special': 403,\n",
              " 'numbered': 404,\n",
              " 'signed': 405,\n",
              " 'gold': 406,\n",
              " 'contains': 407,\n",
              " 'twenty': 408,\n",
              " 'six': 409,\n",
              " 'illustrations': 410,\n",
              " 'one': 411,\n",
              " 'each': 412,\n",
              " 'features': 413,\n",
              " 'animal': 414,\n",
              " 'kingdom': 415,\n",
              " 'atomic': 416,\n",
              " 'abbreviated': 417,\n",
              " 'high': 418,\n",
              " 'precision': 419,\n",
              " 'coordinate': 420,\n",
              " 'passage': 421,\n",
              " 'proper': 422,\n",
              " 'earth': 423,\n",
              " 'average': 424,\n",
              " 'kept': 425,\n",
              " '80': 426,\n",
              " 'national': 427,\n",
              " 'continuous': 428,\n",
              " 'without': 429,\n",
              " 'leap': 430,\n",
              " 'seconds': 431,\n",
              " 'principal': 432,\n",
              " 'terrestrial': 433,\n",
              " 'fixed': 434,\n",
              " 'epoch': 435,\n",
              " 'basis': 436,\n",
              " 'universal': 437,\n",
              " 'principle': 438,\n",
              " 'moral': 439,\n",
              " 'practice': 440,\n",
              " 'concern': 441,\n",
              " 'and/or': 442,\n",
              " 'human': 443,\n",
              " 'beings': 444,\n",
              " 'animals': 445,\n",
              " 'resulting': 446,\n",
              " 'quality': 447,\n",
              " 'both': 448,\n",
              " 'material': 449,\n",
              " 'spiritual': 450,\n",
              " 'traditional': 451,\n",
              " 'virtue': 452,\n",
              " 'cultures': 453,\n",
              " 'core': 454,\n",
              " 'aspect': 455,\n",
              " 'religious': 456,\n",
              " 'secular': 457,\n",
              " 'however': 458,\n",
              " 'object': 459,\n",
              " 'vary': 460,\n",
              " 'religions': 461,\n",
              " 'extreme': 462,\n",
              " 'case': 463,\n",
              " 'may': 464,\n",
              " 'become': 465,\n",
              " 'synonym': 466,\n",
              " 'opposite': 467,\n",
              " 'word': 468,\n",
              " 'popularized': 469,\n",
              " 'possibly': 470,\n",
              " 'coined': 471,\n",
              " 'alice': 472,\n",
              " '1905': 473,\n",
              " 'march': 474,\n",
              " '6': 475,\n",
              " '1982': 476,\n",
              " 'her': 477,\n",
              " 'pen': 478,\n",
              " 'russian': 479,\n",
              " 'writer': 480,\n",
              " 'she': 481,\n",
              " 'fiction': 482,\n",
              " 'developing': 483,\n",
              " 'philosophical': 484,\n",
              " 'system': 485,\n",
              " 'named': 486,\n",
              " 'russia': 487,\n",
              " 'moved': 488,\n",
              " '1926': 489,\n",
              " 'early': 490,\n",
              " 'novels': 491,\n",
              " 'were': 492,\n",
              " 'initially': 493,\n",
              " 'broadway': 494,\n",
              " 'plays': 495,\n",
              " 'achieved': 496,\n",
              " 'fame': 497,\n",
              " '1943': 498,\n",
              " 'novel': 499,\n",
              " '1957': 500,\n",
              " 'mathematician': 501,\n",
              " 'theoretical': 502,\n",
              " 'physicist': 503,\n",
              " 'contributions': 504,\n",
              " 'study': 505,\n",
              " 'operator': 506,\n",
              " 'geometry': 507,\n",
              " 'professor': 508,\n",
              " 'at': 509,\n",
              " 'ohio': 510,\n",
              " 'university': 511,\n",
              " 'fields': 512,\n",
              " 'medal': 513,\n",
              " 'career': 514,\n",
              " 'source': 515,\n",
              " 'academic': 516,\n",
              " 'timeline': 517,\n",
              " 'bachelor': 518,\n",
              " 'degree': 519,\n",
              " 'now': 520,\n",
              " 'part': 521,\n",
              " 'et': 522,\n",
              " '1973': 523,\n",
              " 'pierre': 524,\n",
              " 'marie': 525,\n",
              " 'joseph': 526,\n",
              " '3': 527,\n",
              " '1885': 528,\n",
              " '28': 529,\n",
              " '1981': 530,\n",
              " 'pioneering': 531,\n",
              " 'canadian': 532,\n",
              " 'director': 533,\n",
              " 'producer': 534,\n",
              " 'screenwriter': 535,\n",
              " 'toronto': 536,\n",
              " 'ontario': 537,\n",
              " 'canada': 538,\n",
              " 'younger': 539,\n",
              " 'commercial': 540,\n",
              " 'clothing': 541,\n",
              " 'michael': 542,\n",
              " 'wife': 543,\n",
              " 'mary': 544,\n",
              " 'jane': 545,\n",
              " 'née': 546,\n",
              " 'hunt': 547,\n",
              " 'family': 548,\n",
              " 'when': 549,\n",
              " 'seven': 550,\n",
              " 'years': 551,\n",
              " 'old': 552,\n",
              " '4': 553,\n",
              " '1892': 554,\n",
              " 'ferry': 555,\n",
              " 'algeria': 556,\n",
              " 'people': 557,\n",
              " 'democratic': 558,\n",
              " 'republic': 559,\n",
              " 'country': 560,\n",
              " 'africa': 561,\n",
              " 'northeast': 562,\n",
              " 'libya': 563,\n",
              " 'southeast': 564,\n",
              " 'niger': 565,\n",
              " 'southwest': 566,\n",
              " 'mali': 567,\n",
              " 'mauritania': 568,\n",
              " 'sahara': 569,\n",
              " 'morocco': 570,\n",
              " 'mediterranean': 571,\n",
              " 'sea': 572,\n",
              " 'considered': 573,\n",
              " 'maghreb': 574,\n",
              " 'semi': 575,\n",
              " 'arid': 576,\n",
              " 'geography': 577,\n",
              " 'population': 578,\n",
              " 'living': 579,\n",
              " 'fertile': 580,\n",
              " 'list': 581,\n",
              " 'characters': 582,\n",
              " 'atlas': 583,\n",
              " 'major': 584,\n",
              " 'following': 585,\n",
              " 'protagonist': 586,\n",
              " 'vice': 587,\n",
              " 'charge': 588,\n",
              " 'operations': 589,\n",
              " 'under': 590,\n",
              " 'brother': 591,\n",
              " 'james': 592,\n",
              " 'responsible': 593,\n",
              " 'railroad': 594,\n",
              " 'francisco': 595,\n",
              " 'owner': 596,\n",
              " 'inheritance': 597,\n",
              " 'anthropology': 598,\n",
              " 'scientific': 599,\n",
              " 'humanity': 600,\n",
              " 'concerned': 601,\n",
              " 'behavior': 602,\n",
              " 'present': 603,\n",
              " 'past': 604,\n",
              " 'species': 605,\n",
              " 'social': 606,\n",
              " 'studies': 607,\n",
              " 'patterns': 608,\n",
              " 'while': 609,\n",
              " 'cultural': 610,\n",
              " 'meaning': 611,\n",
              " 'norms': 612,\n",
              " 'values': 613,\n",
              " 'portmanteau': 614,\n",
              " 'term': 615,\n",
              " 'commonly': 616,\n",
              " 'today': 617,\n",
              " 'linguistic': 618,\n",
              " 'how': 619,\n",
              " 'influences': 620,\n",
              " 'biological': 621,\n",
              " 'physical': 622,\n",
              " 'development': 623,\n",
              " 'humans': 624,\n",
              " 'archaeological': 625,\n",
              " 'often': 626,\n",
              " 'termed': 627,\n",
              " '“': 628,\n",
              " '”': 629,\n",
              " 'activity': 630,\n",
              " 'agricultural': 631,\n",
              " 'science': 632,\n",
              " 'short': 633,\n",
              " 'broad': 634,\n",
              " 'field': 635,\n",
              " 'encompasses': 636,\n",
              " 'parts': 637,\n",
              " 'exact': 638,\n",
              " 'natural': 639,\n",
              " 'economic': 640,\n",
              " 'understanding': 641,\n",
              " 'agriculture': 642,\n",
              " 'scientists': 643,\n",
              " 'history': 644,\n",
              " '18th': 645,\n",
              " 'century': 646,\n",
              " 'johann': 647,\n",
              " 'friedrich': 648,\n",
              " 'conducted': 649,\n",
              " 'experiments': 650,\n",
              " 'use': 651,\n",
              " 'calcium': 652,\n",
              " 'john': 653,\n",
              " 'henry': 654,\n",
              " 'gilbert': 655,\n",
              " 'began': 656,\n",
              " 'long': 657,\n",
              " 'research': 658,\n",
              " 'arabic': 659,\n",
              " 'al': 660,\n",
              " 'practiced': 661,\n",
              " 'china': 662,\n",
              " 'india': 663,\n",
              " 'muslim': 664,\n",
              " 'world': 665,\n",
              " 'europe': 666,\n",
              " 'form': 667,\n",
              " 'attested': 668,\n",
              " 'number': 669,\n",
              " 'texts': 670,\n",
              " 'greco': 671,\n",
              " 'roman': 672,\n",
              " 'egypt': 673,\n",
              " 'few': 674,\n",
              " 'centuries': 675,\n",
              " 'ad': 676,\n",
              " 'attempted': 677,\n",
              " 'mature': 678,\n",
              " 'perfect': 679,\n",
              " 'certain': 680,\n",
              " 'materials': 681,\n",
              " 'common': 682,\n",
              " 'aims': 683,\n",
              " 'astronomer': 684,\n",
              " 'scientist': 685,\n",
              " 'astronomy': 686,\n",
              " 'focuses': 687,\n",
              " 'specific': 688,\n",
              " 'question': 689,\n",
              " 'scope': 690,\n",
              " 'they': 691,\n",
              " 'astronomical': 692,\n",
              " 'objects': 693,\n",
              " 'such': 694,\n",
              " 'stars': 695,\n",
              " 'planets': 696,\n",
              " 'moons': 697,\n",
              " 'galaxies': 698,\n",
              " 'either': 699,\n",
              " 'data': 700,\n",
              " 'examples': 701,\n",
              " 'topics': 702,\n",
              " 'astronomers': 703,\n",
              " 'include': 704,\n",
              " 'planetary': 705,\n",
              " 'origin': 706,\n",
              " 'evolution': 707,\n",
              " 'formation': 708,\n",
              " 'related': 709,\n",
              " 'distinct': 710,\n",
              " 'subject': 711,\n",
              " 'cosmology': 712,\n",
              " 'universe': 713,\n",
              " 'whole': 714,\n",
              " 'types': 715,\n",
              " 'ascii': 716,\n",
              " 'code': 717,\n",
              " 'information': 718,\n",
              " 'encoding': 719,\n",
              " 'electronic': 720,\n",
              " 'communication': 721,\n",
              " 'codes': 722,\n",
              " 'represent': 723,\n",
              " 'text': 724,\n",
              " 'computers': 725,\n",
              " 'telecommunications': 726,\n",
              " 'equipment': 727,\n",
              " 'devices': 728,\n",
              " 'because': 729,\n",
              " 'computer': 730,\n",
              " 'systems': 731,\n",
              " 'invented': 732,\n",
              " 'just': 733,\n",
              " 'points': 734,\n",
              " '95': 735,\n",
              " 'instead': 736,\n",
              " 'millions': 737,\n",
              " 'these': 738,\n",
              " 'same': 739,\n",
              " 'internet': 740,\n",
              " 'animation': 741,\n",
              " 'method': 742,\n",
              " 'still': 743,\n",
              " 'figures': 744,\n",
              " 'appear': 745,\n",
              " 'moving': 746,\n",
              " 'images': 747,\n",
              " 'drawn': 748,\n",
              " 'painted': 749,\n",
              " 'hand': 750,\n",
              " 'transparent': 751,\n",
              " 'sheets': 752,\n",
              " 'made': 753,\n",
              " 'generated': 754,\n",
              " 'imagery': 755,\n",
              " 'very': 756,\n",
              " 'detailed': 757,\n",
              " '3d': 758,\n",
              " 'look': 759,\n",
              " 'reasons': 760,\n",
              " 'low': 761,\n",
              " 'bandwidth': 762,\n",
              " 'faster': 763,\n",
              " 'real': 764,\n",
              " 'methods': 765,\n",
              " 'apply': 766,\n",
              " 'apollo': 767,\n",
              " 'deities': 768,\n",
              " 'religion': 769,\n",
              " 'greeks': 770,\n",
              " 'recognized': 771,\n",
              " 'god': 772,\n",
              " 'dance': 773,\n",
              " 'truth': 774,\n",
              " 'healing': 775,\n",
              " 'diseases': 776,\n",
              " 'sun': 777,\n",
              " 'light': 778,\n",
              " 'more': 779,\n",
              " 'important': 780,\n",
              " 'gods': 781,\n",
              " 'zeus': 782,\n",
              " 'twin': 783,\n",
              " 'artemis': 784,\n",
              " 'goddess': 785,\n",
              " 'seen': 786,\n",
              " 'beautiful': 787,\n",
              " 'ideal': 788,\n",
              " '29': 789,\n",
              " '1970': 790,\n",
              " 'former': 791,\n",
              " 'player': 792,\n",
              " 'eight': 793,\n",
              " 'champion': 794,\n",
              " 'olympic': 795,\n",
              " 'well': 796,\n",
              " 'runner': 797,\n",
              " 'up': 798,\n",
              " 'second': 799,\n",
              " 'five': 800,\n",
              " 'men': 801,\n",
              " 'achieve': 802,\n",
              " 'grand': 803,\n",
              " 'open': 804,\n",
              " 'era': 805,\n",
              " 'fifth': 806,\n",
              " 'overall': 807,\n",
              " 'make': 808,\n",
              " 'large': 809,\n",
              " 'mainland': 810,\n",
              " 'asia': 811,\n",
              " 'scattered': 812,\n",
              " 'throughout': 813,\n",
              " 'thailand': 814,\n",
              " 'laos': 815,\n",
              " 'myanmar': 816,\n",
              " 'malaysia': 817,\n",
              " 'bangladesh': 818,\n",
              " 'nepal': 819,\n",
              " 'southern': 820,\n",
              " 'majority': 821,\n",
              " 'vietnam': 822,\n",
              " 'cambodia': 823,\n",
              " 'there': 824,\n",
              " 'around': 825,\n",
              " 'speakers': 826,\n",
              " 'vietnamese': 827,\n",
              " 'khmer': 828,\n",
              " 'recorded': 829,\n",
              " 'official': 830,\n",
              " 'status': 831,\n",
              " 'afro': 832,\n",
              " 'semitic': 833,\n",
              " 'sometimes': 834,\n",
              " 'about': 835,\n",
              " '300': 836,\n",
              " 'spoken': 837,\n",
              " 'predominantly': 838,\n",
              " 'geographic': 839,\n",
              " 'horn': 840,\n",
              " '/': 841,\n",
              " 'exception': 842,\n",
              " 'branches': 843,\n",
              " 'exclusively': 844,\n",
              " 'native': 845,\n",
              " 'african': 846,\n",
              " 'continent': 847,\n",
              " '500': 848,\n",
              " 'principality': 849,\n",
              " 'sovereign': 850,\n",
              " 'landlocked': 851,\n",
              " 'iberian': 852,\n",
              " 'peninsula': 853,\n",
              " 'eastern': 854,\n",
              " 'france': 855,\n",
              " 'spain': 856,\n",
              " 'believed': 857,\n",
              " 'created': 858,\n",
              " 'charlemagne': 859,\n",
              " 'ruled': 860,\n",
              " 'count': 861,\n",
              " 'transferred': 862,\n",
              " 'catholic': 863,\n",
              " 'diocese': 864,\n",
              " 'formed': 865,\n",
              " 'charter': 866,\n",
              " 'headed': 867,\n",
              " 'co': 868,\n",
              " 'bishop': 869,\n",
              " 'catalonia': 870,\n",
              " 'mathematics': 871,\n",
              " 'statistics': 872,\n",
              " 'arithmetic': 873,\n",
              " 'mean': 874,\n",
              " 'context': 875,\n",
              " 'clear': 876,\n",
              " 'sum': 877,\n",
              " 'collection': 878,\n",
              " 'numbers': 879,\n",
              " 'divided': 880,\n",
              " 'results': 881,\n",
              " 'experiment': 882,\n",
              " 'survey': 883,\n",
              " 'some': 884,\n",
              " 'contexts': 885,\n",
              " 'helps': 886,\n",
              " 'distinguish': 887,\n",
              " 'means': 888,\n",
              " 'geometric': 889,\n",
              " 'harmonic': 890,\n",
              " 'football': 891,\n",
              " 'conference': 892,\n",
              " 'afc': 893,\n",
              " 'league': 894,\n",
              " 'nfl': 895,\n",
              " 'highest': 896,\n",
              " 'professional': 897,\n",
              " 'level': 898,\n",
              " 'counterpart': 899,\n",
              " 'nfc': 900,\n",
              " 'contain': 901,\n",
              " '16': 902,\n",
              " 'teams': 903,\n",
              " 'divisions': 904,\n",
              " 'merger': 905,\n",
              " 'between': 906,\n",
              " 'afl': 907,\n",
              " 'ten': 908,\n",
              " 'became': 909,\n",
              " 'members': 910,\n",
              " 'farm': 911,\n",
              " 'satirical': 912,\n",
              " 'novella': 913,\n",
              " 'england': 914,\n",
              " '17': 915,\n",
              " 'august': 916,\n",
              " '1945': 917,\n",
              " 'tells': 918,\n",
              " 'story': 919,\n",
              " 'group': 920,\n",
              " 'rebel': 921,\n",
              " 'against': 922,\n",
              " 'farmer': 923,\n",
              " 'create': 924,\n",
              " 'society': 925,\n",
              " 'where': 926,\n",
              " 'equal': 927,\n",
              " 'ultimately': 928,\n",
              " 'rebellion': 929,\n",
              " 'dictatorship': 930,\n",
              " 'napoleon': 931,\n",
              " 'ends': 932,\n",
              " 'bad': 933,\n",
              " 'before': 934,\n",
              " 'according': 935,\n",
              " 'vertebrates': 936,\n",
              " 'class': 937,\n",
              " 'belong': 938,\n",
              " 'inhabit': 939,\n",
              " 'wide': 940,\n",
              " 'variety': 941,\n",
              " 'habitats': 942,\n",
              " 'freshwater': 943,\n",
              " 'aquatic': 944,\n",
              " 'thus': 945,\n",
              " 'start': 946,\n",
              " 'water': 947,\n",
              " 'developed': 948,\n",
              " 'generally': 949,\n",
              " 'metamorphosis': 950,\n",
              " 'adult': 951,\n",
              " 'air': 952,\n",
              " 'breathing': 953,\n",
              " 'skin': 954,\n",
              " 'secondary': 955,\n",
              " 'small': 956,\n",
              " 'alaska': 957,\n",
              " 'located': 958,\n",
              " 'northwest': 959,\n",
              " 'america': 960,\n",
              " 'borders': 961,\n",
              " 'province': 962,\n",
              " 'british': 963,\n",
              " 'columbia': 964,\n",
              " 'territory': 965,\n",
              " 'shares': 966,\n",
              " 'maritime': 967,\n",
              " 'border': 968,\n",
              " 'federation': 969,\n",
              " 'autonomous': 970,\n",
              " 'across': 971,\n",
              " 'strait': 972,\n",
              " 'seas': 973,\n",
              " 'arctic': 974,\n",
              " 'ocean': 975,\n",
              " 'pacific': 976,\n",
              " 'lies': 977,\n",
              " 'farming': 978,\n",
              " 'plants': 979,\n",
              " 'livestock': 980,\n",
              " 'key': 981,\n",
              " 'rise': 982,\n",
              " 'civilization': 983,\n",
              " 'whereby': 984,\n",
              " 'food': 985,\n",
              " 'enabled': 986,\n",
              " 'live': 987,\n",
              " 'cities': 988,\n",
              " 'thousands': 989,\n",
              " 'ago': 990,\n",
              " 'wild': 991,\n",
              " 'grains': 992,\n",
              " 'beginning': 993,\n",
              " 'least': 994,\n",
              " 'farmers': 995,\n",
              " 'plant': 996,\n",
              " 'them': 997,\n",
              " 'sheep': 998,\n",
              " 'cattle': 999,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8r3Ej4fBIKJB"
      },
      "source": [
        "## 1.2 Data to Bag-of-Words Tensors [2pt]\n",
        "\n",
        "In the code block below, write code to prepare the data in PyTorch tensors.\n",
        "\n",
        "The text should be converted to a bag of words (ie., a vector the length of the vocabulary in the mapping in the previous step, with counts of the words in the text)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input for this function : list of ( list of tokens )\n",
        "# this function converts each element of the input to a bag of words ( by first creating an array of occurence of each vocabulary word and then coveting this array to a tensor)\n",
        "def createTensorforDocs(data):\n",
        "  vector_for_docs = []\n",
        "  words = Vocabulary.keys()\n",
        "  for x in data:\n",
        "    vector = [x[word] if word in x.keys() else 0 for word in words ]\n",
        "    vector_for_docs.append(vector)\n",
        "  return torch.from_numpy(numpy.asarray(vector_for_docs))"
      ],
      "metadata": {
        "id": "IhdQz7PpUSVe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "####################################### Code for text being converted to bag of words #######################################\n",
        "\n",
        "# populating tensors used in training and testing model\n",
        "x_training_data_tensor = createTensorforDocs(training_text_tokenized_set)\n",
        "x_dev_data_tensor = createTensorforDocs(dev_text_tokenized_set)\n",
        "x_test_data_tensor = createTensorforDocs(test_text_tokenized_set)\n",
        "\n",
        "\n",
        "####################################### Code for changing the shape of Y vectors from shape(size_of_dataset) to shape([size_of_dataset],1) #######################################\n",
        "\n",
        "# populating tensors used in training and testing model\n",
        "y_training_data_tensor = torch.from_numpy(numpy.asarray([[x] for x in training_lengths]))\n",
        "y_dev_data_tensor = torch.from_numpy(numpy.asarray([[x] for x in dev_lengths]))\n",
        "y_test_data_tensor = torch.from_numpy(numpy.asarray([[x] for x in test_lengths]))"
      ],
      "metadata": {
        "id": "vswOxiT2UqJI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('x_training_data_tensor',x_training_data_tensor)\n",
        "print('x_dev_data_tensor',x_dev_data_tensor)\n",
        "print('x_test_data_tensor',x_test_data_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNrjk8eVTeY8",
        "outputId": "1858af57-ef4d-4bcd-8474-b3f2e15d3b93"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_training_data_tensor tensor([[2, 3, 2,  ..., 0, 0, 0],\n",
            "        [0, 3, 4,  ..., 0, 0, 0],\n",
            "        [0, 3, 5,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 1,  ..., 0, 0, 0],\n",
            "        [0, 2, 4,  ..., 0, 0, 0],\n",
            "        [0, 3, 2,  ..., 0, 0, 0]])\n",
            "x_dev_data_tensor tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 2,  ..., 0, 0, 0],\n",
            "        [0, 0, 2,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 2, 6,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 1, 1,  ..., 0, 0, 0]])\n",
            "x_test_data_tensor tensor([[0, 2, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 1,  ..., 0, 0, 0],\n",
            "        [0, 0, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 2, 3,  ..., 0, 0, 0],\n",
            "        [0, 3, 1,  ..., 0, 0, 0],\n",
            "        [0, 1, 3,  ..., 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('y_training_data_tensor)',y_training_data_tensor)\n",
        "print('y_dev_data_tensor',y_dev_data_tensor)\n",
        "print('y_test_data_tensor',y_test_data_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGNyUpO3U_nN",
        "outputId": "861c62ea-2490-4863-9aa8-1583cb50eef7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_training_data_tensor) tensor([[0.6453],\n",
            "        [0.3528],\n",
            "        [0.1265],\n",
            "        ...,\n",
            "        [0.5215],\n",
            "        [0.0191],\n",
            "        [0.1101]], dtype=torch.float64)\n",
            "y_dev_data_tensor tensor([[0.0552],\n",
            "        [0.0999],\n",
            "        [0.1331],\n",
            "        [0.0461],\n",
            "        [0.5329],\n",
            "        [0.3803],\n",
            "        [0.7429],\n",
            "        [0.3737],\n",
            "        [0.1130],\n",
            "        [0.4459],\n",
            "        [0.8221],\n",
            "        [0.5769],\n",
            "        [0.0800],\n",
            "        [0.0039],\n",
            "        [0.8192],\n",
            "        [0.2340],\n",
            "        [0.3241],\n",
            "        [0.4813],\n",
            "        [0.1308],\n",
            "        [0.1061],\n",
            "        [0.0964],\n",
            "        [0.4800],\n",
            "        [0.3005],\n",
            "        [0.4446],\n",
            "        [0.6819],\n",
            "        [0.0624],\n",
            "        [0.0023],\n",
            "        [0.6516],\n",
            "        [0.1084],\n",
            "        [0.0338],\n",
            "        [0.1668],\n",
            "        [1.0000],\n",
            "        [0.0378],\n",
            "        [0.7162],\n",
            "        [1.0000],\n",
            "        [0.4729],\n",
            "        [0.1461],\n",
            "        [0.0339],\n",
            "        [0.1397],\n",
            "        [0.0467],\n",
            "        [0.0139],\n",
            "        [0.1381],\n",
            "        [0.0618],\n",
            "        [0.6992],\n",
            "        [0.0825],\n",
            "        [0.1998],\n",
            "        [0.3397],\n",
            "        [0.3242],\n",
            "        [0.8384],\n",
            "        [0.6603],\n",
            "        [0.1526],\n",
            "        [0.4454],\n",
            "        [0.5000],\n",
            "        [0.1777],\n",
            "        [0.3162],\n",
            "        [0.4711],\n",
            "        [1.0000],\n",
            "        [0.0682],\n",
            "        [1.0000],\n",
            "        [0.0045],\n",
            "        [0.1025],\n",
            "        [0.3801],\n",
            "        [0.4676],\n",
            "        [1.0000],\n",
            "        [0.0698],\n",
            "        [0.1510],\n",
            "        [0.1671],\n",
            "        [0.9450],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.1527],\n",
            "        [0.4708],\n",
            "        [0.1268],\n",
            "        [0.2870],\n",
            "        [0.3339],\n",
            "        [0.1383],\n",
            "        [0.5040],\n",
            "        [0.0370],\n",
            "        [0.1159],\n",
            "        [0.2667],\n",
            "        [0.6404],\n",
            "        [0.7743],\n",
            "        [0.7592],\n",
            "        [0.5285],\n",
            "        [0.7861],\n",
            "        [0.9499],\n",
            "        [0.3047],\n",
            "        [0.1033],\n",
            "        [0.0131],\n",
            "        [0.1359],\n",
            "        [1.0000],\n",
            "        [0.6687],\n",
            "        [0.3711],\n",
            "        [0.0019],\n",
            "        [0.1374],\n",
            "        [0.0550],\n",
            "        [0.4501],\n",
            "        [0.0871],\n",
            "        [0.0251],\n",
            "        [0.0958],\n",
            "        [0.7153],\n",
            "        [0.2709],\n",
            "        [0.0938],\n",
            "        [0.0630],\n",
            "        [0.5334],\n",
            "        [0.7670],\n",
            "        [0.2958],\n",
            "        [1.0000],\n",
            "        [0.0533],\n",
            "        [0.1070],\n",
            "        [1.0000],\n",
            "        [0.2736],\n",
            "        [0.1435],\n",
            "        [0.0660],\n",
            "        [0.0499],\n",
            "        [0.1667],\n",
            "        [0.0373],\n",
            "        [0.0993],\n",
            "        [0.0466],\n",
            "        [0.3042],\n",
            "        [0.1685],\n",
            "        [0.0732],\n",
            "        [0.0373],\n",
            "        [0.0412],\n",
            "        [1.0000],\n",
            "        [0.1720],\n",
            "        [1.0000],\n",
            "        [0.4960],\n",
            "        [0.1058],\n",
            "        [0.1516],\n",
            "        [0.1190],\n",
            "        [0.0278],\n",
            "        [0.0161],\n",
            "        [0.0811],\n",
            "        [0.0274],\n",
            "        [0.2107],\n",
            "        [0.2254],\n",
            "        [0.0354],\n",
            "        [0.0276],\n",
            "        [0.2861],\n",
            "        [0.4141],\n",
            "        [0.0063],\n",
            "        [0.1041],\n",
            "        [0.1422],\n",
            "        [0.0026],\n",
            "        [0.5488],\n",
            "        [0.0083],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.1772],\n",
            "        [0.1442],\n",
            "        [0.6086],\n",
            "        [0.1025],\n",
            "        [0.1059],\n",
            "        [0.5772],\n",
            "        [0.0464],\n",
            "        [0.3392],\n",
            "        [0.1572],\n",
            "        [0.2298],\n",
            "        [0.1472],\n",
            "        [0.1704],\n",
            "        [0.1909],\n",
            "        [0.5225],\n",
            "        [0.5311],\n",
            "        [0.0995],\n",
            "        [1.0000],\n",
            "        [0.9419],\n",
            "        [0.2544],\n",
            "        [0.1917],\n",
            "        [0.5731],\n",
            "        [0.0576],\n",
            "        [0.4418],\n",
            "        [0.4653],\n",
            "        [0.5705],\n",
            "        [0.1428],\n",
            "        [0.2416],\n",
            "        [0.9614],\n",
            "        [0.1927],\n",
            "        [0.2578],\n",
            "        [1.0000],\n",
            "        [0.0605],\n",
            "        [0.8633],\n",
            "        [0.2742],\n",
            "        [0.0922],\n",
            "        [0.1719],\n",
            "        [0.3184],\n",
            "        [0.5352],\n",
            "        [0.0855],\n",
            "        [0.2844],\n",
            "        [0.6468],\n",
            "        [0.2538],\n",
            "        [0.6768],\n",
            "        [0.1783],\n",
            "        [0.1734],\n",
            "        [1.0000],\n",
            "        [0.1903],\n",
            "        [0.3684],\n",
            "        [0.1791],\n",
            "        [0.5791],\n",
            "        [0.1715],\n",
            "        [0.2113],\n",
            "        [0.5502],\n",
            "        [0.0636],\n",
            "        [0.9030],\n",
            "        [0.9305],\n",
            "        [0.0810],\n",
            "        [0.5443],\n",
            "        [0.1210],\n",
            "        [0.0411],\n",
            "        [0.0696],\n",
            "        [0.0202],\n",
            "        [1.0000],\n",
            "        [0.1869],\n",
            "        [0.0955],\n",
            "        [0.2788],\n",
            "        [0.0526],\n",
            "        [0.2637],\n",
            "        [0.2653],\n",
            "        [0.5137],\n",
            "        [0.2417],\n",
            "        [0.5192],\n",
            "        [0.0616],\n",
            "        [0.0589],\n",
            "        [0.2975],\n",
            "        [0.1366],\n",
            "        [0.1460],\n",
            "        [1.0000],\n",
            "        [0.2907],\n",
            "        [0.0478],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.8466],\n",
            "        [1.0000],\n",
            "        [0.5458],\n",
            "        [0.0836],\n",
            "        [0.0661],\n",
            "        [0.5950],\n",
            "        [0.1564],\n",
            "        [0.7383],\n",
            "        [0.1482],\n",
            "        [0.0874],\n",
            "        [0.1036],\n",
            "        [0.0136],\n",
            "        [0.1710],\n",
            "        [0.3181],\n",
            "        [0.0932],\n",
            "        [0.1279],\n",
            "        [0.0738],\n",
            "        [0.5986],\n",
            "        [0.1309],\n",
            "        [0.5684],\n",
            "        [0.4329],\n",
            "        [0.4022],\n",
            "        [0.0509],\n",
            "        [1.0000],\n",
            "        [0.0930],\n",
            "        [0.3622],\n",
            "        [0.6285],\n",
            "        [0.0204],\n",
            "        [0.0400],\n",
            "        [0.4648],\n",
            "        [0.4888],\n",
            "        [0.0746],\n",
            "        [0.5997],\n",
            "        [0.1226],\n",
            "        [0.1428],\n",
            "        [1.0000],\n",
            "        [0.2761],\n",
            "        [0.8673],\n",
            "        [0.5736],\n",
            "        [0.0904],\n",
            "        [0.2847],\n",
            "        [0.1933],\n",
            "        [0.9925],\n",
            "        [0.0530],\n",
            "        [1.0000],\n",
            "        [0.3818],\n",
            "        [0.1926],\n",
            "        [0.2347],\n",
            "        [0.0495],\n",
            "        [0.1507],\n",
            "        [0.0944],\n",
            "        [0.6934],\n",
            "        [0.3214],\n",
            "        [0.0658],\n",
            "        [0.4168],\n",
            "        [0.0598],\n",
            "        [0.0755],\n",
            "        [0.3732],\n",
            "        [0.1074],\n",
            "        [0.1907],\n",
            "        [0.0793],\n",
            "        [0.0125],\n",
            "        [0.6042],\n",
            "        [0.2933],\n",
            "        [0.0921],\n",
            "        [0.1638],\n",
            "        [0.5166],\n",
            "        [0.1108],\n",
            "        [0.1479],\n",
            "        [0.6797],\n",
            "        [0.0729],\n",
            "        [0.3447],\n",
            "        [0.1113],\n",
            "        [0.0074],\n",
            "        [0.3192],\n",
            "        [0.0732],\n",
            "        [0.4896],\n",
            "        [0.0898],\n",
            "        [0.2058],\n",
            "        [0.1809],\n",
            "        [0.4949],\n",
            "        [0.1215],\n",
            "        [0.5396],\n",
            "        [0.3673],\n",
            "        [0.4221],\n",
            "        [0.5566],\n",
            "        [0.1831],\n",
            "        [0.1356],\n",
            "        [0.1146],\n",
            "        [0.2202],\n",
            "        [0.0026],\n",
            "        [0.2610],\n",
            "        [0.3612],\n",
            "        [0.2210],\n",
            "        [0.0115],\n",
            "        [0.1540],\n",
            "        [0.1382],\n",
            "        [0.0398],\n",
            "        [0.2324],\n",
            "        [0.0707],\n",
            "        [0.2244],\n",
            "        [0.3915],\n",
            "        [0.7267],\n",
            "        [0.0852],\n",
            "        [0.9519],\n",
            "        [0.8890],\n",
            "        [1.0000],\n",
            "        [0.0270],\n",
            "        [0.8057],\n",
            "        [0.2766],\n",
            "        [1.0000],\n",
            "        [0.3670],\n",
            "        [0.5905],\n",
            "        [0.8443],\n",
            "        [0.0209],\n",
            "        [0.0020],\n",
            "        [0.4240],\n",
            "        [0.1114],\n",
            "        [0.2551],\n",
            "        [1.0000],\n",
            "        [0.1128],\n",
            "        [0.0226],\n",
            "        [0.0706],\n",
            "        [0.1425],\n",
            "        [0.5396],\n",
            "        [0.2499],\n",
            "        [0.4385],\n",
            "        [0.0569],\n",
            "        [0.7493],\n",
            "        [0.4873],\n",
            "        [1.0000],\n",
            "        [0.0396],\n",
            "        [0.0212],\n",
            "        [0.0917],\n",
            "        [0.4900],\n",
            "        [0.3780],\n",
            "        [0.9537],\n",
            "        [0.5273],\n",
            "        [0.5015],\n",
            "        [0.4526],\n",
            "        [0.6640],\n",
            "        [0.9036],\n",
            "        [0.6609],\n",
            "        [0.6129],\n",
            "        [0.0723],\n",
            "        [0.4331],\n",
            "        [0.6472],\n",
            "        [0.3413],\n",
            "        [0.1697],\n",
            "        [0.5351],\n",
            "        [0.3211],\n",
            "        [0.0349],\n",
            "        [0.1421],\n",
            "        [0.0347],\n",
            "        [0.1976],\n",
            "        [1.0000],\n",
            "        [0.9426],\n",
            "        [0.3868],\n",
            "        [0.0022],\n",
            "        [0.9736],\n",
            "        [0.5517],\n",
            "        [1.0000],\n",
            "        [0.0039],\n",
            "        [0.4918],\n",
            "        [0.4659],\n",
            "        [1.0000],\n",
            "        [0.4971],\n",
            "        [1.0000],\n",
            "        [0.6098],\n",
            "        [0.1030],\n",
            "        [0.1271],\n",
            "        [0.4269],\n",
            "        [0.7659],\n",
            "        [0.4114],\n",
            "        [0.3915],\n",
            "        [0.4465],\n",
            "        [0.2480],\n",
            "        [0.0216],\n",
            "        [0.0492],\n",
            "        [0.0514],\n",
            "        [0.0448],\n",
            "        [0.1160],\n",
            "        [0.0409],\n",
            "        [0.0487],\n",
            "        [0.0296],\n",
            "        [0.1258],\n",
            "        [0.0222],\n",
            "        [0.0288],\n",
            "        [0.0175],\n",
            "        [0.0245],\n",
            "        [0.0724],\n",
            "        [0.0415],\n",
            "        [0.0395],\n",
            "        [0.0638],\n",
            "        [0.0335],\n",
            "        [0.0989],\n",
            "        [0.0658],\n",
            "        [0.2023],\n",
            "        [0.0483],\n",
            "        [0.0398],\n",
            "        [0.0274],\n",
            "        [0.0792],\n",
            "        [0.0168],\n",
            "        [0.1511],\n",
            "        [0.0379],\n",
            "        [0.2555],\n",
            "        [0.1387],\n",
            "        [0.1587],\n",
            "        [0.8037],\n",
            "        [0.7510],\n",
            "        [0.0354],\n",
            "        [0.4384],\n",
            "        [0.6548],\n",
            "        [0.1266],\n",
            "        [0.1825],\n",
            "        [0.1372],\n",
            "        [0.1137],\n",
            "        [0.0497],\n",
            "        [0.0733],\n",
            "        [0.2562],\n",
            "        [0.3874],\n",
            "        [0.3403],\n",
            "        [0.0549],\n",
            "        [0.0350],\n",
            "        [0.4400],\n",
            "        [0.0963],\n",
            "        [0.8298],\n",
            "        [0.2418],\n",
            "        [0.4063],\n",
            "        [0.0360],\n",
            "        [0.1896],\n",
            "        [1.0000],\n",
            "        [0.6663],\n",
            "        [0.4688],\n",
            "        [0.5476],\n",
            "        [0.3494],\n",
            "        [0.4552],\n",
            "        [1.0000],\n",
            "        [0.2076],\n",
            "        [0.7823],\n",
            "        [0.3434],\n",
            "        [0.4403],\n",
            "        [0.0955],\n",
            "        [0.5256],\n",
            "        [0.2341],\n",
            "        [0.0605],\n",
            "        [0.1107],\n",
            "        [0.0388],\n",
            "        [0.0744],\n",
            "        [1.0000],\n",
            "        [0.1375],\n",
            "        [0.0163],\n",
            "        [0.5064],\n",
            "        [0.7643],\n",
            "        [0.0667],\n",
            "        [0.1421],\n",
            "        [0.0856],\n",
            "        [0.1714],\n",
            "        [0.1683],\n",
            "        [0.2343],\n",
            "        [0.0763],\n",
            "        [0.4178],\n",
            "        [0.0972],\n",
            "        [0.2800],\n",
            "        [0.0735],\n",
            "        [0.2085],\n",
            "        [0.2189],\n",
            "        [0.3422],\n",
            "        [0.1604],\n",
            "        [0.9719],\n",
            "        [1.0000],\n",
            "        [0.4589],\n",
            "        [0.2066],\n",
            "        [0.0417],\n",
            "        [0.1853],\n",
            "        [0.0815],\n",
            "        [0.0218],\n",
            "        [0.2330],\n",
            "        [0.0394],\n",
            "        [0.2955],\n",
            "        [0.3204],\n",
            "        [0.5487],\n",
            "        [0.1723],\n",
            "        [0.2869],\n",
            "        [0.3066],\n",
            "        [0.3998],\n",
            "        [0.6446],\n",
            "        [0.3397],\n",
            "        [0.2826],\n",
            "        [0.3616],\n",
            "        [0.3954],\n",
            "        [0.4052],\n",
            "        [0.2708],\n",
            "        [0.1449],\n",
            "        [1.0000],\n",
            "        [0.1041],\n",
            "        [0.7139],\n",
            "        [0.1893],\n",
            "        [0.2629],\n",
            "        [0.4443],\n",
            "        [0.7169],\n",
            "        [1.0000],\n",
            "        [0.2719],\n",
            "        [0.0344],\n",
            "        [0.0747],\n",
            "        [0.0717],\n",
            "        [0.4316],\n",
            "        [0.7741],\n",
            "        [0.0089],\n",
            "        [0.0638],\n",
            "        [1.0000],\n",
            "        [0.2871],\n",
            "        [0.2995],\n",
            "        [0.4347],\n",
            "        [0.7895],\n",
            "        [0.1105],\n",
            "        [0.2477],\n",
            "        [0.8325],\n",
            "        [0.2359],\n",
            "        [0.5043],\n",
            "        [0.3333],\n",
            "        [0.1594],\n",
            "        [0.0142],\n",
            "        [0.0622],\n",
            "        [0.0902],\n",
            "        [0.0113],\n",
            "        [0.5932],\n",
            "        [0.7026],\n",
            "        [0.1338],\n",
            "        [0.0638],\n",
            "        [0.0552],\n",
            "        [0.1671],\n",
            "        [0.0713],\n",
            "        [0.0344],\n",
            "        [0.3230],\n",
            "        [0.0671],\n",
            "        [0.0612],\n",
            "        [0.1337],\n",
            "        [0.0247],\n",
            "        [0.0798],\n",
            "        [0.3528],\n",
            "        [0.5027],\n",
            "        [0.7039],\n",
            "        [1.0000],\n",
            "        [0.2878],\n",
            "        [0.0700],\n",
            "        [0.0375],\n",
            "        [0.6571],\n",
            "        [0.0395],\n",
            "        [0.0462],\n",
            "        [0.1186],\n",
            "        [0.0335],\n",
            "        [1.0000],\n",
            "        [0.2144],\n",
            "        [0.2182],\n",
            "        [0.2033],\n",
            "        [0.6828],\n",
            "        [0.0766],\n",
            "        [0.0718],\n",
            "        [0.0861],\n",
            "        [0.0228],\n",
            "        [0.9964],\n",
            "        [1.0000],\n",
            "        [0.3780],\n",
            "        [0.2425],\n",
            "        [0.9091],\n",
            "        [0.8175],\n",
            "        [0.1943],\n",
            "        [0.3286],\n",
            "        [0.7354],\n",
            "        [0.0882],\n",
            "        [0.5753],\n",
            "        [0.0409],\n",
            "        [0.0600],\n",
            "        [0.1799],\n",
            "        [0.2281],\n",
            "        [0.5863],\n",
            "        [0.0145],\n",
            "        [0.1333],\n",
            "        [0.1519],\n",
            "        [0.5058],\n",
            "        [0.2329],\n",
            "        [0.0166],\n",
            "        [0.0221],\n",
            "        [0.2844],\n",
            "        [0.6261],\n",
            "        [1.0000],\n",
            "        [0.0738],\n",
            "        [0.3613],\n",
            "        [0.1427],\n",
            "        [0.1559],\n",
            "        [0.4143],\n",
            "        [0.0767],\n",
            "        [0.3595],\n",
            "        [0.0934],\n",
            "        [0.0290],\n",
            "        [0.6909],\n",
            "        [1.0000],\n",
            "        [0.2044],\n",
            "        [0.8456],\n",
            "        [0.1570],\n",
            "        [0.6457],\n",
            "        [0.0064],\n",
            "        [0.1708],\n",
            "        [0.0633],\n",
            "        [0.9418],\n",
            "        [0.0281],\n",
            "        [0.0086],\n",
            "        [0.6039],\n",
            "        [0.2846],\n",
            "        [0.2821],\n",
            "        [0.0696],\n",
            "        [0.2283],\n",
            "        [0.2939],\n",
            "        [0.1087],\n",
            "        [0.4184],\n",
            "        [0.5101],\n",
            "        [0.7152],\n",
            "        [0.0320],\n",
            "        [0.0797],\n",
            "        [1.0000],\n",
            "        [0.2391],\n",
            "        [0.0575],\n",
            "        [0.3524],\n",
            "        [0.3337],\n",
            "        [0.1137],\n",
            "        [0.2390],\n",
            "        [0.2283],\n",
            "        [0.1761],\n",
            "        [0.1389],\n",
            "        [0.4430],\n",
            "        [0.0732],\n",
            "        [0.1607],\n",
            "        [1.0000],\n",
            "        [0.5644],\n",
            "        [0.1314],\n",
            "        [0.4022],\n",
            "        [0.2799],\n",
            "        [0.3263],\n",
            "        [0.2987],\n",
            "        [0.1683],\n",
            "        [0.9467],\n",
            "        [0.4441],\n",
            "        [0.5954],\n",
            "        [0.0029],\n",
            "        [0.1493],\n",
            "        [0.0576],\n",
            "        [0.5446],\n",
            "        [0.3687],\n",
            "        [0.1442],\n",
            "        [0.1071],\n",
            "        [0.1420],\n",
            "        [0.2088],\n",
            "        [0.5777],\n",
            "        [1.0000],\n",
            "        [0.3677],\n",
            "        [0.0383],\n",
            "        [0.0233],\n",
            "        [0.0387],\n",
            "        [0.6148],\n",
            "        [0.1195],\n",
            "        [0.1067],\n",
            "        [0.1600],\n",
            "        [0.0390],\n",
            "        [1.0000],\n",
            "        [0.0653],\n",
            "        [0.3330],\n",
            "        [0.1188],\n",
            "        [0.2913],\n",
            "        [0.0309],\n",
            "        [0.1120],\n",
            "        [0.1799],\n",
            "        [0.1419],\n",
            "        [0.1202],\n",
            "        [0.4585],\n",
            "        [0.0171],\n",
            "        [0.0464],\n",
            "        [0.5838],\n",
            "        [0.0470],\n",
            "        [0.1685],\n",
            "        [0.2367],\n",
            "        [0.7918],\n",
            "        [0.1420],\n",
            "        [0.1547],\n",
            "        [0.6156],\n",
            "        [0.1110],\n",
            "        [0.3763],\n",
            "        [0.0450],\n",
            "        [0.1245],\n",
            "        [0.1499],\n",
            "        [0.1167],\n",
            "        [0.3048],\n",
            "        [0.2895],\n",
            "        [0.0027],\n",
            "        [0.1653],\n",
            "        [0.3833],\n",
            "        [0.1507],\n",
            "        [0.0118],\n",
            "        [0.0961],\n",
            "        [0.4322],\n",
            "        [0.2814],\n",
            "        [0.4466],\n",
            "        [0.0375],\n",
            "        [0.4953],\n",
            "        [0.7260],\n",
            "        [0.2629],\n",
            "        [0.1448],\n",
            "        [0.1251],\n",
            "        [0.5530],\n",
            "        [0.6276],\n",
            "        [0.4577],\n",
            "        [0.3861],\n",
            "        [0.0430],\n",
            "        [0.1478],\n",
            "        [0.1538],\n",
            "        [0.3511],\n",
            "        [0.3679],\n",
            "        [0.1860],\n",
            "        [0.1101],\n",
            "        [1.0000],\n",
            "        [0.3395],\n",
            "        [0.4292],\n",
            "        [0.0981],\n",
            "        [0.0090],\n",
            "        [0.4104],\n",
            "        [0.5419],\n",
            "        [0.2914],\n",
            "        [1.0000],\n",
            "        [0.1407],\n",
            "        [0.7847],\n",
            "        [0.2228],\n",
            "        [0.0143],\n",
            "        [0.0894],\n",
            "        [0.1893],\n",
            "        [0.0037],\n",
            "        [0.6113],\n",
            "        [0.0227],\n",
            "        [0.0198],\n",
            "        [0.0371],\n",
            "        [0.5014],\n",
            "        [0.3955],\n",
            "        [0.1643],\n",
            "        [0.4345],\n",
            "        [0.0717],\n",
            "        [0.3588],\n",
            "        [0.1890],\n",
            "        [0.6763],\n",
            "        [0.3267],\n",
            "        [0.1317],\n",
            "        [0.0452],\n",
            "        [0.2685],\n",
            "        [0.1480],\n",
            "        [0.0739],\n",
            "        [0.0422],\n",
            "        [0.1160],\n",
            "        [0.1466],\n",
            "        [1.0000],\n",
            "        [0.2060],\n",
            "        [0.6097],\n",
            "        [1.0000],\n",
            "        [0.0402],\n",
            "        [0.0840],\n",
            "        [0.0543],\n",
            "        [0.0168],\n",
            "        [0.0684],\n",
            "        [0.3268],\n",
            "        [0.0292],\n",
            "        [0.0668],\n",
            "        [0.5577],\n",
            "        [0.1656],\n",
            "        [0.3260],\n",
            "        [0.0381],\n",
            "        [0.0306],\n",
            "        [0.0729],\n",
            "        [1.0000],\n",
            "        [0.0880],\n",
            "        [0.0707],\n",
            "        [0.1630],\n",
            "        [0.0152],\n",
            "        [0.0362],\n",
            "        [0.0739],\n",
            "        [0.0191],\n",
            "        [0.1827],\n",
            "        [0.5474],\n",
            "        [0.0467],\n",
            "        [0.7092],\n",
            "        [0.1145],\n",
            "        [0.1154],\n",
            "        [0.2286],\n",
            "        [0.0778],\n",
            "        [0.4654],\n",
            "        [0.1575],\n",
            "        [0.1722],\n",
            "        [0.1941],\n",
            "        [0.2205],\n",
            "        [0.0431],\n",
            "        [0.3764],\n",
            "        [0.3930],\n",
            "        [0.0414],\n",
            "        [0.0406],\n",
            "        [1.0000],\n",
            "        [0.4400],\n",
            "        [0.0989],\n",
            "        [0.0644],\n",
            "        [0.0305],\n",
            "        [0.4770],\n",
            "        [1.0000],\n",
            "        [0.0738],\n",
            "        [0.0432],\n",
            "        [0.1729],\n",
            "        [0.1052],\n",
            "        [0.1339],\n",
            "        [0.2162],\n",
            "        [0.0409],\n",
            "        [0.0209],\n",
            "        [0.0511],\n",
            "        [0.0054],\n",
            "        [0.0547],\n",
            "        [0.1053],\n",
            "        [0.3648],\n",
            "        [0.9354],\n",
            "        [0.4095],\n",
            "        [0.5391],\n",
            "        [0.5209],\n",
            "        [0.0213],\n",
            "        [0.0784],\n",
            "        [1.0000],\n",
            "        [0.0097],\n",
            "        [1.0000],\n",
            "        [0.0393],\n",
            "        [0.8295],\n",
            "        [0.3003],\n",
            "        [0.0799],\n",
            "        [0.2739],\n",
            "        [0.1823],\n",
            "        [0.6535],\n",
            "        [0.1375],\n",
            "        [0.5236],\n",
            "        [0.0345],\n",
            "        [0.0316],\n",
            "        [0.1064],\n",
            "        [0.1611],\n",
            "        [0.0916],\n",
            "        [0.0586],\n",
            "        [0.0865],\n",
            "        [0.7904],\n",
            "        [0.1418],\n",
            "        [0.1393],\n",
            "        [0.4854],\n",
            "        [0.3130],\n",
            "        [0.0940],\n",
            "        [0.1205],\n",
            "        [0.2234],\n",
            "        [0.3264],\n",
            "        [0.2004],\n",
            "        [0.0691],\n",
            "        [0.1346],\n",
            "        [0.1029],\n",
            "        [0.0401],\n",
            "        [0.1285],\n",
            "        [0.0555],\n",
            "        [0.2742],\n",
            "        [0.6522],\n",
            "        [0.1536],\n",
            "        [0.2144],\n",
            "        [0.0106],\n",
            "        [0.0881],\n",
            "        [0.6326],\n",
            "        [0.0255],\n",
            "        [0.0297],\n",
            "        [0.0342],\n",
            "        [0.0823],\n",
            "        [0.0510],\n",
            "        [0.0378],\n",
            "        [0.0410],\n",
            "        [0.1058],\n",
            "        [0.1704],\n",
            "        [0.0728],\n",
            "        [0.1260],\n",
            "        [0.3938],\n",
            "        [0.1562],\n",
            "        [0.5025],\n",
            "        [0.9346],\n",
            "        [0.1655],\n",
            "        [0.6490],\n",
            "        [1.0000],\n",
            "        [0.0665],\n",
            "        [0.0022],\n",
            "        [0.5275],\n",
            "        [0.1905],\n",
            "        [0.0442],\n",
            "        [0.5409],\n",
            "        [0.1910],\n",
            "        [0.4206],\n",
            "        [0.0203],\n",
            "        [0.0966],\n",
            "        [0.0752],\n",
            "        [0.0176],\n",
            "        [0.0521],\n",
            "        [0.0579],\n",
            "        [0.0392],\n",
            "        [0.0131],\n",
            "        [0.1045],\n",
            "        [0.5853],\n",
            "        [0.1313],\n",
            "        [0.1621],\n",
            "        [0.1919],\n",
            "        [0.2930],\n",
            "        [0.1693],\n",
            "        [0.0606],\n",
            "        [0.2769],\n",
            "        [0.1252],\n",
            "        [0.1136],\n",
            "        [0.2492],\n",
            "        [0.2440],\n",
            "        [0.7159],\n",
            "        [0.4882],\n",
            "        [0.3176],\n",
            "        [0.2892],\n",
            "        [0.1437],\n",
            "        [0.2928],\n",
            "        [0.1700],\n",
            "        [0.7412],\n",
            "        [0.9296],\n",
            "        [1.0000],\n",
            "        [0.6531],\n",
            "        [0.1073],\n",
            "        [0.0702],\n",
            "        [0.0782],\n",
            "        [0.1016],\n",
            "        [0.1579],\n",
            "        [0.3720],\n",
            "        [0.3677],\n",
            "        [0.3498],\n",
            "        [0.4528],\n",
            "        [0.1867],\n",
            "        [0.9082],\n",
            "        [0.1292],\n",
            "        [0.1013],\n",
            "        [0.3027],\n",
            "        [0.2353],\n",
            "        [0.5917],\n",
            "        [0.1775],\n",
            "        [0.5195],\n",
            "        [0.1134],\n",
            "        [0.2188],\n",
            "        [0.1856],\n",
            "        [0.1123],\n",
            "        [0.6131],\n",
            "        [0.6980],\n",
            "        [0.0725],\n",
            "        [0.5260],\n",
            "        [0.3009],\n",
            "        [0.1999],\n",
            "        [0.1379],\n",
            "        [1.0000],\n",
            "        [0.2219],\n",
            "        [0.2032],\n",
            "        [0.2687],\n",
            "        [0.1390],\n",
            "        [0.3186],\n",
            "        [0.1686],\n",
            "        [0.1953]], dtype=torch.float64)\n",
            "y_test_data_tensor tensor([[0.2905],\n",
            "        [0.4138],\n",
            "        [0.0558],\n",
            "        [0.0634],\n",
            "        [0.0414],\n",
            "        [0.0571],\n",
            "        [0.2096],\n",
            "        [0.3854],\n",
            "        [0.2260],\n",
            "        [0.1627],\n",
            "        [0.4779],\n",
            "        [1.0000],\n",
            "        [0.8417],\n",
            "        [0.4917],\n",
            "        [0.1004],\n",
            "        [0.7282],\n",
            "        [0.3487],\n",
            "        [0.2106],\n",
            "        [0.1163],\n",
            "        [0.1497],\n",
            "        [0.3482],\n",
            "        [0.0969],\n",
            "        [0.1787],\n",
            "        [0.0840],\n",
            "        [0.1663],\n",
            "        [0.1318],\n",
            "        [0.2430],\n",
            "        [0.1366],\n",
            "        [0.1876],\n",
            "        [0.0432],\n",
            "        [0.0761],\n",
            "        [0.0632],\n",
            "        [0.3013],\n",
            "        [0.5176],\n",
            "        [0.6209],\n",
            "        [0.0202],\n",
            "        [0.1058],\n",
            "        [1.0000],\n",
            "        [0.1024],\n",
            "        [0.3109],\n",
            "        [0.1410],\n",
            "        [0.0759],\n",
            "        [0.1623],\n",
            "        [0.1526],\n",
            "        [0.2695],\n",
            "        [0.3350],\n",
            "        [0.1012],\n",
            "        [0.0670],\n",
            "        [0.1031],\n",
            "        [0.1988],\n",
            "        [0.2438],\n",
            "        [0.0645],\n",
            "        [0.1019],\n",
            "        [0.1207],\n",
            "        [0.0450],\n",
            "        [0.0857],\n",
            "        [0.1981],\n",
            "        [0.1901],\n",
            "        [0.4734],\n",
            "        [0.3259],\n",
            "        [0.5425],\n",
            "        [0.0714],\n",
            "        [0.5765],\n",
            "        [0.4959],\n",
            "        [0.0094],\n",
            "        [0.9576],\n",
            "        [0.2494],\n",
            "        [0.0191],\n",
            "        [0.0207],\n",
            "        [0.1148],\n",
            "        [0.0868],\n",
            "        [0.1217],\n",
            "        [0.3807],\n",
            "        [0.4320],\n",
            "        [0.6002],\n",
            "        [0.0745],\n",
            "        [0.0402],\n",
            "        [0.0381],\n",
            "        [0.0341],\n",
            "        [0.2083],\n",
            "        [0.1927],\n",
            "        [0.1915],\n",
            "        [0.3305],\n",
            "        [0.0717],\n",
            "        [0.2285],\n",
            "        [0.0482],\n",
            "        [0.0984],\n",
            "        [0.4014],\n",
            "        [0.0396],\n",
            "        [0.0612],\n",
            "        [0.3275],\n",
            "        [0.2901],\n",
            "        [0.1572],\n",
            "        [0.0716],\n",
            "        [0.5070],\n",
            "        [0.4909],\n",
            "        [0.1147],\n",
            "        [0.2071],\n",
            "        [0.1169],\n",
            "        [0.0808],\n",
            "        [0.0394],\n",
            "        [0.0497],\n",
            "        [0.0473],\n",
            "        [0.2616],\n",
            "        [0.1531],\n",
            "        [0.2614],\n",
            "        [0.4656],\n",
            "        [1.0000],\n",
            "        [0.3236],\n",
            "        [0.0381],\n",
            "        [0.2265],\n",
            "        [0.0614],\n",
            "        [0.0415],\n",
            "        [0.0376],\n",
            "        [0.0255],\n",
            "        [0.0751],\n",
            "        [0.2396],\n",
            "        [0.1029],\n",
            "        [0.0383],\n",
            "        [0.2123],\n",
            "        [0.0393],\n",
            "        [0.4627],\n",
            "        [0.1200],\n",
            "        [0.2774],\n",
            "        [0.8199],\n",
            "        [0.1181],\n",
            "        [0.0667],\n",
            "        [0.4591],\n",
            "        [0.3566],\n",
            "        [0.3264],\n",
            "        [0.5491],\n",
            "        [0.0076],\n",
            "        [0.4509],\n",
            "        [0.2040],\n",
            "        [0.1600],\n",
            "        [0.0646],\n",
            "        [0.0454],\n",
            "        [0.1099],\n",
            "        [0.0997],\n",
            "        [0.1874],\n",
            "        [0.0126],\n",
            "        [0.2367],\n",
            "        [0.3920],\n",
            "        [0.1122],\n",
            "        [0.0362],\n",
            "        [0.3079],\n",
            "        [0.0974],\n",
            "        [0.2129],\n",
            "        [0.0347],\n",
            "        [0.6693],\n",
            "        [0.6996],\n",
            "        [1.0000],\n",
            "        [0.0024],\n",
            "        [0.7431],\n",
            "        [0.1548],\n",
            "        [0.3637],\n",
            "        [0.0655],\n",
            "        [0.1733],\n",
            "        [0.2460],\n",
            "        [0.0907],\n",
            "        [0.0999],\n",
            "        [0.3283],\n",
            "        [0.1964],\n",
            "        [0.0550],\n",
            "        [0.4847],\n",
            "        [0.5815],\n",
            "        [0.0146],\n",
            "        [0.0722],\n",
            "        [0.0898],\n",
            "        [0.4501],\n",
            "        [0.4386],\n",
            "        [0.1549],\n",
            "        [0.3573],\n",
            "        [0.3442],\n",
            "        [0.2468],\n",
            "        [0.2733],\n",
            "        [0.0047],\n",
            "        [0.4323],\n",
            "        [0.4736],\n",
            "        [1.0000],\n",
            "        [0.0478],\n",
            "        [0.1609],\n",
            "        [0.7323],\n",
            "        [0.0220],\n",
            "        [0.0260],\n",
            "        [0.0409],\n",
            "        [0.0581],\n",
            "        [0.2917],\n",
            "        [0.0709],\n",
            "        [0.0318],\n",
            "        [0.0035],\n",
            "        [0.0051],\n",
            "        [0.1708],\n",
            "        [0.2498],\n",
            "        [0.7912],\n",
            "        [0.0979],\n",
            "        [1.0000],\n",
            "        [0.3806],\n",
            "        [0.1529],\n",
            "        [0.2142],\n",
            "        [0.1303],\n",
            "        [0.1900],\n",
            "        [0.1355],\n",
            "        [0.7581],\n",
            "        [0.2362],\n",
            "        [0.2900],\n",
            "        [0.4483],\n",
            "        [0.9900],\n",
            "        [0.0384],\n",
            "        [0.0726],\n",
            "        [0.3724],\n",
            "        [0.4604],\n",
            "        [0.1505],\n",
            "        [0.0703],\n",
            "        [0.8946],\n",
            "        [0.1741],\n",
            "        [0.6558],\n",
            "        [0.0129],\n",
            "        [0.2217],\n",
            "        [0.3803],\n",
            "        [0.1291],\n",
            "        [0.3616],\n",
            "        [0.0353],\n",
            "        [0.0391],\n",
            "        [0.2902],\n",
            "        [0.1158],\n",
            "        [0.1629],\n",
            "        [0.0699],\n",
            "        [0.0265],\n",
            "        [1.0000],\n",
            "        [0.0830],\n",
            "        [0.3402],\n",
            "        [0.1002],\n",
            "        [0.8251],\n",
            "        [0.1671],\n",
            "        [0.1885],\n",
            "        [0.0022],\n",
            "        [0.6669],\n",
            "        [0.6698],\n",
            "        [0.0665],\n",
            "        [0.0937],\n",
            "        [0.2486],\n",
            "        [0.2830],\n",
            "        [1.0000],\n",
            "        [0.2115],\n",
            "        [0.6577],\n",
            "        [0.8638],\n",
            "        [0.6452],\n",
            "        [0.3605],\n",
            "        [0.0064],\n",
            "        [0.0978],\n",
            "        [0.0552],\n",
            "        [0.2200],\n",
            "        [0.5453],\n",
            "        [0.1490],\n",
            "        [0.0373],\n",
            "        [0.2637],\n",
            "        [0.2501],\n",
            "        [0.1805],\n",
            "        [0.2414],\n",
            "        [0.0137],\n",
            "        [0.7147],\n",
            "        [0.4024],\n",
            "        [0.2233],\n",
            "        [0.0974],\n",
            "        [0.4258],\n",
            "        [0.1569],\n",
            "        [0.1793],\n",
            "        [0.3297],\n",
            "        [0.0870],\n",
            "        [0.2088],\n",
            "        [0.0762],\n",
            "        [0.1747],\n",
            "        [0.3548],\n",
            "        [0.1214],\n",
            "        [0.3002],\n",
            "        [0.1897],\n",
            "        [0.4681],\n",
            "        [0.0633],\n",
            "        [0.0756],\n",
            "        [0.4083],\n",
            "        [0.0673],\n",
            "        [0.4281],\n",
            "        [0.0492],\n",
            "        [0.2128],\n",
            "        [0.0999],\n",
            "        [0.1571],\n",
            "        [0.1993],\n",
            "        [0.2387],\n",
            "        [0.1563],\n",
            "        [0.1363],\n",
            "        [0.3970],\n",
            "        [0.0250],\n",
            "        [0.4429],\n",
            "        [0.1005],\n",
            "        [0.1046],\n",
            "        [0.1660],\n",
            "        [0.0113],\n",
            "        [0.1196],\n",
            "        [0.0740],\n",
            "        [0.1615],\n",
            "        [0.0513],\n",
            "        [0.1033],\n",
            "        [0.1496],\n",
            "        [0.0524],\n",
            "        [0.0654],\n",
            "        [0.0763],\n",
            "        [0.0911],\n",
            "        [0.4934],\n",
            "        [0.1520],\n",
            "        [0.5364],\n",
            "        [0.2513],\n",
            "        [0.2667],\n",
            "        [0.1155],\n",
            "        [0.6917],\n",
            "        [0.1897],\n",
            "        [0.4272],\n",
            "        [0.1916],\n",
            "        [0.1487],\n",
            "        [0.1962],\n",
            "        [0.2396],\n",
            "        [0.2856],\n",
            "        [0.0476],\n",
            "        [0.2017],\n",
            "        [0.2115],\n",
            "        [0.1002],\n",
            "        [0.0037],\n",
            "        [0.0050],\n",
            "        [0.0036],\n",
            "        [0.0607],\n",
            "        [0.1948],\n",
            "        [0.4711],\n",
            "        [0.2258],\n",
            "        [0.0834],\n",
            "        [0.0165],\n",
            "        [0.0978],\n",
            "        [0.7646],\n",
            "        [0.0269],\n",
            "        [0.5491],\n",
            "        [0.0389],\n",
            "        [0.7723],\n",
            "        [0.1679],\n",
            "        [0.0201],\n",
            "        [0.3911],\n",
            "        [0.3414],\n",
            "        [0.0985],\n",
            "        [0.1994],\n",
            "        [0.0367],\n",
            "        [0.0427],\n",
            "        [0.1667],\n",
            "        [0.6906],\n",
            "        [0.4803],\n",
            "        [0.0545],\n",
            "        [0.5769],\n",
            "        [0.0428],\n",
            "        [0.0021],\n",
            "        [0.2898],\n",
            "        [0.1730],\n",
            "        [0.0153],\n",
            "        [0.0210],\n",
            "        [0.3894],\n",
            "        [0.1854],\n",
            "        [0.0516],\n",
            "        [0.2722],\n",
            "        [0.3443],\n",
            "        [0.1148],\n",
            "        [0.4934],\n",
            "        [1.0000],\n",
            "        [0.5383],\n",
            "        [0.1455],\n",
            "        [0.2760],\n",
            "        [0.0028],\n",
            "        [0.1421],\n",
            "        [0.3106],\n",
            "        [0.4408],\n",
            "        [0.0960],\n",
            "        [0.2385],\n",
            "        [0.8496],\n",
            "        [0.2474],\n",
            "        [0.2162],\n",
            "        [0.4042],\n",
            "        [0.1009],\n",
            "        [0.2154],\n",
            "        [0.0889],\n",
            "        [0.0663],\n",
            "        [0.7277],\n",
            "        [0.2739],\n",
            "        [0.0870],\n",
            "        [0.3906],\n",
            "        [0.2752],\n",
            "        [0.3292],\n",
            "        [0.2592],\n",
            "        [0.1591],\n",
            "        [0.3442],\n",
            "        [0.1681],\n",
            "        [0.4459],\n",
            "        [0.3542],\n",
            "        [0.4263],\n",
            "        [0.0800],\n",
            "        [0.3990],\n",
            "        [0.3342],\n",
            "        [0.3115],\n",
            "        [0.0710],\n",
            "        [0.1136],\n",
            "        [0.0623],\n",
            "        [0.1175],\n",
            "        [0.1139],\n",
            "        [0.0421],\n",
            "        [0.0958],\n",
            "        [0.6308],\n",
            "        [0.2213],\n",
            "        [0.1770],\n",
            "        [0.0563],\n",
            "        [0.1296],\n",
            "        [0.6989],\n",
            "        [0.1038],\n",
            "        [0.0892],\n",
            "        [0.2267],\n",
            "        [0.0548],\n",
            "        [0.7630],\n",
            "        [0.0263],\n",
            "        [0.3782],\n",
            "        [0.0946],\n",
            "        [0.8948],\n",
            "        [0.8158],\n",
            "        [0.1882],\n",
            "        [0.9363],\n",
            "        [0.0693],\n",
            "        [0.4388],\n",
            "        [0.0809],\n",
            "        [0.1139],\n",
            "        [0.2955],\n",
            "        [0.1044],\n",
            "        [0.2508],\n",
            "        [0.8290],\n",
            "        [0.0637],\n",
            "        [0.1320],\n",
            "        [0.0382],\n",
            "        [0.4277],\n",
            "        [0.1713],\n",
            "        [0.4515],\n",
            "        [0.1211],\n",
            "        [0.0703],\n",
            "        [0.3160],\n",
            "        [0.1439],\n",
            "        [0.3067],\n",
            "        [1.0000],\n",
            "        [0.5652],\n",
            "        [0.2088],\n",
            "        [0.4383],\n",
            "        [0.0696],\n",
            "        [0.0551],\n",
            "        [0.3407],\n",
            "        [0.4540],\n",
            "        [0.6390],\n",
            "        [0.6172],\n",
            "        [0.1149],\n",
            "        [0.2921],\n",
            "        [0.1667],\n",
            "        [0.7880],\n",
            "        [0.9166],\n",
            "        [0.1608],\n",
            "        [0.3438],\n",
            "        [0.0675],\n",
            "        [0.0427],\n",
            "        [0.0031],\n",
            "        [0.0656],\n",
            "        [0.1080],\n",
            "        [0.0447],\n",
            "        [0.1571],\n",
            "        [0.1522],\n",
            "        [0.8334],\n",
            "        [0.0600],\n",
            "        [0.0564],\n",
            "        [0.1052],\n",
            "        [0.2234],\n",
            "        [0.0549],\n",
            "        [0.0563],\n",
            "        [1.0000],\n",
            "        [0.7691],\n",
            "        [0.3375],\n",
            "        [0.0387],\n",
            "        [0.4271],\n",
            "        [0.1287],\n",
            "        [0.0882],\n",
            "        [0.2780],\n",
            "        [0.1247],\n",
            "        [0.0581],\n",
            "        [0.1767],\n",
            "        [0.2115],\n",
            "        [0.6352],\n",
            "        [0.2878],\n",
            "        [0.0602],\n",
            "        [1.0000],\n",
            "        [0.3529],\n",
            "        [0.1817],\n",
            "        [0.1019],\n",
            "        [0.3930],\n",
            "        [0.0609],\n",
            "        [0.5716],\n",
            "        [0.1380],\n",
            "        [0.0528],\n",
            "        [0.0726],\n",
            "        [1.0000],\n",
            "        [0.1635],\n",
            "        [0.0899],\n",
            "        [0.6695],\n",
            "        [0.0930],\n",
            "        [0.0329],\n",
            "        [0.0640],\n",
            "        [0.0723],\n",
            "        [0.3651],\n",
            "        [0.2055],\n",
            "        [0.2768],\n",
            "        [0.6159],\n",
            "        [0.1454],\n",
            "        [0.4062],\n",
            "        [0.0988],\n",
            "        [0.0151],\n",
            "        [0.1494],\n",
            "        [0.2207],\n",
            "        [0.4739],\n",
            "        [0.5913],\n",
            "        [0.0646],\n",
            "        [0.2138],\n",
            "        [0.2294],\n",
            "        [0.1562],\n",
            "        [0.2331],\n",
            "        [0.0083],\n",
            "        [0.0346],\n",
            "        [0.0035],\n",
            "        [0.1289],\n",
            "        [0.3022],\n",
            "        [0.1016],\n",
            "        [0.0571],\n",
            "        [0.7405],\n",
            "        [0.1064],\n",
            "        [0.3778],\n",
            "        [0.0906],\n",
            "        [0.3961],\n",
            "        [0.1140],\n",
            "        [0.1763],\n",
            "        [0.1190],\n",
            "        [0.8663],\n",
            "        [0.1318],\n",
            "        [0.0657],\n",
            "        [0.2610],\n",
            "        [0.2635],\n",
            "        [0.0218],\n",
            "        [0.0622],\n",
            "        [0.1012],\n",
            "        [0.1834],\n",
            "        [0.0973],\n",
            "        [0.2746],\n",
            "        [0.6565],\n",
            "        [0.3646],\n",
            "        [0.1873],\n",
            "        [0.0958],\n",
            "        [0.2886],\n",
            "        [0.1409],\n",
            "        [0.7882],\n",
            "        [0.3627],\n",
            "        [0.3659],\n",
            "        [0.2959],\n",
            "        [0.5024],\n",
            "        [0.2041],\n",
            "        [0.2827],\n",
            "        [0.1028],\n",
            "        [0.3271],\n",
            "        [0.4351],\n",
            "        [0.2734],\n",
            "        [0.0868],\n",
            "        [0.0434],\n",
            "        [0.7601],\n",
            "        [0.4859],\n",
            "        [0.0898],\n",
            "        [0.0343],\n",
            "        [0.1080],\n",
            "        [0.0026],\n",
            "        [0.1511],\n",
            "        [0.0408],\n",
            "        [0.7346],\n",
            "        [0.0364],\n",
            "        [0.1725],\n",
            "        [0.0418],\n",
            "        [0.3718],\n",
            "        [0.1438],\n",
            "        [0.7239],\n",
            "        [0.4759],\n",
            "        [0.4037],\n",
            "        [0.1645],\n",
            "        [0.0528],\n",
            "        [0.4105],\n",
            "        [0.2687],\n",
            "        [0.5844],\n",
            "        [0.2843],\n",
            "        [0.4874],\n",
            "        [0.0639],\n",
            "        [0.5438],\n",
            "        [0.1183],\n",
            "        [0.2572],\n",
            "        [0.1292],\n",
            "        [0.0502],\n",
            "        [0.2799],\n",
            "        [0.0220],\n",
            "        [0.0551],\n",
            "        [0.1749],\n",
            "        [1.0000],\n",
            "        [0.2985],\n",
            "        [0.2746],\n",
            "        [0.1210],\n",
            "        [0.2282],\n",
            "        [0.1563],\n",
            "        [0.0044],\n",
            "        [0.0947],\n",
            "        [0.0024],\n",
            "        [0.0898],\n",
            "        [0.6397],\n",
            "        [0.1816],\n",
            "        [0.1595],\n",
            "        [0.0505],\n",
            "        [0.0332],\n",
            "        [0.2777],\n",
            "        [0.2316],\n",
            "        [0.4605],\n",
            "        [0.4327],\n",
            "        [0.9659],\n",
            "        [1.0000],\n",
            "        [0.5618],\n",
            "        [1.0000],\n",
            "        [0.2377],\n",
            "        [1.0000],\n",
            "        [0.2695],\n",
            "        [0.2265],\n",
            "        [1.0000],\n",
            "        [0.8716],\n",
            "        [0.9072],\n",
            "        [0.4918],\n",
            "        [0.7141],\n",
            "        [0.6613],\n",
            "        [0.1570],\n",
            "        [0.0376],\n",
            "        [0.7293],\n",
            "        [1.0000],\n",
            "        [0.0412],\n",
            "        [0.9940],\n",
            "        [0.7583],\n",
            "        [0.6002],\n",
            "        [0.9257],\n",
            "        [1.0000],\n",
            "        [0.2289],\n",
            "        [0.4206],\n",
            "        [1.0000],\n",
            "        [0.2817],\n",
            "        [1.0000],\n",
            "        [0.8942],\n",
            "        [0.2719],\n",
            "        [0.4605],\n",
            "        [0.4810],\n",
            "        [1.0000],\n",
            "        [0.3921],\n",
            "        [0.0718],\n",
            "        [1.0000],\n",
            "        [0.1449],\n",
            "        [0.0614],\n",
            "        [0.4447],\n",
            "        [0.1322],\n",
            "        [0.0595],\n",
            "        [0.0228],\n",
            "        [0.1957],\n",
            "        [0.5333],\n",
            "        [0.5391],\n",
            "        [0.5046],\n",
            "        [0.0473],\n",
            "        [0.0665],\n",
            "        [0.0315],\n",
            "        [0.1070],\n",
            "        [0.0525],\n",
            "        [0.0399],\n",
            "        [0.0603],\n",
            "        [0.0274],\n",
            "        [0.4739],\n",
            "        [1.0000],\n",
            "        [0.4302],\n",
            "        [0.2647],\n",
            "        [0.6847],\n",
            "        [0.0183],\n",
            "        [0.4492],\n",
            "        [0.7767],\n",
            "        [0.4579],\n",
            "        [0.6582],\n",
            "        [1.0000],\n",
            "        [0.2856],\n",
            "        [0.1948],\n",
            "        [0.9992],\n",
            "        [0.1265],\n",
            "        [0.6090],\n",
            "        [0.6852],\n",
            "        [0.3240],\n",
            "        [0.2183],\n",
            "        [0.0434],\n",
            "        [0.3677],\n",
            "        [0.2207],\n",
            "        [0.3095],\n",
            "        [0.2036],\n",
            "        [0.4368],\n",
            "        [0.2408],\n",
            "        [0.7867],\n",
            "        [0.2307],\n",
            "        [0.0076],\n",
            "        [0.0100],\n",
            "        [0.0456],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.0895],\n",
            "        [0.1237],\n",
            "        [1.0000],\n",
            "        [0.1877],\n",
            "        [0.0228],\n",
            "        [0.0620],\n",
            "        [0.0360],\n",
            "        [0.0190],\n",
            "        [0.0359],\n",
            "        [1.0000],\n",
            "        [0.1933],\n",
            "        [0.1422],\n",
            "        [0.4407],\n",
            "        [0.3850],\n",
            "        [0.4445],\n",
            "        [0.1076],\n",
            "        [0.0118],\n",
            "        [0.9129],\n",
            "        [0.0531],\n",
            "        [0.1282],\n",
            "        [0.2476],\n",
            "        [0.0889],\n",
            "        [0.1460],\n",
            "        [0.0403],\n",
            "        [0.3762],\n",
            "        [0.4222],\n",
            "        [0.8270],\n",
            "        [0.5851],\n",
            "        [0.3215],\n",
            "        [0.1072],\n",
            "        [0.4636],\n",
            "        [0.1054],\n",
            "        [0.8156],\n",
            "        [0.7890],\n",
            "        [0.6570],\n",
            "        [0.3806],\n",
            "        [0.3416],\n",
            "        [0.4413],\n",
            "        [0.1779],\n",
            "        [0.4075],\n",
            "        [0.2169],\n",
            "        [1.0000],\n",
            "        [0.4967],\n",
            "        [0.4373],\n",
            "        [0.1869],\n",
            "        [0.4829],\n",
            "        [0.6098],\n",
            "        [0.0657],\n",
            "        [0.9624],\n",
            "        [0.0498],\n",
            "        [0.5223],\n",
            "        [0.7793],\n",
            "        [0.1453],\n",
            "        [0.0397],\n",
            "        [0.6209],\n",
            "        [0.4188],\n",
            "        [0.0990],\n",
            "        [1.0000],\n",
            "        [0.4010],\n",
            "        [0.4813],\n",
            "        [0.3114],\n",
            "        [0.2604],\n",
            "        [1.0000],\n",
            "        [0.1772],\n",
            "        [0.2613],\n",
            "        [0.1874],\n",
            "        [0.2576],\n",
            "        [0.0025],\n",
            "        [0.6538],\n",
            "        [0.5346],\n",
            "        [0.0989],\n",
            "        [0.1428],\n",
            "        [0.3265],\n",
            "        [0.9017],\n",
            "        [0.0539],\n",
            "        [0.4693],\n",
            "        [0.3366],\n",
            "        [0.2103],\n",
            "        [0.2440],\n",
            "        [0.0706],\n",
            "        [0.5123],\n",
            "        [0.9074],\n",
            "        [0.5136],\n",
            "        [0.7793],\n",
            "        [0.2562],\n",
            "        [0.1391],\n",
            "        [0.4527],\n",
            "        [0.0129],\n",
            "        [0.6433],\n",
            "        [0.0171],\n",
            "        [0.3953],\n",
            "        [0.2413],\n",
            "        [0.0738],\n",
            "        [1.0000],\n",
            "        [0.1853],\n",
            "        [0.3294],\n",
            "        [0.7567],\n",
            "        [0.1775],\n",
            "        [0.1036],\n",
            "        [1.0000],\n",
            "        [0.3665],\n",
            "        [0.9694],\n",
            "        [0.1885],\n",
            "        [0.0317],\n",
            "        [0.2455],\n",
            "        [0.6648],\n",
            "        [0.4269],\n",
            "        [0.2590],\n",
            "        [0.2987],\n",
            "        [0.9532],\n",
            "        [0.0826],\n",
            "        [0.0408],\n",
            "        [0.7859],\n",
            "        [0.4450],\n",
            "        [0.7816],\n",
            "        [0.0473],\n",
            "        [0.0377],\n",
            "        [0.1943],\n",
            "        [0.1328],\n",
            "        [0.0661],\n",
            "        [0.5315],\n",
            "        [0.1037],\n",
            "        [0.1577],\n",
            "        [0.5936],\n",
            "        [0.1237],\n",
            "        [0.2647],\n",
            "        [0.1817],\n",
            "        [0.8354],\n",
            "        [0.1770],\n",
            "        [0.1607],\n",
            "        [0.3526],\n",
            "        [0.5014],\n",
            "        [0.5175],\n",
            "        [0.3798],\n",
            "        [0.0930],\n",
            "        [0.5243],\n",
            "        [0.5124],\n",
            "        [0.0924],\n",
            "        [0.4939],\n",
            "        [0.5563],\n",
            "        [0.3920],\n",
            "        [0.2285],\n",
            "        [0.4212],\n",
            "        [0.1723],\n",
            "        [0.6358],\n",
            "        [0.9434],\n",
            "        [0.0982],\n",
            "        [0.0228],\n",
            "        [0.2217],\n",
            "        [0.1136],\n",
            "        [0.4089],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.0437],\n",
            "        [0.1724],\n",
            "        [0.6244],\n",
            "        [0.1964],\n",
            "        [0.3551],\n",
            "        [0.2972],\n",
            "        [0.2562],\n",
            "        [0.2121],\n",
            "        [0.0501],\n",
            "        [0.6816],\n",
            "        [0.5989],\n",
            "        [0.6726],\n",
            "        [0.2104],\n",
            "        [0.2923],\n",
            "        [0.1058],\n",
            "        [0.2335],\n",
            "        [0.2196],\n",
            "        [0.1930],\n",
            "        [0.2590],\n",
            "        [0.0788],\n",
            "        [0.4757],\n",
            "        [0.1454],\n",
            "        [0.1190],\n",
            "        [0.2494],\n",
            "        [0.4061],\n",
            "        [0.0910],\n",
            "        [0.4658],\n",
            "        [0.1930],\n",
            "        [0.6326],\n",
            "        [0.4888],\n",
            "        [0.1005],\n",
            "        [0.2478],\n",
            "        [0.0018],\n",
            "        [0.2249],\n",
            "        [0.7536],\n",
            "        [0.1505],\n",
            "        [0.1553],\n",
            "        [0.3978],\n",
            "        [0.4769],\n",
            "        [0.2891],\n",
            "        [0.1654],\n",
            "        [1.0000],\n",
            "        [0.2052],\n",
            "        [0.0638],\n",
            "        [0.5705],\n",
            "        [0.1071],\n",
            "        [0.4708],\n",
            "        [0.6598],\n",
            "        [0.1951],\n",
            "        [0.2322],\n",
            "        [0.2209],\n",
            "        [0.3357],\n",
            "        [0.1046],\n",
            "        [0.7737],\n",
            "        [0.1274],\n",
            "        [0.0779],\n",
            "        [0.1069],\n",
            "        [0.7015],\n",
            "        [0.9708],\n",
            "        [0.1301],\n",
            "        [0.2762],\n",
            "        [0.0959],\n",
            "        [0.0259],\n",
            "        [0.7080],\n",
            "        [0.0400],\n",
            "        [0.2310],\n",
            "        [0.7622],\n",
            "        [0.9172],\n",
            "        [1.0000],\n",
            "        [0.2985],\n",
            "        [1.0000],\n",
            "        [0.4041],\n",
            "        [0.7114],\n",
            "        [0.0363],\n",
            "        [0.0141],\n",
            "        [0.2857],\n",
            "        [0.0458],\n",
            "        [0.2116],\n",
            "        [0.2152],\n",
            "        [0.2761],\n",
            "        [0.5560],\n",
            "        [0.1955],\n",
            "        [0.0223],\n",
            "        [0.0852],\n",
            "        [0.0292],\n",
            "        [0.0024],\n",
            "        [0.0104],\n",
            "        [0.0211],\n",
            "        [0.8732],\n",
            "        [0.1959],\n",
            "        [0.3845],\n",
            "        [0.1260],\n",
            "        [0.1769],\n",
            "        [0.2238],\n",
            "        [0.0428],\n",
            "        [0.1085],\n",
            "        [0.0677],\n",
            "        [0.5095],\n",
            "        [0.1454],\n",
            "        [0.9673],\n",
            "        [0.2472],\n",
            "        [0.1108],\n",
            "        [0.1216],\n",
            "        [0.1773],\n",
            "        [0.0987],\n",
            "        [0.2681],\n",
            "        [0.6009],\n",
            "        [0.1177],\n",
            "        [0.2673],\n",
            "        [0.1533],\n",
            "        [0.3452],\n",
            "        [0.0840],\n",
            "        [0.3269],\n",
            "        [0.2839],\n",
            "        [0.1793],\n",
            "        [0.9559],\n",
            "        [0.3155],\n",
            "        [0.1336],\n",
            "        [0.4224],\n",
            "        [0.6924],\n",
            "        [0.8656],\n",
            "        [0.4098],\n",
            "        [0.1198],\n",
            "        [0.1573]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsb--KW_I_F7"
      },
      "source": [
        "## 1.3 Model Creation [2pt]\n",
        "\n",
        "Construct a linear model with an SGD optimiser (we recommend a learning rate of `1e-4`) and mean squared error as the loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JEzbIGe4I_QK"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "# model and optimiser for prediction of article lenght \n",
        "linearRegression =  nn.Linear(len(Vocabulary),1)\n",
        "optimizer = torch.optim.SGD(linearRegression.parameters(), lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "I8jIGvPGWYkx"
      },
      "outputs": [],
      "source": [
        "# function used for calculating cost\n",
        "def mse(x1, x2):\n",
        "  diff = x1 - x2\n",
        "  return torch.sum(diff*diff)/diff.numel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjHulTA6JQ3z"
      },
      "source": [
        "## 1.4 Training [2pt]\n",
        "\n",
        "Write a loop to train your model for 100 epochs, printing performance on the dev set every 10 epochs."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this function trains specified model using specified optimizer for the number of epochs specified\n",
        "def training(model,optimizerForModel,no_of_epochs):\n",
        "  display_interval = no_of_epochs/10\n",
        "\n",
        "  for epoch in range(no_of_epochs):\n",
        "    predictions = model(x_data)\n",
        "    loss = mse(predictions, y_data)\n",
        "    loss.backward()\n",
        "    optimizerForModel.step() \n",
        "    optimizerForModel.zero_grad() \n",
        "    if epoch % display_interval == 0 :\n",
        "      # calculate the loss of the current model\n",
        "      predictions = model(x_dev_data)\n",
        "      loss = mse(predictions, y_dev_data)          \n",
        "      print(\"Epoch:\", '%04d' % (epoch), \"dev loss=\", \"{:.8f}\".format(loss))\n",
        "\n",
        "  print(\"=========================================================\")\n",
        "  training_loss = mse(model(x_data), y_data)   \n",
        "  print(\"Optimised:\", \"training loss=\", \"{:.9f}\".format(training_loss.data))\n",
        "  training_loss = mse(model(x_dev_data), y_dev_data)   \n",
        "  print(\"Optimised:\", \"dev loss=\", \"{:.9f}\".format(training_loss.data))\n",
        "  print(\"=========================================================\")"
      ],
      "metadata": {
        "id": "_z17k6g3ziFS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qPSx-srFR5km"
      },
      "outputs": [],
      "source": [
        "# populating variables used in training the model\n",
        "x_data = x_training_data_tensor.float()\n",
        "y_data = y_training_data_tensor.float()\n",
        "x_dev_data = x_dev_data_tensor.float()\n",
        "y_dev_data = y_dev_data_tensor.float()\n",
        "x_test_data = x_test_data_tensor.float()\n",
        "y_test_data = y_test_data_tensor.float()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####################################### Code for training model for 100 epochs, printing performance on the dev set every 10 epochs #######################################\n",
        "# model will run for 100 epochs\n",
        "%time training(linearRegression,optimizer,100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbNL20IEW9ce",
        "outputId": "85be58a4-dd0b-4c76-dae6-30ff60875223"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0000 dev loss= 0.16157503\n",
            "Epoch: 0010 dev loss= 0.12982070\n",
            "Epoch: 0020 dev loss= 0.11151215\n",
            "Epoch: 0030 dev loss= 0.10091813\n",
            "Epoch: 0040 dev loss= 0.09475143\n",
            "Epoch: 0050 dev loss= 0.09112658\n",
            "Epoch: 0060 dev loss= 0.08896209\n",
            "Epoch: 0070 dev loss= 0.08763759\n",
            "Epoch: 0080 dev loss= 0.08679716\n",
            "Epoch: 0090 dev loss= 0.08623658\n",
            "=========================================================\n",
            "Optimised: training loss= 0.087500580\n",
            "Optimised: dev loss= 0.085873276\n",
            "=========================================================\n",
            "CPU times: user 4.82 s, sys: 28.3 ms, total: 4.85 s\n",
            "Wall time: 4.97 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCwG22mOoyJ0"
      },
      "source": [
        "## 1.1 Measure Accuracy [2pt]\n",
        "\n",
        "In the code block below, write code to evaluate your model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this function evaluates specified model on test set\n",
        "def testing(model):\n",
        "  print(\"=========================================================\")\n",
        "  training_loss = mse(model(x_data), y_data)   \n",
        "  print(\"Optimised:\", \"training loss=\", \"{:.9f}\".format(training_loss.data))\n",
        "  training_loss = mse(model(x_dev_data), y_dev_data)   \n",
        "  print(\"Optimised:\", \"dev loss=\", \"{:.9f}\".format(training_loss.data))\n",
        "  print(\"=========================================================\")\n",
        "\n",
        "  # Calculating testing loss\n",
        "  testing_loss = mse(model(x_test_data), y_test_data) \n",
        "  print(\"Testing loss=\", \"{:.9f}\".format(testing_loss.data))\n",
        "  print(\"Absolute mean square loss difference:\", \"{:.9f}\".format(abs(training_loss.data - testing_loss.data)))"
      ],
      "metadata": {
        "id": "bCKYre8Ae9tB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################################### code to evaluate model on the test set. #######################################\n",
        "\n",
        "%time testing(linearRegression)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzbKda-1fUPp",
        "outputId": "71af0873-c9a7-4bf9-959a-ff8b109fb462"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================\n",
            "Optimised: training loss= 0.087500580\n",
            "Optimised: dev loss= 0.085873276\n",
            "=========================================================\n",
            "Testing loss= 0.079499044\n",
            "Absolute mean square loss difference: 0.006374232\n",
            "CPU times: user 39.1 ms, sys: 854 µs, total: 40 ms\n",
            "Wall time: 33.3 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TE7CMqZoylt"
      },
      "source": [
        "## 1.2 Analyse the Model [2pt]\n",
        "\n",
        "In the code block below, write code to identify the 50 words with the highest weights and the 50 words with the lowest weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "T4bmSbhhoy7d"
      },
      "outputs": [],
      "source": [
        "# Code to associate vocabulary element with respective weights \n",
        "weights_without_gradient = linearRegression.weight.detach()\n",
        "weights = weights_without_gradient.numpy()[0]\n",
        "dtype = [('word',numpy.object_),('weight',float)]\n",
        "values = []\n",
        "for i in range(0,len(Vocabulary)):\n",
        "  values.append((list(Vocabulary.keys())[i],weights[i]))\n",
        "important_words_with_weights_sorted = numpy.sort(numpy.array(values,dtype=dtype),order='weight')[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####################################### 50 words with the highest weights identified #######################################\n",
        "\n",
        "#words with highest weights\n",
        "important_words_with_weights_sorted[:50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eWHczZNcD0h",
        "outputId": "c17c79bf-bb47-4f00-fb94-08a2451f811d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([('of', 0.01702806), ('the', 0.01616932), ('in', 0.01288139),\n",
              "       ('at', 0.01243216), ('–', 0.01215785), ('all', 0.01212496),\n",
              "       ('creating', 0.01209114), ('confederate', 0.01208129),\n",
              "       ('fossils', 0.01208048), ('capacity', 0.012078  ),\n",
              "       ('centers', 0.01207101), ('thriller', 0.01206873),\n",
              "       ('confederation', 0.01206743), ('theatrical', 0.01205799),\n",
              "       ('attempts', 0.01205662), ('mya', 0.01205641),\n",
              "       ('ottoman', 0.01205078), ('straits', 0.01204906),\n",
              "       ('show', 0.0120482 ), ('long', 0.01204792), ('firm', 0.01204728),\n",
              "       ('measure', 0.01204004), ('count', 0.01203752),\n",
              "       ('davis', 0.01203716), ('improving', 0.01202694),\n",
              "       ('cathedral', 0.01201396), ('houses', 0.01199976),\n",
              "       ('economies', 0.01199922), ('america', 0.01199831),\n",
              "       ('basque', 0.01199717), ('taking', 0.01198024),\n",
              "       ('training', 0.01198005), ('dry', 0.01197861),\n",
              "       ('heart', 0.01197722), ('jerusalem', 0.01197718),\n",
              "       ('marshall', 0.01197248), ('capita', 0.01196873),\n",
              "       ('highway', 0.01196736), ('8th', 0.0119646 ),\n",
              "       ('column', 0.01196295), ('dealing', 0.01195742),\n",
              "       ('ethiopian', 0.01195306), ('michael', 0.01195054),\n",
              "       ('articles', 0.01194452), ('oldest', 0.01194078),\n",
              "       ('objectives', 0.01194043), ('psychiatrist', 0.01193448),\n",
              "       ('songwriter', 0.01192996), ('nor', 0.01192816),\n",
              "       ('nanp', 0.01192764)], dtype=[('word', 'O'), ('weight', '<f8')])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####################################### 50 words with the lowest weights identified #######################################\n",
        "\n",
        "#words with lowest weights\n",
        "important_words_with_weights_sorted[-50:][::-1]"
      ],
      "metadata": {
        "id": "ClN3NDCrU9Ke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdac6942-52c4-4042-ec06-359f365380bc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([('organised', -0.01206932), ('francesco', -0.01206626),\n",
              "       ('reserves', -0.01205936), ('2010', -0.01205783),\n",
              "       ('ritual', -0.01205778), ('1927', -0.01205746),\n",
              "       ('juice', -0.01205644), ('biography', -0.01205084),\n",
              "       ('1932', -0.01203747), ('emperors', -0.01203547),\n",
              "       ('operate', -0.01203311), ('laser', -0.01202521),\n",
              "       ('architecture', -0.01202202), ('becoming', -0.01202058),\n",
              "       ('projects', -0.01201517), ('wider', -0.01201157),\n",
              "       ('titled', -0.01200502), ('passing', -0.01199951),\n",
              "       ('holidays', -0.01199939), ('centres', -0.01199607),\n",
              "       ('advocates', -0.0119927 ), ('headquartered', -0.01198541),\n",
              "       ('caribbean', -0.01197631), ('missionary', -0.01197587),\n",
              "       ('theatre', -0.01197538), ('things', -0.01197077),\n",
              "       ('exploration', -0.01197059), ('question', -0.01197045),\n",
              "       ('harbours', -0.01196087), ('center', -0.01195694),\n",
              "       ('matches', -0.01195681), ('spaceflight', -0.01194841),\n",
              "       ('volume', -0.01194496), ('d.c.', -0.01194452),\n",
              "       ('bridges', -0.01193214), ('manhattan', -0.01192672),\n",
              "       ('lie', -0.01192125), ('foremost', -0.01191875),\n",
              "       ('130', -0.0119174 ), ('achievement', -0.01191451),\n",
              "       ('follow', -0.01191363), ('applications', -0.01191218),\n",
              "       ('month', -0.01191194), ('those', -0.01190005),\n",
              "       ('refer', -0.0118996 ), ('winner', -0.01189414),\n",
              "       ('dated', -0.01189301), ('them', -0.01188913),\n",
              "       ('swedish', -0.01188468), ('verification', -0.011879  )],\n",
              "      dtype=[('word', 'O'), ('weight', '<f8')])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5fxNtitbFck"
      },
      "source": [
        "# 2 - Compare Data Storage Methods\n",
        "\n",
        "This section relates to content from **the week 1 lecture and the week 2 lab**.\n",
        "\n",
        "Implement a variant of the model with a sparse vector for your input bag of words (See https://pytorch.org/docs/stable/sparse.html for how to switch a vector to be sparse). Use the default sparse vector type (COO)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jc7LbuE6bQjW"
      },
      "outputs": [],
      "source": [
        "# populating data for training model\n",
        "x_data = x_data.to_sparse()\n",
        "y_data = y_data.to_sparse()\n",
        "x_dev_data = x_dev_data.to_sparse()\n",
        "y_dev_data = y_dev_data.to_sparse()\n",
        "x_test_data = x_test_data.to_sparse()\n",
        "y_test_data = y_test_data.to_sparse()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('x_data_tensor',x_data)\n",
        "print('x_dev_data',x_dev_data)\n",
        "print('x_test_data',x_test_data)"
      ],
      "metadata": {
        "id": "SlwK0w-YWQ8t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1080c15b-e2b7-486a-e9de-20590a51ce6d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_data_tensor tensor(indices=tensor([[   0,    0,    0,  ..., 9858, 9858, 9858],\n",
            "                       [   0,    1,    2,  ..., 5188, 5702, 6707]]),\n",
            "       values=tensor([2., 3., 2.,  ..., 1., 1., 1.]),\n",
            "       size=(9859, 6853), nnz=527943, layout=torch.sparse_coo)\n",
            "x_dev_data tensor(indices=tensor([[   0,    0,    0,  ...,  993,  993,  993],\n",
            "                       [   5,    7,    8,  ..., 4240, 5386, 6623]]),\n",
            "       values=tensor([4., 1., 5.,  ..., 2., 1., 3.]),\n",
            "       size=(994, 6853), nnz=52662, layout=torch.sparse_coo)\n",
            "x_test_data tensor(indices=tensor([[   0,    0,    0,  ...,  990,  990,  990],\n",
            "                       [   1,    5,    8,  ..., 4802, 4803, 6057]]),\n",
            "       values=tensor([ 2.,  1., 10.,  ...,  1.,  1.,  1.]),\n",
            "       size=(991, 6853), nnz=52583, layout=torch.sparse_coo)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('y_data',y_data)\n",
        "print('y_dev_data',y_dev_data)\n",
        "print('y_test_data',y_test_data)"
      ],
      "metadata": {
        "id": "_cJw6YdsWR6S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e6d2149-4c01-4b7e-c6f4-5a4eaa6d5146"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_data tensor(indices=tensor([[   0,    1,    2,  ..., 9856, 9857, 9858],\n",
            "                       [   0,    0,    0,  ...,    0,    0,    0]]),\n",
            "       values=tensor([0.6453, 0.3528, 0.1265,  ..., 0.5215, 0.0191, 0.1101]),\n",
            "       size=(9859, 1), nnz=9859, layout=torch.sparse_coo)\n",
            "y_dev_data tensor(indices=tensor([[  0,   1,   2,  ..., 991, 992, 993],\n",
            "                       [  0,   0,   0,  ...,   0,   0,   0]]),\n",
            "       values=tensor([0.0552, 0.0999, 0.1331, 0.0461, 0.5329, 0.3803, 0.7429,\n",
            "                      0.3737, 0.1130, 0.4459, 0.8221, 0.5769, 0.0800, 0.0039,\n",
            "                      0.8192, 0.2340, 0.3241, 0.4813, 0.1308, 0.1061, 0.0964,\n",
            "                      0.4800, 0.3005, 0.4446, 0.6819, 0.0624, 0.0023, 0.6516,\n",
            "                      0.1084, 0.0338, 0.1668, 1.0000, 0.0378, 0.7162, 1.0000,\n",
            "                      0.4729, 0.1461, 0.0339, 0.1397, 0.0467, 0.0139, 0.1381,\n",
            "                      0.0618, 0.6992, 0.0825, 0.1998, 0.3397, 0.3242, 0.8384,\n",
            "                      0.6603, 0.1526, 0.4454, 0.5000, 0.1777, 0.3162, 0.4711,\n",
            "                      1.0000, 0.0682, 1.0000, 0.0045, 0.1025, 0.3801, 0.4676,\n",
            "                      1.0000, 0.0698, 0.1510, 0.1671, 0.9450, 1.0000, 1.0000,\n",
            "                      0.1527, 0.4708, 0.1268, 0.2870, 0.3339, 0.1383, 0.5040,\n",
            "                      0.0370, 0.1159, 0.2667, 0.6404, 0.7743, 0.7592, 0.5285,\n",
            "                      0.7861, 0.9499, 0.3047, 0.1033, 0.0131, 0.1359, 1.0000,\n",
            "                      0.6687, 0.3711, 0.0019, 0.1374, 0.0550, 0.4501, 0.0871,\n",
            "                      0.0251, 0.0958, 0.7153, 0.2709, 0.0938, 0.0630, 0.5334,\n",
            "                      0.7670, 0.2958, 1.0000, 0.0533, 0.1070, 1.0000, 0.2736,\n",
            "                      0.1435, 0.0660, 0.0499, 0.1667, 0.0373, 0.0993, 0.0466,\n",
            "                      0.3042, 0.1685, 0.0732, 0.0373, 0.0412, 1.0000, 0.1720,\n",
            "                      1.0000, 0.4960, 0.1058, 0.1516, 0.1190, 0.0278, 0.0161,\n",
            "                      0.0811, 0.0274, 0.2107, 0.2254, 0.0354, 0.0276, 0.2861,\n",
            "                      0.4141, 0.0063, 0.1041, 0.1422, 0.0026, 0.5488, 0.0083,\n",
            "                      1.0000, 1.0000, 0.1772, 0.1442, 0.6086, 0.1025, 0.1059,\n",
            "                      0.5772, 0.0464, 0.3392, 0.1572, 0.2298, 0.1472, 0.1704,\n",
            "                      0.1909, 0.5225, 0.5311, 0.0995, 1.0000, 0.9419, 0.2544,\n",
            "                      0.1917, 0.5731, 0.0576, 0.4418, 0.4653, 0.5705, 0.1428,\n",
            "                      0.2416, 0.9614, 0.1927, 0.2578, 1.0000, 0.0605, 0.8633,\n",
            "                      0.2742, 0.0922, 0.1719, 0.3184, 0.5352, 0.0855, 0.2844,\n",
            "                      0.6468, 0.2538, 0.6768, 0.1783, 0.1734, 1.0000, 0.1903,\n",
            "                      0.3684, 0.1791, 0.5791, 0.1715, 0.2113, 0.5502, 0.0636,\n",
            "                      0.9030, 0.9305, 0.0810, 0.5443, 0.1210, 0.0411, 0.0696,\n",
            "                      0.0202, 1.0000, 0.1869, 0.0955, 0.2788, 0.0526, 0.2637,\n",
            "                      0.2653, 0.5137, 0.2417, 0.5192, 0.0616, 0.0589, 0.2975,\n",
            "                      0.1366, 0.1460, 1.0000, 0.2907, 0.0478, 1.0000, 1.0000,\n",
            "                      0.8466, 1.0000, 0.5458, 0.0836, 0.0661, 0.5950, 0.1564,\n",
            "                      0.7383, 0.1482, 0.0874, 0.1036, 0.0136, 0.1710, 0.3181,\n",
            "                      0.0932, 0.1279, 0.0738, 0.5986, 0.1309, 0.5684, 0.4329,\n",
            "                      0.4022, 0.0509, 1.0000, 0.0930, 0.3622, 0.6285, 0.0204,\n",
            "                      0.0400, 0.4648, 0.4888, 0.0746, 0.5997, 0.1226, 0.1428,\n",
            "                      1.0000, 0.2761, 0.8673, 0.5736, 0.0904, 0.2847, 0.1933,\n",
            "                      0.9925, 0.0530, 1.0000, 0.3818, 0.1926, 0.2347, 0.0495,\n",
            "                      0.1507, 0.0944, 0.6934, 0.3214, 0.0658, 0.4168, 0.0598,\n",
            "                      0.0755, 0.3732, 0.1074, 0.1907, 0.0793, 0.0125, 0.6042,\n",
            "                      0.2933, 0.0921, 0.1638, 0.5166, 0.1108, 0.1479, 0.6797,\n",
            "                      0.0729, 0.3447, 0.1113, 0.0074, 0.3192, 0.0732, 0.4896,\n",
            "                      0.0898, 0.2058, 0.1809, 0.4949, 0.1215, 0.5396, 0.3673,\n",
            "                      0.4221, 0.5566, 0.1831, 0.1356, 0.1146, 0.2202, 0.0026,\n",
            "                      0.2610, 0.3612, 0.2210, 0.0115, 0.1540, 0.1382, 0.0398,\n",
            "                      0.2324, 0.0707, 0.2244, 0.3915, 0.7267, 0.0852, 0.9519,\n",
            "                      0.8890, 1.0000, 0.0270, 0.8057, 0.2766, 1.0000, 0.3670,\n",
            "                      0.5905, 0.8443, 0.0209, 0.0020, 0.4240, 0.1114, 0.2551,\n",
            "                      1.0000, 0.1128, 0.0226, 0.0706, 0.1425, 0.5396, 0.2499,\n",
            "                      0.4385, 0.0569, 0.7493, 0.4873, 1.0000, 0.0396, 0.0212,\n",
            "                      0.0917, 0.4900, 0.3780, 0.9537, 0.5273, 0.5015, 0.4526,\n",
            "                      0.6640, 0.9036, 0.6609, 0.6129, 0.0723, 0.4331, 0.6472,\n",
            "                      0.3413, 0.1697, 0.5351, 0.3211, 0.0349, 0.1421, 0.0347,\n",
            "                      0.1976, 1.0000, 0.9426, 0.3868, 0.0022, 0.9736, 0.5517,\n",
            "                      1.0000, 0.0039, 0.4918, 0.4659, 1.0000, 0.4971, 1.0000,\n",
            "                      0.6098, 0.1030, 0.1271, 0.4269, 0.7659, 0.4114, 0.3915,\n",
            "                      0.4465, 0.2480, 0.0216, 0.0492, 0.0514, 0.0448, 0.1160,\n",
            "                      0.0409, 0.0487, 0.0296, 0.1258, 0.0222, 0.0288, 0.0175,\n",
            "                      0.0245, 0.0724, 0.0415, 0.0395, 0.0638, 0.0335, 0.0989,\n",
            "                      0.0658, 0.2023, 0.0483, 0.0398, 0.0274, 0.0792, 0.0168,\n",
            "                      0.1511, 0.0379, 0.2555, 0.1387, 0.1587, 0.8037, 0.7510,\n",
            "                      0.0354, 0.4384, 0.6548, 0.1266, 0.1825, 0.1372, 0.1137,\n",
            "                      0.0497, 0.0733, 0.2562, 0.3874, 0.3403, 0.0549, 0.0350,\n",
            "                      0.4400, 0.0963, 0.8298, 0.2418, 0.4063, 0.0360, 0.1896,\n",
            "                      1.0000, 0.6663, 0.4688, 0.5476, 0.3494, 0.4552, 1.0000,\n",
            "                      0.2076, 0.7823, 0.3434, 0.4403, 0.0955, 0.5256, 0.2341,\n",
            "                      0.0605, 0.1107, 0.0388, 0.0744, 1.0000, 0.1375, 0.0163,\n",
            "                      0.5064, 0.7643, 0.0667, 0.1421, 0.0856, 0.1714, 0.1683,\n",
            "                      0.2343, 0.0763, 0.4178, 0.0972, 0.2800, 0.0735, 0.2085,\n",
            "                      0.2189, 0.3422, 0.1604, 0.9719, 1.0000, 0.4589, 0.2066,\n",
            "                      0.0417, 0.1853, 0.0815, 0.0218, 0.2330, 0.0394, 0.2955,\n",
            "                      0.3204, 0.5487, 0.1723, 0.2869, 0.3066, 0.3998, 0.6446,\n",
            "                      0.3397, 0.2826, 0.3616, 0.3954, 0.4052, 0.2708, 0.1449,\n",
            "                      1.0000, 0.1041, 0.7139, 0.1893, 0.2629, 0.4443, 0.7169,\n",
            "                      1.0000, 0.2719, 0.0344, 0.0747, 0.0717, 0.4316, 0.7741,\n",
            "                      0.0089, 0.0638, 1.0000, 0.2871, 0.2995, 0.4347, 0.7895,\n",
            "                      0.1105, 0.2477, 0.8325, 0.2359, 0.5043, 0.3333, 0.1594,\n",
            "                      0.0142, 0.0622, 0.0902, 0.0113, 0.5932, 0.7026, 0.1338,\n",
            "                      0.0638, 0.0552, 0.1671, 0.0713, 0.0344, 0.3230, 0.0671,\n",
            "                      0.0612, 0.1337, 0.0247, 0.0798, 0.3528, 0.5027, 0.7039,\n",
            "                      1.0000, 0.2878, 0.0700, 0.0375, 0.6571, 0.0395, 0.0462,\n",
            "                      0.1186, 0.0335, 1.0000, 0.2144, 0.2182, 0.2033, 0.6828,\n",
            "                      0.0766, 0.0718, 0.0861, 0.0228, 0.9964, 1.0000, 0.3780,\n",
            "                      0.2425, 0.9091, 0.8175, 0.1943, 0.3286, 0.7354, 0.0882,\n",
            "                      0.5753, 0.0409, 0.0600, 0.1799, 0.2281, 0.5863, 0.0145,\n",
            "                      0.1333, 0.1519, 0.5058, 0.2329, 0.0166, 0.0221, 0.2844,\n",
            "                      0.6261, 1.0000, 0.0738, 0.3613, 0.1427, 0.1559, 0.4143,\n",
            "                      0.0767, 0.3595, 0.0934, 0.0290, 0.6909, 1.0000, 0.2044,\n",
            "                      0.8456, 0.1570, 0.6457, 0.0064, 0.1708, 0.0633, 0.9418,\n",
            "                      0.0281, 0.0086, 0.6039, 0.2846, 0.2821, 0.0696, 0.2283,\n",
            "                      0.2939, 0.1087, 0.4184, 0.5101, 0.7152, 0.0320, 0.0797,\n",
            "                      1.0000, 0.2391, 0.0575, 0.3524, 0.3337, 0.1137, 0.2390,\n",
            "                      0.2283, 0.1761, 0.1389, 0.4430, 0.0732, 0.1607, 1.0000,\n",
            "                      0.5644, 0.1314, 0.4022, 0.2799, 0.3263, 0.2987, 0.1683,\n",
            "                      0.9467, 0.4441, 0.5954, 0.0029, 0.1493, 0.0576, 0.5446,\n",
            "                      0.3687, 0.1442, 0.1071, 0.1420, 0.2088, 0.5777, 1.0000,\n",
            "                      0.3677, 0.0383, 0.0233, 0.0387, 0.6148, 0.1195, 0.1067,\n",
            "                      0.1600, 0.0390, 1.0000, 0.0653, 0.3330, 0.1188, 0.2913,\n",
            "                      0.0309, 0.1120, 0.1799, 0.1419, 0.1202, 0.4585, 0.0171,\n",
            "                      0.0464, 0.5838, 0.0470, 0.1685, 0.2367, 0.7918, 0.1420,\n",
            "                      0.1547, 0.6156, 0.1110, 0.3763, 0.0450, 0.1245, 0.1499,\n",
            "                      0.1167, 0.3048, 0.2895, 0.0027, 0.1653, 0.3833, 0.1507,\n",
            "                      0.0118, 0.0961, 0.4322, 0.2814, 0.4466, 0.0375, 0.4953,\n",
            "                      0.7260, 0.2629, 0.1448, 0.1251, 0.5530, 0.6276, 0.4577,\n",
            "                      0.3861, 0.0430, 0.1478, 0.1538, 0.3511, 0.3679, 0.1860,\n",
            "                      0.1101, 1.0000, 0.3395, 0.4292, 0.0981, 0.0090, 0.4104,\n",
            "                      0.5419, 0.2914, 1.0000, 0.1407, 0.7847, 0.2228, 0.0143,\n",
            "                      0.0894, 0.1893, 0.0037, 0.6113, 0.0227, 0.0198, 0.0371,\n",
            "                      0.5014, 0.3955, 0.1643, 0.4345, 0.0717, 0.3588, 0.1890,\n",
            "                      0.6763, 0.3267, 0.1317, 0.0452, 0.2685, 0.1480, 0.0739,\n",
            "                      0.0422, 0.1160, 0.1466, 1.0000, 0.2060, 0.6097, 1.0000,\n",
            "                      0.0402, 0.0840, 0.0543, 0.0168, 0.0684, 0.3268, 0.0292,\n",
            "                      0.0668, 0.5577, 0.1656, 0.3260, 0.0381, 0.0306, 0.0729,\n",
            "                      1.0000, 0.0880, 0.0707, 0.1630, 0.0152, 0.0362, 0.0739,\n",
            "                      0.0191, 0.1827, 0.5474, 0.0467, 0.7092, 0.1145, 0.1154,\n",
            "                      0.2286, 0.0778, 0.4654, 0.1575, 0.1722, 0.1941, 0.2205,\n",
            "                      0.0431, 0.3764, 0.3930, 0.0414, 0.0406, 1.0000, 0.4400,\n",
            "                      0.0989, 0.0644, 0.0305, 0.4770, 1.0000, 0.0738, 0.0432,\n",
            "                      0.1729, 0.1052, 0.1339, 0.2162, 0.0409, 0.0209, 0.0511,\n",
            "                      0.0054, 0.0547, 0.1053, 0.3648, 0.9354, 0.4095, 0.5391,\n",
            "                      0.5209, 0.0213, 0.0784, 1.0000, 0.0097, 1.0000, 0.0393,\n",
            "                      0.8295, 0.3003, 0.0799, 0.2739, 0.1823, 0.6535, 0.1375,\n",
            "                      0.5236, 0.0345, 0.0316, 0.1064, 0.1611, 0.0916, 0.0586,\n",
            "                      0.0865, 0.7904, 0.1418, 0.1393, 0.4854, 0.3130, 0.0940,\n",
            "                      0.1205, 0.2234, 0.3264, 0.2004, 0.0691, 0.1346, 0.1029,\n",
            "                      0.0401, 0.1285, 0.0555, 0.2742, 0.6522, 0.1536, 0.2144,\n",
            "                      0.0106, 0.0881, 0.6326, 0.0255, 0.0297, 0.0342, 0.0823,\n",
            "                      0.0510, 0.0378, 0.0410, 0.1058, 0.1704, 0.0728, 0.1260,\n",
            "                      0.3938, 0.1562, 0.5025, 0.9346, 0.1655, 0.6490, 1.0000,\n",
            "                      0.0665, 0.0022, 0.5275, 0.1905, 0.0442, 0.5409, 0.1910,\n",
            "                      0.4206, 0.0203, 0.0966, 0.0752, 0.0176, 0.0521, 0.0579,\n",
            "                      0.0392, 0.0131, 0.1045, 0.5853, 0.1313, 0.1621, 0.1919,\n",
            "                      0.2930, 0.1693, 0.0606, 0.2769, 0.1252, 0.1136, 0.2492,\n",
            "                      0.2440, 0.7159, 0.4882, 0.3176, 0.2892, 0.1437, 0.2928,\n",
            "                      0.1700, 0.7412, 0.9296, 1.0000, 0.6531, 0.1073, 0.0702,\n",
            "                      0.0782, 0.1016, 0.1579, 0.3720, 0.3677, 0.3498, 0.4528,\n",
            "                      0.1867, 0.9082, 0.1292, 0.1013, 0.3027, 0.2353, 0.5917,\n",
            "                      0.1775, 0.5195, 0.1134, 0.2188, 0.1856, 0.1123, 0.6131,\n",
            "                      0.6980, 0.0725, 0.5260, 0.3009, 0.1999, 0.1379, 1.0000,\n",
            "                      0.2219, 0.2032, 0.2687, 0.1390, 0.3186, 0.1686, 0.1953]),\n",
            "       size=(994, 1), nnz=994, layout=torch.sparse_coo)\n",
            "y_test_data tensor(indices=tensor([[  0,   1,   2,  ..., 988, 989, 990],\n",
            "                       [  0,   0,   0,  ...,   0,   0,   0]]),\n",
            "       values=tensor([0.2905, 0.4138, 0.0558, 0.0634, 0.0414, 0.0571, 0.2096,\n",
            "                      0.3854, 0.2260, 0.1627, 0.4779, 1.0000, 0.8417, 0.4917,\n",
            "                      0.1004, 0.7282, 0.3487, 0.2106, 0.1163, 0.1497, 0.3482,\n",
            "                      0.0969, 0.1787, 0.0840, 0.1663, 0.1318, 0.2430, 0.1366,\n",
            "                      0.1876, 0.0432, 0.0761, 0.0632, 0.3013, 0.5176, 0.6209,\n",
            "                      0.0202, 0.1058, 1.0000, 0.1024, 0.3109, 0.1410, 0.0759,\n",
            "                      0.1623, 0.1526, 0.2695, 0.3350, 0.1012, 0.0670, 0.1031,\n",
            "                      0.1988, 0.2438, 0.0645, 0.1019, 0.1207, 0.0450, 0.0857,\n",
            "                      0.1981, 0.1901, 0.4734, 0.3259, 0.5425, 0.0714, 0.5765,\n",
            "                      0.4959, 0.0094, 0.9576, 0.2494, 0.0191, 0.0207, 0.1148,\n",
            "                      0.0868, 0.1217, 0.3807, 0.4320, 0.6002, 0.0745, 0.0402,\n",
            "                      0.0381, 0.0341, 0.2083, 0.1927, 0.1915, 0.3305, 0.0717,\n",
            "                      0.2285, 0.0482, 0.0984, 0.4014, 0.0396, 0.0612, 0.3275,\n",
            "                      0.2901, 0.1572, 0.0716, 0.5070, 0.4909, 0.1147, 0.2071,\n",
            "                      0.1169, 0.0808, 0.0394, 0.0497, 0.0473, 0.2616, 0.1531,\n",
            "                      0.2614, 0.4656, 1.0000, 0.3236, 0.0381, 0.2265, 0.0614,\n",
            "                      0.0415, 0.0376, 0.0255, 0.0751, 0.2396, 0.1029, 0.0383,\n",
            "                      0.2123, 0.0393, 0.4627, 0.1200, 0.2774, 0.8199, 0.1181,\n",
            "                      0.0667, 0.4591, 0.3566, 0.3264, 0.5491, 0.0076, 0.4509,\n",
            "                      0.2040, 0.1600, 0.0646, 0.0454, 0.1099, 0.0997, 0.1874,\n",
            "                      0.0126, 0.2367, 0.3920, 0.1122, 0.0362, 0.3079, 0.0974,\n",
            "                      0.2129, 0.0347, 0.6693, 0.6996, 1.0000, 0.0024, 0.7431,\n",
            "                      0.1548, 0.3637, 0.0655, 0.1733, 0.2460, 0.0907, 0.0999,\n",
            "                      0.3283, 0.1964, 0.0550, 0.4847, 0.5815, 0.0146, 0.0722,\n",
            "                      0.0898, 0.4501, 0.4386, 0.1549, 0.3573, 0.3442, 0.2468,\n",
            "                      0.2733, 0.0047, 0.4323, 0.4736, 1.0000, 0.0478, 0.1609,\n",
            "                      0.7323, 0.0220, 0.0260, 0.0409, 0.0581, 0.2917, 0.0709,\n",
            "                      0.0318, 0.0035, 0.0051, 0.1708, 0.2498, 0.7912, 0.0979,\n",
            "                      1.0000, 0.3806, 0.1529, 0.2142, 0.1303, 0.1900, 0.1355,\n",
            "                      0.7581, 0.2362, 0.2900, 0.4483, 0.9900, 0.0384, 0.0726,\n",
            "                      0.3724, 0.4604, 0.1505, 0.0703, 0.8946, 0.1741, 0.6558,\n",
            "                      0.0129, 0.2217, 0.3803, 0.1291, 0.3616, 0.0353, 0.0391,\n",
            "                      0.2902, 0.1158, 0.1629, 0.0699, 0.0265, 1.0000, 0.0830,\n",
            "                      0.3402, 0.1002, 0.8251, 0.1671, 0.1885, 0.0022, 0.6669,\n",
            "                      0.6698, 0.0665, 0.0937, 0.2486, 0.2830, 1.0000, 0.2115,\n",
            "                      0.6577, 0.8638, 0.6452, 0.3605, 0.0064, 0.0978, 0.0552,\n",
            "                      0.2200, 0.5453, 0.1490, 0.0373, 0.2637, 0.2501, 0.1805,\n",
            "                      0.2414, 0.0137, 0.7147, 0.4024, 0.2233, 0.0974, 0.4258,\n",
            "                      0.1569, 0.1793, 0.3297, 0.0870, 0.2088, 0.0762, 0.1747,\n",
            "                      0.3548, 0.1214, 0.3002, 0.1897, 0.4681, 0.0633, 0.0756,\n",
            "                      0.4083, 0.0673, 0.4281, 0.0492, 0.2128, 0.0999, 0.1571,\n",
            "                      0.1993, 0.2387, 0.1563, 0.1363, 0.3970, 0.0250, 0.4429,\n",
            "                      0.1005, 0.1046, 0.1660, 0.0113, 0.1196, 0.0740, 0.1615,\n",
            "                      0.0513, 0.1033, 0.1496, 0.0524, 0.0654, 0.0763, 0.0911,\n",
            "                      0.4934, 0.1520, 0.5364, 0.2513, 0.2667, 0.1155, 0.6917,\n",
            "                      0.1897, 0.4272, 0.1916, 0.1487, 0.1962, 0.2396, 0.2856,\n",
            "                      0.0476, 0.2017, 0.2115, 0.1002, 0.0037, 0.0050, 0.0036,\n",
            "                      0.0607, 0.1948, 0.4711, 0.2258, 0.0834, 0.0165, 0.0978,\n",
            "                      0.7646, 0.0269, 0.5491, 0.0389, 0.7723, 0.1679, 0.0201,\n",
            "                      0.3911, 0.3414, 0.0985, 0.1994, 0.0367, 0.0427, 0.1667,\n",
            "                      0.6906, 0.4803, 0.0545, 0.5769, 0.0428, 0.0021, 0.2898,\n",
            "                      0.1730, 0.0153, 0.0210, 0.3894, 0.1854, 0.0516, 0.2722,\n",
            "                      0.3443, 0.1148, 0.4934, 1.0000, 0.5383, 0.1455, 0.2760,\n",
            "                      0.0028, 0.1421, 0.3106, 0.4408, 0.0960, 0.2385, 0.8496,\n",
            "                      0.2474, 0.2162, 0.4042, 0.1009, 0.2154, 0.0889, 0.0663,\n",
            "                      0.7277, 0.2739, 0.0870, 0.3906, 0.2752, 0.3292, 0.2592,\n",
            "                      0.1591, 0.3442, 0.1681, 0.4459, 0.3542, 0.4263, 0.0800,\n",
            "                      0.3990, 0.3342, 0.3115, 0.0710, 0.1136, 0.0623, 0.1175,\n",
            "                      0.1139, 0.0421, 0.0958, 0.6308, 0.2213, 0.1770, 0.0563,\n",
            "                      0.1296, 0.6989, 0.1038, 0.0892, 0.2267, 0.0548, 0.7630,\n",
            "                      0.0263, 0.3782, 0.0946, 0.8948, 0.8158, 0.1882, 0.9363,\n",
            "                      0.0693, 0.4388, 0.0809, 0.1139, 0.2955, 0.1044, 0.2508,\n",
            "                      0.8290, 0.0637, 0.1320, 0.0382, 0.4277, 0.1713, 0.4515,\n",
            "                      0.1211, 0.0703, 0.3160, 0.1439, 0.3067, 1.0000, 0.5652,\n",
            "                      0.2088, 0.4383, 0.0696, 0.0551, 0.3407, 0.4540, 0.6390,\n",
            "                      0.6172, 0.1149, 0.2921, 0.1667, 0.7880, 0.9166, 0.1608,\n",
            "                      0.3438, 0.0675, 0.0427, 0.0031, 0.0656, 0.1080, 0.0447,\n",
            "                      0.1571, 0.1522, 0.8334, 0.0600, 0.0564, 0.1052, 0.2234,\n",
            "                      0.0549, 0.0563, 1.0000, 0.7691, 0.3375, 0.0387, 0.4271,\n",
            "                      0.1287, 0.0882, 0.2780, 0.1247, 0.0581, 0.1767, 0.2115,\n",
            "                      0.6352, 0.2878, 0.0602, 1.0000, 0.3529, 0.1817, 0.1019,\n",
            "                      0.3930, 0.0609, 0.5716, 0.1380, 0.0528, 0.0726, 1.0000,\n",
            "                      0.1635, 0.0899, 0.6695, 0.0930, 0.0329, 0.0640, 0.0723,\n",
            "                      0.3651, 0.2055, 0.2768, 0.6159, 0.1454, 0.4062, 0.0988,\n",
            "                      0.0151, 0.1494, 0.2207, 0.4739, 0.5913, 0.0646, 0.2138,\n",
            "                      0.2294, 0.1562, 0.2331, 0.0083, 0.0346, 0.0035, 0.1289,\n",
            "                      0.3022, 0.1016, 0.0571, 0.7405, 0.1064, 0.3778, 0.0906,\n",
            "                      0.3961, 0.1140, 0.1763, 0.1190, 0.8663, 0.1318, 0.0657,\n",
            "                      0.2610, 0.2635, 0.0218, 0.0622, 0.1012, 0.1834, 0.0973,\n",
            "                      0.2746, 0.6565, 0.3646, 0.1873, 0.0958, 0.2886, 0.1409,\n",
            "                      0.7882, 0.3627, 0.3659, 0.2959, 0.5024, 0.2041, 0.2827,\n",
            "                      0.1028, 0.3271, 0.4351, 0.2734, 0.0868, 0.0434, 0.7601,\n",
            "                      0.4859, 0.0898, 0.0343, 0.1080, 0.0026, 0.1511, 0.0408,\n",
            "                      0.7346, 0.0364, 0.1725, 0.0418, 0.3718, 0.1438, 0.7239,\n",
            "                      0.4759, 0.4037, 0.1645, 0.0528, 0.4105, 0.2687, 0.5844,\n",
            "                      0.2843, 0.4874, 0.0639, 0.5438, 0.1183, 0.2572, 0.1292,\n",
            "                      0.0502, 0.2799, 0.0220, 0.0551, 0.1749, 1.0000, 0.2985,\n",
            "                      0.2746, 0.1210, 0.2282, 0.1563, 0.0044, 0.0947, 0.0024,\n",
            "                      0.0898, 0.6397, 0.1816, 0.1595, 0.0505, 0.0332, 0.2777,\n",
            "                      0.2316, 0.4605, 0.4327, 0.9659, 1.0000, 0.5618, 1.0000,\n",
            "                      0.2377, 1.0000, 0.2695, 0.2265, 1.0000, 0.8716, 0.9072,\n",
            "                      0.4918, 0.7141, 0.6613, 0.1570, 0.0376, 0.7293, 1.0000,\n",
            "                      0.0412, 0.9940, 0.7583, 0.6002, 0.9257, 1.0000, 0.2289,\n",
            "                      0.4206, 1.0000, 0.2817, 1.0000, 0.8942, 0.2719, 0.4605,\n",
            "                      0.4810, 1.0000, 0.3921, 0.0718, 1.0000, 0.1449, 0.0614,\n",
            "                      0.4447, 0.1322, 0.0595, 0.0228, 0.1957, 0.5333, 0.5391,\n",
            "                      0.5046, 0.0473, 0.0665, 0.0315, 0.1070, 0.0525, 0.0399,\n",
            "                      0.0603, 0.0274, 0.4739, 1.0000, 0.4302, 0.2647, 0.6847,\n",
            "                      0.0183, 0.4492, 0.7767, 0.4579, 0.6582, 1.0000, 0.2856,\n",
            "                      0.1948, 0.9992, 0.1265, 0.6090, 0.6852, 0.3240, 0.2183,\n",
            "                      0.0434, 0.3677, 0.2207, 0.3095, 0.2036, 0.4368, 0.2408,\n",
            "                      0.7867, 0.2307, 0.0076, 0.0100, 0.0456, 1.0000, 1.0000,\n",
            "                      0.0895, 0.1237, 1.0000, 0.1877, 0.0228, 0.0620, 0.0360,\n",
            "                      0.0190, 0.0359, 1.0000, 0.1933, 0.1422, 0.4407, 0.3850,\n",
            "                      0.4445, 0.1076, 0.0118, 0.9129, 0.0531, 0.1282, 0.2476,\n",
            "                      0.0889, 0.1460, 0.0403, 0.3762, 0.4222, 0.8270, 0.5851,\n",
            "                      0.3215, 0.1072, 0.4636, 0.1054, 0.8156, 0.7890, 0.6570,\n",
            "                      0.3806, 0.3416, 0.4413, 0.1779, 0.4075, 0.2169, 1.0000,\n",
            "                      0.4967, 0.4373, 0.1869, 0.4829, 0.6098, 0.0657, 0.9624,\n",
            "                      0.0498, 0.5223, 0.7793, 0.1453, 0.0397, 0.6209, 0.4188,\n",
            "                      0.0990, 1.0000, 0.4010, 0.4813, 0.3114, 0.2604, 1.0000,\n",
            "                      0.1772, 0.2613, 0.1874, 0.2576, 0.0025, 0.6538, 0.5346,\n",
            "                      0.0989, 0.1428, 0.3265, 0.9017, 0.0539, 0.4693, 0.3366,\n",
            "                      0.2103, 0.2440, 0.0706, 0.5123, 0.9074, 0.5136, 0.7793,\n",
            "                      0.2562, 0.1391, 0.4527, 0.0129, 0.6433, 0.0171, 0.3953,\n",
            "                      0.2413, 0.0738, 1.0000, 0.1853, 0.3294, 0.7567, 0.1775,\n",
            "                      0.1036, 1.0000, 0.3665, 0.9694, 0.1885, 0.0317, 0.2455,\n",
            "                      0.6648, 0.4269, 0.2590, 0.2987, 0.9532, 0.0826, 0.0408,\n",
            "                      0.7859, 0.4450, 0.7816, 0.0473, 0.0377, 0.1943, 0.1328,\n",
            "                      0.0661, 0.5315, 0.1037, 0.1577, 0.5936, 0.1237, 0.2647,\n",
            "                      0.1817, 0.8354, 0.1770, 0.1607, 0.3526, 0.5014, 0.5175,\n",
            "                      0.3798, 0.0930, 0.5243, 0.5124, 0.0924, 0.4939, 0.5563,\n",
            "                      0.3920, 0.2285, 0.4212, 0.1723, 0.6358, 0.9434, 0.0982,\n",
            "                      0.0228, 0.2217, 0.1136, 0.4089, 1.0000, 1.0000, 0.0437,\n",
            "                      0.1724, 0.6244, 0.1964, 0.3551, 0.2972, 0.2562, 0.2121,\n",
            "                      0.0501, 0.6816, 0.5989, 0.6726, 0.2104, 0.2923, 0.1058,\n",
            "                      0.2335, 0.2196, 0.1930, 0.2590, 0.0788, 0.4757, 0.1454,\n",
            "                      0.1190, 0.2494, 0.4061, 0.0910, 0.4658, 0.1930, 0.6326,\n",
            "                      0.4888, 0.1005, 0.2478, 0.0018, 0.2249, 0.7536, 0.1505,\n",
            "                      0.1553, 0.3978, 0.4769, 0.2891, 0.1654, 1.0000, 0.2052,\n",
            "                      0.0638, 0.5705, 0.1071, 0.4708, 0.6598, 0.1951, 0.2322,\n",
            "                      0.2209, 0.3357, 0.1046, 0.7737, 0.1274, 0.0779, 0.1069,\n",
            "                      0.7015, 0.9708, 0.1301, 0.2762, 0.0959, 0.0259, 0.7080,\n",
            "                      0.0400, 0.2310, 0.7622, 0.9172, 1.0000, 0.2985, 1.0000,\n",
            "                      0.4041, 0.7114, 0.0363, 0.0141, 0.2857, 0.0458, 0.2116,\n",
            "                      0.2152, 0.2761, 0.5560, 0.1955, 0.0223, 0.0852, 0.0292,\n",
            "                      0.0024, 0.0104, 0.0211, 0.8732, 0.1959, 0.3845, 0.1260,\n",
            "                      0.1769, 0.2238, 0.0428, 0.1085, 0.0677, 0.5095, 0.1454,\n",
            "                      0.9673, 0.2472, 0.1108, 0.1216, 0.1773, 0.0987, 0.2681,\n",
            "                      0.6009, 0.1177, 0.2673, 0.1533, 0.3452, 0.0840, 0.3269,\n",
            "                      0.2839, 0.1793, 0.9559, 0.3155, 0.1336, 0.4224, 0.6924,\n",
            "                      0.8656, 0.4098, 0.1198, 0.1573]),\n",
            "       size=(991, 1), nnz=991, layout=torch.sparse_coo)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creation of model that will be trained using sparse vectors\n",
        "linearRegressionForSparce =  nn.Linear(len(Vocabulary),1)\n",
        "optimizerForSparce = torch.optim.SGD(linearRegressionForSparce.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "xYgtFatT2tw6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkAPEr91qBTG"
      },
      "source": [
        "## 2.1 Training and Test Speed [2pt]\n",
        "Compare the time it takes to train and test the new model with the time it takes to train and test the old model.\n",
        "\n",
        "You can time the execution of a line of code using `%time`.\n",
        "See [this guide](https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/01.07-Timing-and-Profiling.ipynb#scrollTo=z1gyaC_PNZUB) for more on timing."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# recording time to train a model with saprce vectors as input\n",
        "%time training(linearRegressionForSparce,optimizerForSparce,100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNGtgCPJX1Ms",
        "outputId": "464093a8-ad9a-46ef-f271-2af3fffddcc0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0000 dev loss= 0.30211979\n",
            "Epoch: 0010 dev loss= 0.21018898\n",
            "Epoch: 0020 dev loss= 0.15715803\n",
            "Epoch: 0030 dev loss= 0.12649871\n",
            "Epoch: 0040 dev loss= 0.10871670\n",
            "Epoch: 0050 dev loss= 0.09835556\n",
            "Epoch: 0060 dev loss= 0.09227756\n",
            "Epoch: 0070 dev loss= 0.08867680\n",
            "Epoch: 0080 dev loss= 0.08651288\n",
            "Epoch: 0090 dev loss= 0.08518549\n",
            "=========================================================\n",
            "Optimised: training loss= 0.084280558\n",
            "Optimised: dev loss= 0.084415913\n",
            "=========================================================\n",
            "CPU times: user 3.02 s, sys: 9.89 ms, total: 3.03 s\n",
            "Wall time: 3.04 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# recording time to test a model with sparce vectors as input\n",
        "%time testing(linearRegressionForSparce)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSz-wW5Tfg6J",
        "outputId": "11104336-cc08-4b3b-87e7-403c58d0a1a0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================\n",
            "Optimised: training loss= 0.084280558\n",
            "Optimised: dev loss= 0.084415913\n",
            "=========================================================\n",
            "Testing loss= 0.075273253\n",
            "Absolute mean square loss difference: 0.009142660\n",
            "CPU times: user 22.1 ms, sys: 1.96 ms, total: 24.1 ms\n",
            "Wall time: 24.4 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# populating variables used in training the model the model in section 1\n",
        "x_data = x_training_data_tensor.float()\n",
        "y_data = y_training_data_tensor.float()\n",
        "x_dev_data = x_dev_data_tensor.float()\n",
        "y_dev_data = y_dev_data_tensor.float()\n",
        "x_test_data = x_test_data_tensor.float()\n",
        "y_test_data = y_test_data_tensor.float()"
      ],
      "metadata": {
        "id": "Fqd5DFOUmo6M"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reinitializing the model is used in section 1\n",
        "linearRegression =  nn.Linear(len(Vocabulary),1)\n",
        "optimizer = torch.optim.SGD(linearRegression.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "L-Jj9sEVmwpi"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# recording time to train a model in section 1\n",
        "%time training(linearRegression,optimizer,100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR_-e2zMnf7S",
        "outputId": "618834c1-7e0f-4dcc-8185-00f8366dd053"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0000 dev loss= 0.26912254\n",
            "Epoch: 0010 dev loss= 0.19174317\n",
            "Epoch: 0020 dev loss= 0.14729714\n",
            "Epoch: 0030 dev loss= 0.12173622\n",
            "Epoch: 0040 dev loss= 0.10700449\n",
            "Epoch: 0050 dev loss= 0.09848249\n",
            "Epoch: 0060 dev loss= 0.09352167\n",
            "Epoch: 0070 dev loss= 0.09060355\n",
            "Epoch: 0080 dev loss= 0.08885767\n",
            "Epoch: 0090 dev loss= 0.08778510\n",
            "=========================================================\n",
            "Optimised: training loss= 0.087428689\n",
            "Optimised: dev loss= 0.087156363\n",
            "=========================================================\n",
            "CPU times: user 4.72 s, sys: 21 ms, total: 4.75 s\n",
            "Wall time: 4.74 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# recording time to test a model in section 1\n",
        "%time testing(linearRegression)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKJ8_QUZnnAQ",
        "outputId": "f30572db-4a1d-4386-f21b-a51b4dc5501d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================\n",
            "Optimised: training loss= 0.087428689\n",
            "Optimised: dev loss= 0.087156363\n",
            "=========================================================\n",
            "Testing loss= 0.078067541\n",
            "Absolute mean square loss difference: 0.009088822\n",
            "CPU times: user 36.8 ms, sys: 1.97 ms, total: 38.7 ms\n",
            "Wall time: 33.5 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On comparing the training time and testing time recorded for model created section 1 (model using dense vectors) and the training and testing time recorded for model created in section 2 (model using sparce vectors) we see that the model using sparse vector takes lesser time to train, same goes for time taken to test as well.\n",
        "\n",
        "In this case training the model using sparse vectors takes 1.72s less time to train and 14.6ms less time to test. this is because sparse vectors have more efficient storage and faster access techniques"
      ],
      "metadata": {
        "id": "t9xt2jVv9tHa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Whic_heibGEL"
      },
      "source": [
        "# 3 - Switch to Word Embeddings\n",
        "\n",
        "This section relates to content from **the week 2 lecture and the week 3 lab**.\n",
        "\n",
        "In this section, you will implement a model based on word2vec.\n",
        "\n",
        "1. Use word2vec to learn embeddings for the words in your data.\n",
        "2. Represent each input document as the average of the word vectors for the words it contains.\n",
        "3. Train a linear regression model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "print(gensim.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txiOj8U657h5",
        "outputId": "82288cd5-1bb2-4d8e-99e1-ee56b784d7ab"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####################################### Code for learning embeddings from words in training dataset #######################################\n",
        "\n",
        "# model to learn word embeddings from training data\n",
        "from gensim.models import Word2Vec\n",
        "word_embeddings_model = Word2Vec(sentences=training_text_tokenized, size=100, window=5, min_count=10, workers=2, sg=0)"
      ],
      "metadata": {
        "id": "Yso495v-YBd4"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this function uses specified word embedding model to generate average vector for each element of specified dataset\n",
        "def getAvgVectors(data,word_embedding_model):\n",
        "  # list of arrays that is treated as a list of vectors \n",
        "  list_of_word_vectors = []\n",
        "  for text in data:\n",
        "    # generating a vector for each word in the text\n",
        "    vector_for_texts = [word_embedding_model.wv[word] for word in text if word_embedding_model.wv.__contains__(word) ]\n",
        "    # reducing the list of word vectors to a mean vector for the dataset element\n",
        "    mean_vector = [sum(i)/len(text) for i in zip(*vector_for_texts)]\n",
        "    list_of_word_vectors.append(mean_vector)\n",
        "  # retruning the list of vectors as tensor\n",
        "  return torch.from_numpy(numpy.asarray(list_of_word_vectors))\n",
        "  #return list_of_word_vectors"
      ],
      "metadata": {
        "id": "CgE0rxW6YwmQ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################################### Code for representing each input document as the average of the word vectors for the words it contains #######################################\n",
        "\n",
        "# generating input data that will be used in training model\n",
        "x_training_word_embedding_tensor = getAvgVectors(training_text_tokenized,word_embeddings_model)\n",
        "x_dev_word_embedding_tensor = getAvgVectors(dev_text_tokenized,word_embeddings_model)\n",
        "x_test_word_embedding_tensor = getAvgVectors(test_text_tokenized,word_embeddings_model)"
      ],
      "metadata": {
        "id": "GZrrLKUQ7Sza"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# populating variables used in training model\n",
        "x_data = x_training_word_embedding_tensor.float()\n",
        "y_data = y_training_data_tensor.float()\n",
        "x_dev_data = x_dev_word_embedding_tensor.float()\n",
        "y_dev_data = y_dev_data_tensor.float()\n",
        "x_test_data = x_test_word_embedding_tensor.float()\n",
        "y_test_data = y_test_data_tensor.float()"
      ],
      "metadata": {
        "id": "-au0fpQ2fhkj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('x_data',x_data)\n",
        "print('x_dev_data',x_dev_data)\n",
        "print('x_test_data',x_test_data)"
      ],
      "metadata": {
        "id": "uCFTjF40WcZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0c8ce89-9da6-4fdd-f684-7394bb7d36f4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_data tensor([[-0.5877, -0.0584, -0.0620,  ...,  0.0216, -0.3667, -0.2914],\n",
            "        [-0.5651, -0.1119, -0.1609,  ...,  0.1444, -0.2572, -0.1452],\n",
            "        [-0.5016, -0.1134, -0.2075,  ...,  0.2529, -0.4345, -0.3639],\n",
            "        ...,\n",
            "        [-0.5559, -0.1558, -0.1314,  ...,  0.3902, -0.5177, -0.2062],\n",
            "        [-0.5544, -0.0438, -0.2238,  ...,  0.0254, -0.3075, -0.3114],\n",
            "        [-0.4939,  0.0416, -0.1102,  ...,  0.0725, -0.3594, -0.1712]])\n",
            "x_dev_data tensor([[-0.6061, -0.3074, -0.2971,  ...,  0.3092, -0.4251, -0.3105],\n",
            "        [-0.5857, -0.0894, -0.1847,  ...,  0.1451, -0.1954, -0.2376],\n",
            "        [-0.5944, -0.1709, -0.2255,  ...,  0.3798, -0.5226, -0.3171],\n",
            "        ...,\n",
            "        [-0.5528, -0.2319, -0.1300,  ...,  0.1162, -0.5047, -0.3705],\n",
            "        [-0.5757, -0.1193, -0.4067,  ...,  0.3365, -0.3388, -0.2778],\n",
            "        [-0.5173, -0.1462, -0.2788,  ...,  0.3027, -0.3760, -0.3550]])\n",
            "x_test_data tensor([[-0.6377, -0.0882,  0.0557,  ...,  0.4014, -0.5563, -0.3310],\n",
            "        [-0.6294, -0.2011, -0.2404,  ...,  0.0009, -0.3416, -0.2654],\n",
            "        [-0.5378, -0.1489, -0.3118,  ...,  0.2987, -0.2010, -0.3017],\n",
            "        ...,\n",
            "        [-0.5666, -0.1603, -0.0675,  ...,  0.2334, -0.5120, -0.2139],\n",
            "        [-0.4142,  0.0081, -0.1039,  ..., -0.0758, -0.3689, -0.0781],\n",
            "        [-0.5689, -0.0129, -0.1109,  ..., -0.0057, -0.1863, -0.2001]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('y_data',y_data)\n",
        "print('y_dev_data',y_dev_data_tensor)\n",
        "print('y_test_data',y_test_data)"
      ],
      "metadata": {
        "id": "lkgrrBZgWc-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2d0c5de-e1a7-4d18-8d71-1cea1429ab45"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_data tensor([[0.6453],\n",
            "        [0.3528],\n",
            "        [0.1265],\n",
            "        ...,\n",
            "        [0.5215],\n",
            "        [0.0191],\n",
            "        [0.1101]])\n",
            "y_dev_data tensor([[0.0552],\n",
            "        [0.0999],\n",
            "        [0.1331],\n",
            "        [0.0461],\n",
            "        [0.5329],\n",
            "        [0.3803],\n",
            "        [0.7429],\n",
            "        [0.3737],\n",
            "        [0.1130],\n",
            "        [0.4459],\n",
            "        [0.8221],\n",
            "        [0.5769],\n",
            "        [0.0800],\n",
            "        [0.0039],\n",
            "        [0.8192],\n",
            "        [0.2340],\n",
            "        [0.3241],\n",
            "        [0.4813],\n",
            "        [0.1308],\n",
            "        [0.1061],\n",
            "        [0.0964],\n",
            "        [0.4800],\n",
            "        [0.3005],\n",
            "        [0.4446],\n",
            "        [0.6819],\n",
            "        [0.0624],\n",
            "        [0.0023],\n",
            "        [0.6516],\n",
            "        [0.1084],\n",
            "        [0.0338],\n",
            "        [0.1668],\n",
            "        [1.0000],\n",
            "        [0.0378],\n",
            "        [0.7162],\n",
            "        [1.0000],\n",
            "        [0.4729],\n",
            "        [0.1461],\n",
            "        [0.0339],\n",
            "        [0.1397],\n",
            "        [0.0467],\n",
            "        [0.0139],\n",
            "        [0.1381],\n",
            "        [0.0618],\n",
            "        [0.6992],\n",
            "        [0.0825],\n",
            "        [0.1998],\n",
            "        [0.3397],\n",
            "        [0.3242],\n",
            "        [0.8384],\n",
            "        [0.6603],\n",
            "        [0.1526],\n",
            "        [0.4454],\n",
            "        [0.5000],\n",
            "        [0.1777],\n",
            "        [0.3162],\n",
            "        [0.4711],\n",
            "        [1.0000],\n",
            "        [0.0682],\n",
            "        [1.0000],\n",
            "        [0.0045],\n",
            "        [0.1025],\n",
            "        [0.3801],\n",
            "        [0.4676],\n",
            "        [1.0000],\n",
            "        [0.0698],\n",
            "        [0.1510],\n",
            "        [0.1671],\n",
            "        [0.9450],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.1527],\n",
            "        [0.4708],\n",
            "        [0.1268],\n",
            "        [0.2870],\n",
            "        [0.3339],\n",
            "        [0.1383],\n",
            "        [0.5040],\n",
            "        [0.0370],\n",
            "        [0.1159],\n",
            "        [0.2667],\n",
            "        [0.6404],\n",
            "        [0.7743],\n",
            "        [0.7592],\n",
            "        [0.5285],\n",
            "        [0.7861],\n",
            "        [0.9499],\n",
            "        [0.3047],\n",
            "        [0.1033],\n",
            "        [0.0131],\n",
            "        [0.1359],\n",
            "        [1.0000],\n",
            "        [0.6687],\n",
            "        [0.3711],\n",
            "        [0.0019],\n",
            "        [0.1374],\n",
            "        [0.0550],\n",
            "        [0.4501],\n",
            "        [0.0871],\n",
            "        [0.0251],\n",
            "        [0.0958],\n",
            "        [0.7153],\n",
            "        [0.2709],\n",
            "        [0.0938],\n",
            "        [0.0630],\n",
            "        [0.5334],\n",
            "        [0.7670],\n",
            "        [0.2958],\n",
            "        [1.0000],\n",
            "        [0.0533],\n",
            "        [0.1070],\n",
            "        [1.0000],\n",
            "        [0.2736],\n",
            "        [0.1435],\n",
            "        [0.0660],\n",
            "        [0.0499],\n",
            "        [0.1667],\n",
            "        [0.0373],\n",
            "        [0.0993],\n",
            "        [0.0466],\n",
            "        [0.3042],\n",
            "        [0.1685],\n",
            "        [0.0732],\n",
            "        [0.0373],\n",
            "        [0.0412],\n",
            "        [1.0000],\n",
            "        [0.1720],\n",
            "        [1.0000],\n",
            "        [0.4960],\n",
            "        [0.1058],\n",
            "        [0.1516],\n",
            "        [0.1190],\n",
            "        [0.0278],\n",
            "        [0.0161],\n",
            "        [0.0811],\n",
            "        [0.0274],\n",
            "        [0.2107],\n",
            "        [0.2254],\n",
            "        [0.0354],\n",
            "        [0.0276],\n",
            "        [0.2861],\n",
            "        [0.4141],\n",
            "        [0.0063],\n",
            "        [0.1041],\n",
            "        [0.1422],\n",
            "        [0.0026],\n",
            "        [0.5488],\n",
            "        [0.0083],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.1772],\n",
            "        [0.1442],\n",
            "        [0.6086],\n",
            "        [0.1025],\n",
            "        [0.1059],\n",
            "        [0.5772],\n",
            "        [0.0464],\n",
            "        [0.3392],\n",
            "        [0.1572],\n",
            "        [0.2298],\n",
            "        [0.1472],\n",
            "        [0.1704],\n",
            "        [0.1909],\n",
            "        [0.5225],\n",
            "        [0.5311],\n",
            "        [0.0995],\n",
            "        [1.0000],\n",
            "        [0.9419],\n",
            "        [0.2544],\n",
            "        [0.1917],\n",
            "        [0.5731],\n",
            "        [0.0576],\n",
            "        [0.4418],\n",
            "        [0.4653],\n",
            "        [0.5705],\n",
            "        [0.1428],\n",
            "        [0.2416],\n",
            "        [0.9614],\n",
            "        [0.1927],\n",
            "        [0.2578],\n",
            "        [1.0000],\n",
            "        [0.0605],\n",
            "        [0.8633],\n",
            "        [0.2742],\n",
            "        [0.0922],\n",
            "        [0.1719],\n",
            "        [0.3184],\n",
            "        [0.5352],\n",
            "        [0.0855],\n",
            "        [0.2844],\n",
            "        [0.6468],\n",
            "        [0.2538],\n",
            "        [0.6768],\n",
            "        [0.1783],\n",
            "        [0.1734],\n",
            "        [1.0000],\n",
            "        [0.1903],\n",
            "        [0.3684],\n",
            "        [0.1791],\n",
            "        [0.5791],\n",
            "        [0.1715],\n",
            "        [0.2113],\n",
            "        [0.5502],\n",
            "        [0.0636],\n",
            "        [0.9030],\n",
            "        [0.9305],\n",
            "        [0.0810],\n",
            "        [0.5443],\n",
            "        [0.1210],\n",
            "        [0.0411],\n",
            "        [0.0696],\n",
            "        [0.0202],\n",
            "        [1.0000],\n",
            "        [0.1869],\n",
            "        [0.0955],\n",
            "        [0.2788],\n",
            "        [0.0526],\n",
            "        [0.2637],\n",
            "        [0.2653],\n",
            "        [0.5137],\n",
            "        [0.2417],\n",
            "        [0.5192],\n",
            "        [0.0616],\n",
            "        [0.0589],\n",
            "        [0.2975],\n",
            "        [0.1366],\n",
            "        [0.1460],\n",
            "        [1.0000],\n",
            "        [0.2907],\n",
            "        [0.0478],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.8466],\n",
            "        [1.0000],\n",
            "        [0.5458],\n",
            "        [0.0836],\n",
            "        [0.0661],\n",
            "        [0.5950],\n",
            "        [0.1564],\n",
            "        [0.7383],\n",
            "        [0.1482],\n",
            "        [0.0874],\n",
            "        [0.1036],\n",
            "        [0.0136],\n",
            "        [0.1710],\n",
            "        [0.3181],\n",
            "        [0.0932],\n",
            "        [0.1279],\n",
            "        [0.0738],\n",
            "        [0.5986],\n",
            "        [0.1309],\n",
            "        [0.5684],\n",
            "        [0.4329],\n",
            "        [0.4022],\n",
            "        [0.0509],\n",
            "        [1.0000],\n",
            "        [0.0930],\n",
            "        [0.3622],\n",
            "        [0.6285],\n",
            "        [0.0204],\n",
            "        [0.0400],\n",
            "        [0.4648],\n",
            "        [0.4888],\n",
            "        [0.0746],\n",
            "        [0.5997],\n",
            "        [0.1226],\n",
            "        [0.1428],\n",
            "        [1.0000],\n",
            "        [0.2761],\n",
            "        [0.8673],\n",
            "        [0.5736],\n",
            "        [0.0904],\n",
            "        [0.2847],\n",
            "        [0.1933],\n",
            "        [0.9925],\n",
            "        [0.0530],\n",
            "        [1.0000],\n",
            "        [0.3818],\n",
            "        [0.1926],\n",
            "        [0.2347],\n",
            "        [0.0495],\n",
            "        [0.1507],\n",
            "        [0.0944],\n",
            "        [0.6934],\n",
            "        [0.3214],\n",
            "        [0.0658],\n",
            "        [0.4168],\n",
            "        [0.0598],\n",
            "        [0.0755],\n",
            "        [0.3732],\n",
            "        [0.1074],\n",
            "        [0.1907],\n",
            "        [0.0793],\n",
            "        [0.0125],\n",
            "        [0.6042],\n",
            "        [0.2933],\n",
            "        [0.0921],\n",
            "        [0.1638],\n",
            "        [0.5166],\n",
            "        [0.1108],\n",
            "        [0.1479],\n",
            "        [0.6797],\n",
            "        [0.0729],\n",
            "        [0.3447],\n",
            "        [0.1113],\n",
            "        [0.0074],\n",
            "        [0.3192],\n",
            "        [0.0732],\n",
            "        [0.4896],\n",
            "        [0.0898],\n",
            "        [0.2058],\n",
            "        [0.1809],\n",
            "        [0.4949],\n",
            "        [0.1215],\n",
            "        [0.5396],\n",
            "        [0.3673],\n",
            "        [0.4221],\n",
            "        [0.5566],\n",
            "        [0.1831],\n",
            "        [0.1356],\n",
            "        [0.1146],\n",
            "        [0.2202],\n",
            "        [0.0026],\n",
            "        [0.2610],\n",
            "        [0.3612],\n",
            "        [0.2210],\n",
            "        [0.0115],\n",
            "        [0.1540],\n",
            "        [0.1382],\n",
            "        [0.0398],\n",
            "        [0.2324],\n",
            "        [0.0707],\n",
            "        [0.2244],\n",
            "        [0.3915],\n",
            "        [0.7267],\n",
            "        [0.0852],\n",
            "        [0.9519],\n",
            "        [0.8890],\n",
            "        [1.0000],\n",
            "        [0.0270],\n",
            "        [0.8057],\n",
            "        [0.2766],\n",
            "        [1.0000],\n",
            "        [0.3670],\n",
            "        [0.5905],\n",
            "        [0.8443],\n",
            "        [0.0209],\n",
            "        [0.0020],\n",
            "        [0.4240],\n",
            "        [0.1114],\n",
            "        [0.2551],\n",
            "        [1.0000],\n",
            "        [0.1128],\n",
            "        [0.0226],\n",
            "        [0.0706],\n",
            "        [0.1425],\n",
            "        [0.5396],\n",
            "        [0.2499],\n",
            "        [0.4385],\n",
            "        [0.0569],\n",
            "        [0.7493],\n",
            "        [0.4873],\n",
            "        [1.0000],\n",
            "        [0.0396],\n",
            "        [0.0212],\n",
            "        [0.0917],\n",
            "        [0.4900],\n",
            "        [0.3780],\n",
            "        [0.9537],\n",
            "        [0.5273],\n",
            "        [0.5015],\n",
            "        [0.4526],\n",
            "        [0.6640],\n",
            "        [0.9036],\n",
            "        [0.6609],\n",
            "        [0.6129],\n",
            "        [0.0723],\n",
            "        [0.4331],\n",
            "        [0.6472],\n",
            "        [0.3413],\n",
            "        [0.1697],\n",
            "        [0.5351],\n",
            "        [0.3211],\n",
            "        [0.0349],\n",
            "        [0.1421],\n",
            "        [0.0347],\n",
            "        [0.1976],\n",
            "        [1.0000],\n",
            "        [0.9426],\n",
            "        [0.3868],\n",
            "        [0.0022],\n",
            "        [0.9736],\n",
            "        [0.5517],\n",
            "        [1.0000],\n",
            "        [0.0039],\n",
            "        [0.4918],\n",
            "        [0.4659],\n",
            "        [1.0000],\n",
            "        [0.4971],\n",
            "        [1.0000],\n",
            "        [0.6098],\n",
            "        [0.1030],\n",
            "        [0.1271],\n",
            "        [0.4269],\n",
            "        [0.7659],\n",
            "        [0.4114],\n",
            "        [0.3915],\n",
            "        [0.4465],\n",
            "        [0.2480],\n",
            "        [0.0216],\n",
            "        [0.0492],\n",
            "        [0.0514],\n",
            "        [0.0448],\n",
            "        [0.1160],\n",
            "        [0.0409],\n",
            "        [0.0487],\n",
            "        [0.0296],\n",
            "        [0.1258],\n",
            "        [0.0222],\n",
            "        [0.0288],\n",
            "        [0.0175],\n",
            "        [0.0245],\n",
            "        [0.0724],\n",
            "        [0.0415],\n",
            "        [0.0395],\n",
            "        [0.0638],\n",
            "        [0.0335],\n",
            "        [0.0989],\n",
            "        [0.0658],\n",
            "        [0.2023],\n",
            "        [0.0483],\n",
            "        [0.0398],\n",
            "        [0.0274],\n",
            "        [0.0792],\n",
            "        [0.0168],\n",
            "        [0.1511],\n",
            "        [0.0379],\n",
            "        [0.2555],\n",
            "        [0.1387],\n",
            "        [0.1587],\n",
            "        [0.8037],\n",
            "        [0.7510],\n",
            "        [0.0354],\n",
            "        [0.4384],\n",
            "        [0.6548],\n",
            "        [0.1266],\n",
            "        [0.1825],\n",
            "        [0.1372],\n",
            "        [0.1137],\n",
            "        [0.0497],\n",
            "        [0.0733],\n",
            "        [0.2562],\n",
            "        [0.3874],\n",
            "        [0.3403],\n",
            "        [0.0549],\n",
            "        [0.0350],\n",
            "        [0.4400],\n",
            "        [0.0963],\n",
            "        [0.8298],\n",
            "        [0.2418],\n",
            "        [0.4063],\n",
            "        [0.0360],\n",
            "        [0.1896],\n",
            "        [1.0000],\n",
            "        [0.6663],\n",
            "        [0.4688],\n",
            "        [0.5476],\n",
            "        [0.3494],\n",
            "        [0.4552],\n",
            "        [1.0000],\n",
            "        [0.2076],\n",
            "        [0.7823],\n",
            "        [0.3434],\n",
            "        [0.4403],\n",
            "        [0.0955],\n",
            "        [0.5256],\n",
            "        [0.2341],\n",
            "        [0.0605],\n",
            "        [0.1107],\n",
            "        [0.0388],\n",
            "        [0.0744],\n",
            "        [1.0000],\n",
            "        [0.1375],\n",
            "        [0.0163],\n",
            "        [0.5064],\n",
            "        [0.7643],\n",
            "        [0.0667],\n",
            "        [0.1421],\n",
            "        [0.0856],\n",
            "        [0.1714],\n",
            "        [0.1683],\n",
            "        [0.2343],\n",
            "        [0.0763],\n",
            "        [0.4178],\n",
            "        [0.0972],\n",
            "        [0.2800],\n",
            "        [0.0735],\n",
            "        [0.2085],\n",
            "        [0.2189],\n",
            "        [0.3422],\n",
            "        [0.1604],\n",
            "        [0.9719],\n",
            "        [1.0000],\n",
            "        [0.4589],\n",
            "        [0.2066],\n",
            "        [0.0417],\n",
            "        [0.1853],\n",
            "        [0.0815],\n",
            "        [0.0218],\n",
            "        [0.2330],\n",
            "        [0.0394],\n",
            "        [0.2955],\n",
            "        [0.3204],\n",
            "        [0.5487],\n",
            "        [0.1723],\n",
            "        [0.2869],\n",
            "        [0.3066],\n",
            "        [0.3998],\n",
            "        [0.6446],\n",
            "        [0.3397],\n",
            "        [0.2826],\n",
            "        [0.3616],\n",
            "        [0.3954],\n",
            "        [0.4052],\n",
            "        [0.2708],\n",
            "        [0.1449],\n",
            "        [1.0000],\n",
            "        [0.1041],\n",
            "        [0.7139],\n",
            "        [0.1893],\n",
            "        [0.2629],\n",
            "        [0.4443],\n",
            "        [0.7169],\n",
            "        [1.0000],\n",
            "        [0.2719],\n",
            "        [0.0344],\n",
            "        [0.0747],\n",
            "        [0.0717],\n",
            "        [0.4316],\n",
            "        [0.7741],\n",
            "        [0.0089],\n",
            "        [0.0638],\n",
            "        [1.0000],\n",
            "        [0.2871],\n",
            "        [0.2995],\n",
            "        [0.4347],\n",
            "        [0.7895],\n",
            "        [0.1105],\n",
            "        [0.2477],\n",
            "        [0.8325],\n",
            "        [0.2359],\n",
            "        [0.5043],\n",
            "        [0.3333],\n",
            "        [0.1594],\n",
            "        [0.0142],\n",
            "        [0.0622],\n",
            "        [0.0902],\n",
            "        [0.0113],\n",
            "        [0.5932],\n",
            "        [0.7026],\n",
            "        [0.1338],\n",
            "        [0.0638],\n",
            "        [0.0552],\n",
            "        [0.1671],\n",
            "        [0.0713],\n",
            "        [0.0344],\n",
            "        [0.3230],\n",
            "        [0.0671],\n",
            "        [0.0612],\n",
            "        [0.1337],\n",
            "        [0.0247],\n",
            "        [0.0798],\n",
            "        [0.3528],\n",
            "        [0.5027],\n",
            "        [0.7039],\n",
            "        [1.0000],\n",
            "        [0.2878],\n",
            "        [0.0700],\n",
            "        [0.0375],\n",
            "        [0.6571],\n",
            "        [0.0395],\n",
            "        [0.0462],\n",
            "        [0.1186],\n",
            "        [0.0335],\n",
            "        [1.0000],\n",
            "        [0.2144],\n",
            "        [0.2182],\n",
            "        [0.2033],\n",
            "        [0.6828],\n",
            "        [0.0766],\n",
            "        [0.0718],\n",
            "        [0.0861],\n",
            "        [0.0228],\n",
            "        [0.9964],\n",
            "        [1.0000],\n",
            "        [0.3780],\n",
            "        [0.2425],\n",
            "        [0.9091],\n",
            "        [0.8175],\n",
            "        [0.1943],\n",
            "        [0.3286],\n",
            "        [0.7354],\n",
            "        [0.0882],\n",
            "        [0.5753],\n",
            "        [0.0409],\n",
            "        [0.0600],\n",
            "        [0.1799],\n",
            "        [0.2281],\n",
            "        [0.5863],\n",
            "        [0.0145],\n",
            "        [0.1333],\n",
            "        [0.1519],\n",
            "        [0.5058],\n",
            "        [0.2329],\n",
            "        [0.0166],\n",
            "        [0.0221],\n",
            "        [0.2844],\n",
            "        [0.6261],\n",
            "        [1.0000],\n",
            "        [0.0738],\n",
            "        [0.3613],\n",
            "        [0.1427],\n",
            "        [0.1559],\n",
            "        [0.4143],\n",
            "        [0.0767],\n",
            "        [0.3595],\n",
            "        [0.0934],\n",
            "        [0.0290],\n",
            "        [0.6909],\n",
            "        [1.0000],\n",
            "        [0.2044],\n",
            "        [0.8456],\n",
            "        [0.1570],\n",
            "        [0.6457],\n",
            "        [0.0064],\n",
            "        [0.1708],\n",
            "        [0.0633],\n",
            "        [0.9418],\n",
            "        [0.0281],\n",
            "        [0.0086],\n",
            "        [0.6039],\n",
            "        [0.2846],\n",
            "        [0.2821],\n",
            "        [0.0696],\n",
            "        [0.2283],\n",
            "        [0.2939],\n",
            "        [0.1087],\n",
            "        [0.4184],\n",
            "        [0.5101],\n",
            "        [0.7152],\n",
            "        [0.0320],\n",
            "        [0.0797],\n",
            "        [1.0000],\n",
            "        [0.2391],\n",
            "        [0.0575],\n",
            "        [0.3524],\n",
            "        [0.3337],\n",
            "        [0.1137],\n",
            "        [0.2390],\n",
            "        [0.2283],\n",
            "        [0.1761],\n",
            "        [0.1389],\n",
            "        [0.4430],\n",
            "        [0.0732],\n",
            "        [0.1607],\n",
            "        [1.0000],\n",
            "        [0.5644],\n",
            "        [0.1314],\n",
            "        [0.4022],\n",
            "        [0.2799],\n",
            "        [0.3263],\n",
            "        [0.2987],\n",
            "        [0.1683],\n",
            "        [0.9467],\n",
            "        [0.4441],\n",
            "        [0.5954],\n",
            "        [0.0029],\n",
            "        [0.1493],\n",
            "        [0.0576],\n",
            "        [0.5446],\n",
            "        [0.3687],\n",
            "        [0.1442],\n",
            "        [0.1071],\n",
            "        [0.1420],\n",
            "        [0.2088],\n",
            "        [0.5777],\n",
            "        [1.0000],\n",
            "        [0.3677],\n",
            "        [0.0383],\n",
            "        [0.0233],\n",
            "        [0.0387],\n",
            "        [0.6148],\n",
            "        [0.1195],\n",
            "        [0.1067],\n",
            "        [0.1600],\n",
            "        [0.0390],\n",
            "        [1.0000],\n",
            "        [0.0653],\n",
            "        [0.3330],\n",
            "        [0.1188],\n",
            "        [0.2913],\n",
            "        [0.0309],\n",
            "        [0.1120],\n",
            "        [0.1799],\n",
            "        [0.1419],\n",
            "        [0.1202],\n",
            "        [0.4585],\n",
            "        [0.0171],\n",
            "        [0.0464],\n",
            "        [0.5838],\n",
            "        [0.0470],\n",
            "        [0.1685],\n",
            "        [0.2367],\n",
            "        [0.7918],\n",
            "        [0.1420],\n",
            "        [0.1547],\n",
            "        [0.6156],\n",
            "        [0.1110],\n",
            "        [0.3763],\n",
            "        [0.0450],\n",
            "        [0.1245],\n",
            "        [0.1499],\n",
            "        [0.1167],\n",
            "        [0.3048],\n",
            "        [0.2895],\n",
            "        [0.0027],\n",
            "        [0.1653],\n",
            "        [0.3833],\n",
            "        [0.1507],\n",
            "        [0.0118],\n",
            "        [0.0961],\n",
            "        [0.4322],\n",
            "        [0.2814],\n",
            "        [0.4466],\n",
            "        [0.0375],\n",
            "        [0.4953],\n",
            "        [0.7260],\n",
            "        [0.2629],\n",
            "        [0.1448],\n",
            "        [0.1251],\n",
            "        [0.5530],\n",
            "        [0.6276],\n",
            "        [0.4577],\n",
            "        [0.3861],\n",
            "        [0.0430],\n",
            "        [0.1478],\n",
            "        [0.1538],\n",
            "        [0.3511],\n",
            "        [0.3679],\n",
            "        [0.1860],\n",
            "        [0.1101],\n",
            "        [1.0000],\n",
            "        [0.3395],\n",
            "        [0.4292],\n",
            "        [0.0981],\n",
            "        [0.0090],\n",
            "        [0.4104],\n",
            "        [0.5419],\n",
            "        [0.2914],\n",
            "        [1.0000],\n",
            "        [0.1407],\n",
            "        [0.7847],\n",
            "        [0.2228],\n",
            "        [0.0143],\n",
            "        [0.0894],\n",
            "        [0.1893],\n",
            "        [0.0037],\n",
            "        [0.6113],\n",
            "        [0.0227],\n",
            "        [0.0198],\n",
            "        [0.0371],\n",
            "        [0.5014],\n",
            "        [0.3955],\n",
            "        [0.1643],\n",
            "        [0.4345],\n",
            "        [0.0717],\n",
            "        [0.3588],\n",
            "        [0.1890],\n",
            "        [0.6763],\n",
            "        [0.3267],\n",
            "        [0.1317],\n",
            "        [0.0452],\n",
            "        [0.2685],\n",
            "        [0.1480],\n",
            "        [0.0739],\n",
            "        [0.0422],\n",
            "        [0.1160],\n",
            "        [0.1466],\n",
            "        [1.0000],\n",
            "        [0.2060],\n",
            "        [0.6097],\n",
            "        [1.0000],\n",
            "        [0.0402],\n",
            "        [0.0840],\n",
            "        [0.0543],\n",
            "        [0.0168],\n",
            "        [0.0684],\n",
            "        [0.3268],\n",
            "        [0.0292],\n",
            "        [0.0668],\n",
            "        [0.5577],\n",
            "        [0.1656],\n",
            "        [0.3260],\n",
            "        [0.0381],\n",
            "        [0.0306],\n",
            "        [0.0729],\n",
            "        [1.0000],\n",
            "        [0.0880],\n",
            "        [0.0707],\n",
            "        [0.1630],\n",
            "        [0.0152],\n",
            "        [0.0362],\n",
            "        [0.0739],\n",
            "        [0.0191],\n",
            "        [0.1827],\n",
            "        [0.5474],\n",
            "        [0.0467],\n",
            "        [0.7092],\n",
            "        [0.1145],\n",
            "        [0.1154],\n",
            "        [0.2286],\n",
            "        [0.0778],\n",
            "        [0.4654],\n",
            "        [0.1575],\n",
            "        [0.1722],\n",
            "        [0.1941],\n",
            "        [0.2205],\n",
            "        [0.0431],\n",
            "        [0.3764],\n",
            "        [0.3930],\n",
            "        [0.0414],\n",
            "        [0.0406],\n",
            "        [1.0000],\n",
            "        [0.4400],\n",
            "        [0.0989],\n",
            "        [0.0644],\n",
            "        [0.0305],\n",
            "        [0.4770],\n",
            "        [1.0000],\n",
            "        [0.0738],\n",
            "        [0.0432],\n",
            "        [0.1729],\n",
            "        [0.1052],\n",
            "        [0.1339],\n",
            "        [0.2162],\n",
            "        [0.0409],\n",
            "        [0.0209],\n",
            "        [0.0511],\n",
            "        [0.0054],\n",
            "        [0.0547],\n",
            "        [0.1053],\n",
            "        [0.3648],\n",
            "        [0.9354],\n",
            "        [0.4095],\n",
            "        [0.5391],\n",
            "        [0.5209],\n",
            "        [0.0213],\n",
            "        [0.0784],\n",
            "        [1.0000],\n",
            "        [0.0097],\n",
            "        [1.0000],\n",
            "        [0.0393],\n",
            "        [0.8295],\n",
            "        [0.3003],\n",
            "        [0.0799],\n",
            "        [0.2739],\n",
            "        [0.1823],\n",
            "        [0.6535],\n",
            "        [0.1375],\n",
            "        [0.5236],\n",
            "        [0.0345],\n",
            "        [0.0316],\n",
            "        [0.1064],\n",
            "        [0.1611],\n",
            "        [0.0916],\n",
            "        [0.0586],\n",
            "        [0.0865],\n",
            "        [0.7904],\n",
            "        [0.1418],\n",
            "        [0.1393],\n",
            "        [0.4854],\n",
            "        [0.3130],\n",
            "        [0.0940],\n",
            "        [0.1205],\n",
            "        [0.2234],\n",
            "        [0.3264],\n",
            "        [0.2004],\n",
            "        [0.0691],\n",
            "        [0.1346],\n",
            "        [0.1029],\n",
            "        [0.0401],\n",
            "        [0.1285],\n",
            "        [0.0555],\n",
            "        [0.2742],\n",
            "        [0.6522],\n",
            "        [0.1536],\n",
            "        [0.2144],\n",
            "        [0.0106],\n",
            "        [0.0881],\n",
            "        [0.6326],\n",
            "        [0.0255],\n",
            "        [0.0297],\n",
            "        [0.0342],\n",
            "        [0.0823],\n",
            "        [0.0510],\n",
            "        [0.0378],\n",
            "        [0.0410],\n",
            "        [0.1058],\n",
            "        [0.1704],\n",
            "        [0.0728],\n",
            "        [0.1260],\n",
            "        [0.3938],\n",
            "        [0.1562],\n",
            "        [0.5025],\n",
            "        [0.9346],\n",
            "        [0.1655],\n",
            "        [0.6490],\n",
            "        [1.0000],\n",
            "        [0.0665],\n",
            "        [0.0022],\n",
            "        [0.5275],\n",
            "        [0.1905],\n",
            "        [0.0442],\n",
            "        [0.5409],\n",
            "        [0.1910],\n",
            "        [0.4206],\n",
            "        [0.0203],\n",
            "        [0.0966],\n",
            "        [0.0752],\n",
            "        [0.0176],\n",
            "        [0.0521],\n",
            "        [0.0579],\n",
            "        [0.0392],\n",
            "        [0.0131],\n",
            "        [0.1045],\n",
            "        [0.5853],\n",
            "        [0.1313],\n",
            "        [0.1621],\n",
            "        [0.1919],\n",
            "        [0.2930],\n",
            "        [0.1693],\n",
            "        [0.0606],\n",
            "        [0.2769],\n",
            "        [0.1252],\n",
            "        [0.1136],\n",
            "        [0.2492],\n",
            "        [0.2440],\n",
            "        [0.7159],\n",
            "        [0.4882],\n",
            "        [0.3176],\n",
            "        [0.2892],\n",
            "        [0.1437],\n",
            "        [0.2928],\n",
            "        [0.1700],\n",
            "        [0.7412],\n",
            "        [0.9296],\n",
            "        [1.0000],\n",
            "        [0.6531],\n",
            "        [0.1073],\n",
            "        [0.0702],\n",
            "        [0.0782],\n",
            "        [0.1016],\n",
            "        [0.1579],\n",
            "        [0.3720],\n",
            "        [0.3677],\n",
            "        [0.3498],\n",
            "        [0.4528],\n",
            "        [0.1867],\n",
            "        [0.9082],\n",
            "        [0.1292],\n",
            "        [0.1013],\n",
            "        [0.3027],\n",
            "        [0.2353],\n",
            "        [0.5917],\n",
            "        [0.1775],\n",
            "        [0.5195],\n",
            "        [0.1134],\n",
            "        [0.2188],\n",
            "        [0.1856],\n",
            "        [0.1123],\n",
            "        [0.6131],\n",
            "        [0.6980],\n",
            "        [0.0725],\n",
            "        [0.5260],\n",
            "        [0.3009],\n",
            "        [0.1999],\n",
            "        [0.1379],\n",
            "        [1.0000],\n",
            "        [0.2219],\n",
            "        [0.2032],\n",
            "        [0.2687],\n",
            "        [0.1390],\n",
            "        [0.3186],\n",
            "        [0.1686],\n",
            "        [0.1953]], dtype=torch.float64)\n",
            "y_test_data tensor([[0.2905],\n",
            "        [0.4138],\n",
            "        [0.0558],\n",
            "        [0.0634],\n",
            "        [0.0414],\n",
            "        [0.0571],\n",
            "        [0.2096],\n",
            "        [0.3854],\n",
            "        [0.2260],\n",
            "        [0.1627],\n",
            "        [0.4779],\n",
            "        [1.0000],\n",
            "        [0.8417],\n",
            "        [0.4917],\n",
            "        [0.1004],\n",
            "        [0.7282],\n",
            "        [0.3487],\n",
            "        [0.2106],\n",
            "        [0.1163],\n",
            "        [0.1497],\n",
            "        [0.3482],\n",
            "        [0.0969],\n",
            "        [0.1787],\n",
            "        [0.0840],\n",
            "        [0.1663],\n",
            "        [0.1318],\n",
            "        [0.2430],\n",
            "        [0.1366],\n",
            "        [0.1876],\n",
            "        [0.0432],\n",
            "        [0.0761],\n",
            "        [0.0632],\n",
            "        [0.3013],\n",
            "        [0.5176],\n",
            "        [0.6209],\n",
            "        [0.0202],\n",
            "        [0.1058],\n",
            "        [1.0000],\n",
            "        [0.1024],\n",
            "        [0.3109],\n",
            "        [0.1410],\n",
            "        [0.0759],\n",
            "        [0.1623],\n",
            "        [0.1526],\n",
            "        [0.2695],\n",
            "        [0.3350],\n",
            "        [0.1012],\n",
            "        [0.0670],\n",
            "        [0.1031],\n",
            "        [0.1988],\n",
            "        [0.2438],\n",
            "        [0.0645],\n",
            "        [0.1019],\n",
            "        [0.1207],\n",
            "        [0.0450],\n",
            "        [0.0857],\n",
            "        [0.1981],\n",
            "        [0.1901],\n",
            "        [0.4734],\n",
            "        [0.3259],\n",
            "        [0.5425],\n",
            "        [0.0714],\n",
            "        [0.5765],\n",
            "        [0.4959],\n",
            "        [0.0094],\n",
            "        [0.9576],\n",
            "        [0.2494],\n",
            "        [0.0191],\n",
            "        [0.0207],\n",
            "        [0.1148],\n",
            "        [0.0868],\n",
            "        [0.1217],\n",
            "        [0.3807],\n",
            "        [0.4320],\n",
            "        [0.6002],\n",
            "        [0.0745],\n",
            "        [0.0402],\n",
            "        [0.0381],\n",
            "        [0.0341],\n",
            "        [0.2083],\n",
            "        [0.1927],\n",
            "        [0.1915],\n",
            "        [0.3305],\n",
            "        [0.0717],\n",
            "        [0.2285],\n",
            "        [0.0482],\n",
            "        [0.0984],\n",
            "        [0.4014],\n",
            "        [0.0396],\n",
            "        [0.0612],\n",
            "        [0.3275],\n",
            "        [0.2901],\n",
            "        [0.1572],\n",
            "        [0.0716],\n",
            "        [0.5070],\n",
            "        [0.4909],\n",
            "        [0.1147],\n",
            "        [0.2071],\n",
            "        [0.1169],\n",
            "        [0.0808],\n",
            "        [0.0394],\n",
            "        [0.0497],\n",
            "        [0.0473],\n",
            "        [0.2616],\n",
            "        [0.1531],\n",
            "        [0.2614],\n",
            "        [0.4656],\n",
            "        [1.0000],\n",
            "        [0.3236],\n",
            "        [0.0381],\n",
            "        [0.2265],\n",
            "        [0.0614],\n",
            "        [0.0415],\n",
            "        [0.0376],\n",
            "        [0.0255],\n",
            "        [0.0751],\n",
            "        [0.2396],\n",
            "        [0.1029],\n",
            "        [0.0383],\n",
            "        [0.2123],\n",
            "        [0.0393],\n",
            "        [0.4627],\n",
            "        [0.1200],\n",
            "        [0.2774],\n",
            "        [0.8199],\n",
            "        [0.1181],\n",
            "        [0.0667],\n",
            "        [0.4591],\n",
            "        [0.3566],\n",
            "        [0.3264],\n",
            "        [0.5491],\n",
            "        [0.0076],\n",
            "        [0.4509],\n",
            "        [0.2040],\n",
            "        [0.1600],\n",
            "        [0.0646],\n",
            "        [0.0454],\n",
            "        [0.1099],\n",
            "        [0.0997],\n",
            "        [0.1874],\n",
            "        [0.0126],\n",
            "        [0.2367],\n",
            "        [0.3920],\n",
            "        [0.1122],\n",
            "        [0.0362],\n",
            "        [0.3079],\n",
            "        [0.0974],\n",
            "        [0.2129],\n",
            "        [0.0347],\n",
            "        [0.6693],\n",
            "        [0.6996],\n",
            "        [1.0000],\n",
            "        [0.0024],\n",
            "        [0.7431],\n",
            "        [0.1548],\n",
            "        [0.3637],\n",
            "        [0.0655],\n",
            "        [0.1733],\n",
            "        [0.2460],\n",
            "        [0.0907],\n",
            "        [0.0999],\n",
            "        [0.3283],\n",
            "        [0.1964],\n",
            "        [0.0550],\n",
            "        [0.4847],\n",
            "        [0.5815],\n",
            "        [0.0146],\n",
            "        [0.0722],\n",
            "        [0.0898],\n",
            "        [0.4501],\n",
            "        [0.4386],\n",
            "        [0.1549],\n",
            "        [0.3573],\n",
            "        [0.3442],\n",
            "        [0.2468],\n",
            "        [0.2733],\n",
            "        [0.0047],\n",
            "        [0.4323],\n",
            "        [0.4736],\n",
            "        [1.0000],\n",
            "        [0.0478],\n",
            "        [0.1609],\n",
            "        [0.7323],\n",
            "        [0.0220],\n",
            "        [0.0260],\n",
            "        [0.0409],\n",
            "        [0.0581],\n",
            "        [0.2917],\n",
            "        [0.0709],\n",
            "        [0.0318],\n",
            "        [0.0035],\n",
            "        [0.0051],\n",
            "        [0.1708],\n",
            "        [0.2498],\n",
            "        [0.7912],\n",
            "        [0.0979],\n",
            "        [1.0000],\n",
            "        [0.3806],\n",
            "        [0.1529],\n",
            "        [0.2142],\n",
            "        [0.1303],\n",
            "        [0.1900],\n",
            "        [0.1355],\n",
            "        [0.7581],\n",
            "        [0.2362],\n",
            "        [0.2900],\n",
            "        [0.4483],\n",
            "        [0.9900],\n",
            "        [0.0384],\n",
            "        [0.0726],\n",
            "        [0.3724],\n",
            "        [0.4604],\n",
            "        [0.1505],\n",
            "        [0.0703],\n",
            "        [0.8946],\n",
            "        [0.1741],\n",
            "        [0.6558],\n",
            "        [0.0129],\n",
            "        [0.2217],\n",
            "        [0.3803],\n",
            "        [0.1291],\n",
            "        [0.3616],\n",
            "        [0.0353],\n",
            "        [0.0391],\n",
            "        [0.2902],\n",
            "        [0.1158],\n",
            "        [0.1629],\n",
            "        [0.0699],\n",
            "        [0.0265],\n",
            "        [1.0000],\n",
            "        [0.0830],\n",
            "        [0.3402],\n",
            "        [0.1002],\n",
            "        [0.8251],\n",
            "        [0.1671],\n",
            "        [0.1885],\n",
            "        [0.0022],\n",
            "        [0.6669],\n",
            "        [0.6698],\n",
            "        [0.0665],\n",
            "        [0.0937],\n",
            "        [0.2486],\n",
            "        [0.2830],\n",
            "        [1.0000],\n",
            "        [0.2115],\n",
            "        [0.6577],\n",
            "        [0.8638],\n",
            "        [0.6452],\n",
            "        [0.3605],\n",
            "        [0.0064],\n",
            "        [0.0978],\n",
            "        [0.0552],\n",
            "        [0.2200],\n",
            "        [0.5453],\n",
            "        [0.1490],\n",
            "        [0.0373],\n",
            "        [0.2637],\n",
            "        [0.2501],\n",
            "        [0.1805],\n",
            "        [0.2414],\n",
            "        [0.0137],\n",
            "        [0.7147],\n",
            "        [0.4024],\n",
            "        [0.2233],\n",
            "        [0.0974],\n",
            "        [0.4258],\n",
            "        [0.1569],\n",
            "        [0.1793],\n",
            "        [0.3297],\n",
            "        [0.0870],\n",
            "        [0.2088],\n",
            "        [0.0762],\n",
            "        [0.1747],\n",
            "        [0.3548],\n",
            "        [0.1214],\n",
            "        [0.3002],\n",
            "        [0.1897],\n",
            "        [0.4681],\n",
            "        [0.0633],\n",
            "        [0.0756],\n",
            "        [0.4083],\n",
            "        [0.0673],\n",
            "        [0.4281],\n",
            "        [0.0492],\n",
            "        [0.2128],\n",
            "        [0.0999],\n",
            "        [0.1571],\n",
            "        [0.1993],\n",
            "        [0.2387],\n",
            "        [0.1563],\n",
            "        [0.1363],\n",
            "        [0.3970],\n",
            "        [0.0250],\n",
            "        [0.4429],\n",
            "        [0.1005],\n",
            "        [0.1046],\n",
            "        [0.1660],\n",
            "        [0.0113],\n",
            "        [0.1196],\n",
            "        [0.0740],\n",
            "        [0.1615],\n",
            "        [0.0513],\n",
            "        [0.1033],\n",
            "        [0.1496],\n",
            "        [0.0524],\n",
            "        [0.0654],\n",
            "        [0.0763],\n",
            "        [0.0911],\n",
            "        [0.4934],\n",
            "        [0.1520],\n",
            "        [0.5364],\n",
            "        [0.2513],\n",
            "        [0.2667],\n",
            "        [0.1155],\n",
            "        [0.6917],\n",
            "        [0.1897],\n",
            "        [0.4272],\n",
            "        [0.1916],\n",
            "        [0.1487],\n",
            "        [0.1962],\n",
            "        [0.2396],\n",
            "        [0.2856],\n",
            "        [0.0476],\n",
            "        [0.2017],\n",
            "        [0.2115],\n",
            "        [0.1002],\n",
            "        [0.0037],\n",
            "        [0.0050],\n",
            "        [0.0036],\n",
            "        [0.0607],\n",
            "        [0.1948],\n",
            "        [0.4711],\n",
            "        [0.2258],\n",
            "        [0.0834],\n",
            "        [0.0165],\n",
            "        [0.0978],\n",
            "        [0.7646],\n",
            "        [0.0269],\n",
            "        [0.5491],\n",
            "        [0.0389],\n",
            "        [0.7723],\n",
            "        [0.1679],\n",
            "        [0.0201],\n",
            "        [0.3911],\n",
            "        [0.3414],\n",
            "        [0.0985],\n",
            "        [0.1994],\n",
            "        [0.0367],\n",
            "        [0.0427],\n",
            "        [0.1667],\n",
            "        [0.6906],\n",
            "        [0.4803],\n",
            "        [0.0545],\n",
            "        [0.5769],\n",
            "        [0.0428],\n",
            "        [0.0021],\n",
            "        [0.2898],\n",
            "        [0.1730],\n",
            "        [0.0153],\n",
            "        [0.0210],\n",
            "        [0.3894],\n",
            "        [0.1854],\n",
            "        [0.0516],\n",
            "        [0.2722],\n",
            "        [0.3443],\n",
            "        [0.1148],\n",
            "        [0.4934],\n",
            "        [1.0000],\n",
            "        [0.5383],\n",
            "        [0.1455],\n",
            "        [0.2760],\n",
            "        [0.0028],\n",
            "        [0.1421],\n",
            "        [0.3106],\n",
            "        [0.4408],\n",
            "        [0.0960],\n",
            "        [0.2385],\n",
            "        [0.8496],\n",
            "        [0.2474],\n",
            "        [0.2162],\n",
            "        [0.4042],\n",
            "        [0.1009],\n",
            "        [0.2154],\n",
            "        [0.0889],\n",
            "        [0.0663],\n",
            "        [0.7277],\n",
            "        [0.2739],\n",
            "        [0.0870],\n",
            "        [0.3906],\n",
            "        [0.2752],\n",
            "        [0.3292],\n",
            "        [0.2592],\n",
            "        [0.1591],\n",
            "        [0.3442],\n",
            "        [0.1681],\n",
            "        [0.4459],\n",
            "        [0.3542],\n",
            "        [0.4263],\n",
            "        [0.0800],\n",
            "        [0.3990],\n",
            "        [0.3342],\n",
            "        [0.3115],\n",
            "        [0.0710],\n",
            "        [0.1136],\n",
            "        [0.0623],\n",
            "        [0.1175],\n",
            "        [0.1139],\n",
            "        [0.0421],\n",
            "        [0.0958],\n",
            "        [0.6308],\n",
            "        [0.2213],\n",
            "        [0.1770],\n",
            "        [0.0563],\n",
            "        [0.1296],\n",
            "        [0.6989],\n",
            "        [0.1038],\n",
            "        [0.0892],\n",
            "        [0.2267],\n",
            "        [0.0548],\n",
            "        [0.7630],\n",
            "        [0.0263],\n",
            "        [0.3782],\n",
            "        [0.0946],\n",
            "        [0.8948],\n",
            "        [0.8158],\n",
            "        [0.1882],\n",
            "        [0.9363],\n",
            "        [0.0693],\n",
            "        [0.4388],\n",
            "        [0.0809],\n",
            "        [0.1139],\n",
            "        [0.2955],\n",
            "        [0.1044],\n",
            "        [0.2508],\n",
            "        [0.8290],\n",
            "        [0.0637],\n",
            "        [0.1320],\n",
            "        [0.0382],\n",
            "        [0.4277],\n",
            "        [0.1713],\n",
            "        [0.4515],\n",
            "        [0.1211],\n",
            "        [0.0703],\n",
            "        [0.3160],\n",
            "        [0.1439],\n",
            "        [0.3067],\n",
            "        [1.0000],\n",
            "        [0.5652],\n",
            "        [0.2088],\n",
            "        [0.4383],\n",
            "        [0.0696],\n",
            "        [0.0551],\n",
            "        [0.3407],\n",
            "        [0.4540],\n",
            "        [0.6390],\n",
            "        [0.6172],\n",
            "        [0.1149],\n",
            "        [0.2921],\n",
            "        [0.1667],\n",
            "        [0.7880],\n",
            "        [0.9166],\n",
            "        [0.1608],\n",
            "        [0.3438],\n",
            "        [0.0675],\n",
            "        [0.0427],\n",
            "        [0.0031],\n",
            "        [0.0656],\n",
            "        [0.1080],\n",
            "        [0.0447],\n",
            "        [0.1571],\n",
            "        [0.1522],\n",
            "        [0.8334],\n",
            "        [0.0600],\n",
            "        [0.0564],\n",
            "        [0.1052],\n",
            "        [0.2234],\n",
            "        [0.0549],\n",
            "        [0.0563],\n",
            "        [1.0000],\n",
            "        [0.7691],\n",
            "        [0.3375],\n",
            "        [0.0387],\n",
            "        [0.4271],\n",
            "        [0.1287],\n",
            "        [0.0882],\n",
            "        [0.2780],\n",
            "        [0.1247],\n",
            "        [0.0581],\n",
            "        [0.1767],\n",
            "        [0.2115],\n",
            "        [0.6352],\n",
            "        [0.2878],\n",
            "        [0.0602],\n",
            "        [1.0000],\n",
            "        [0.3529],\n",
            "        [0.1817],\n",
            "        [0.1019],\n",
            "        [0.3930],\n",
            "        [0.0609],\n",
            "        [0.5716],\n",
            "        [0.1380],\n",
            "        [0.0528],\n",
            "        [0.0726],\n",
            "        [1.0000],\n",
            "        [0.1635],\n",
            "        [0.0899],\n",
            "        [0.6695],\n",
            "        [0.0930],\n",
            "        [0.0329],\n",
            "        [0.0640],\n",
            "        [0.0723],\n",
            "        [0.3651],\n",
            "        [0.2055],\n",
            "        [0.2768],\n",
            "        [0.6159],\n",
            "        [0.1454],\n",
            "        [0.4062],\n",
            "        [0.0988],\n",
            "        [0.0151],\n",
            "        [0.1494],\n",
            "        [0.2207],\n",
            "        [0.4739],\n",
            "        [0.5913],\n",
            "        [0.0646],\n",
            "        [0.2138],\n",
            "        [0.2294],\n",
            "        [0.1562],\n",
            "        [0.2331],\n",
            "        [0.0083],\n",
            "        [0.0346],\n",
            "        [0.0035],\n",
            "        [0.1289],\n",
            "        [0.3022],\n",
            "        [0.1016],\n",
            "        [0.0571],\n",
            "        [0.7405],\n",
            "        [0.1064],\n",
            "        [0.3778],\n",
            "        [0.0906],\n",
            "        [0.3961],\n",
            "        [0.1140],\n",
            "        [0.1763],\n",
            "        [0.1190],\n",
            "        [0.8663],\n",
            "        [0.1318],\n",
            "        [0.0657],\n",
            "        [0.2610],\n",
            "        [0.2635],\n",
            "        [0.0218],\n",
            "        [0.0622],\n",
            "        [0.1012],\n",
            "        [0.1834],\n",
            "        [0.0973],\n",
            "        [0.2746],\n",
            "        [0.6565],\n",
            "        [0.3646],\n",
            "        [0.1873],\n",
            "        [0.0958],\n",
            "        [0.2886],\n",
            "        [0.1409],\n",
            "        [0.7882],\n",
            "        [0.3627],\n",
            "        [0.3659],\n",
            "        [0.2959],\n",
            "        [0.5024],\n",
            "        [0.2041],\n",
            "        [0.2827],\n",
            "        [0.1028],\n",
            "        [0.3271],\n",
            "        [0.4351],\n",
            "        [0.2734],\n",
            "        [0.0868],\n",
            "        [0.0434],\n",
            "        [0.7601],\n",
            "        [0.4859],\n",
            "        [0.0898],\n",
            "        [0.0343],\n",
            "        [0.1080],\n",
            "        [0.0026],\n",
            "        [0.1511],\n",
            "        [0.0408],\n",
            "        [0.7346],\n",
            "        [0.0364],\n",
            "        [0.1725],\n",
            "        [0.0418],\n",
            "        [0.3718],\n",
            "        [0.1438],\n",
            "        [0.7239],\n",
            "        [0.4759],\n",
            "        [0.4037],\n",
            "        [0.1645],\n",
            "        [0.0528],\n",
            "        [0.4105],\n",
            "        [0.2687],\n",
            "        [0.5844],\n",
            "        [0.2843],\n",
            "        [0.4874],\n",
            "        [0.0639],\n",
            "        [0.5438],\n",
            "        [0.1183],\n",
            "        [0.2572],\n",
            "        [0.1292],\n",
            "        [0.0502],\n",
            "        [0.2799],\n",
            "        [0.0220],\n",
            "        [0.0551],\n",
            "        [0.1749],\n",
            "        [1.0000],\n",
            "        [0.2985],\n",
            "        [0.2746],\n",
            "        [0.1210],\n",
            "        [0.2282],\n",
            "        [0.1563],\n",
            "        [0.0044],\n",
            "        [0.0947],\n",
            "        [0.0024],\n",
            "        [0.0898],\n",
            "        [0.6397],\n",
            "        [0.1816],\n",
            "        [0.1595],\n",
            "        [0.0505],\n",
            "        [0.0332],\n",
            "        [0.2777],\n",
            "        [0.2316],\n",
            "        [0.4605],\n",
            "        [0.4327],\n",
            "        [0.9659],\n",
            "        [1.0000],\n",
            "        [0.5618],\n",
            "        [1.0000],\n",
            "        [0.2377],\n",
            "        [1.0000],\n",
            "        [0.2695],\n",
            "        [0.2265],\n",
            "        [1.0000],\n",
            "        [0.8716],\n",
            "        [0.9072],\n",
            "        [0.4918],\n",
            "        [0.7141],\n",
            "        [0.6613],\n",
            "        [0.1570],\n",
            "        [0.0376],\n",
            "        [0.7293],\n",
            "        [1.0000],\n",
            "        [0.0412],\n",
            "        [0.9940],\n",
            "        [0.7583],\n",
            "        [0.6002],\n",
            "        [0.9257],\n",
            "        [1.0000],\n",
            "        [0.2289],\n",
            "        [0.4206],\n",
            "        [1.0000],\n",
            "        [0.2817],\n",
            "        [1.0000],\n",
            "        [0.8942],\n",
            "        [0.2719],\n",
            "        [0.4605],\n",
            "        [0.4810],\n",
            "        [1.0000],\n",
            "        [0.3921],\n",
            "        [0.0718],\n",
            "        [1.0000],\n",
            "        [0.1449],\n",
            "        [0.0614],\n",
            "        [0.4447],\n",
            "        [0.1322],\n",
            "        [0.0595],\n",
            "        [0.0228],\n",
            "        [0.1957],\n",
            "        [0.5333],\n",
            "        [0.5391],\n",
            "        [0.5046],\n",
            "        [0.0473],\n",
            "        [0.0665],\n",
            "        [0.0315],\n",
            "        [0.1070],\n",
            "        [0.0525],\n",
            "        [0.0399],\n",
            "        [0.0603],\n",
            "        [0.0274],\n",
            "        [0.4739],\n",
            "        [1.0000],\n",
            "        [0.4302],\n",
            "        [0.2647],\n",
            "        [0.6847],\n",
            "        [0.0183],\n",
            "        [0.4492],\n",
            "        [0.7767],\n",
            "        [0.4579],\n",
            "        [0.6582],\n",
            "        [1.0000],\n",
            "        [0.2856],\n",
            "        [0.1948],\n",
            "        [0.9992],\n",
            "        [0.1265],\n",
            "        [0.6090],\n",
            "        [0.6852],\n",
            "        [0.3240],\n",
            "        [0.2183],\n",
            "        [0.0434],\n",
            "        [0.3677],\n",
            "        [0.2207],\n",
            "        [0.3095],\n",
            "        [0.2036],\n",
            "        [0.4368],\n",
            "        [0.2408],\n",
            "        [0.7867],\n",
            "        [0.2307],\n",
            "        [0.0076],\n",
            "        [0.0100],\n",
            "        [0.0456],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.0895],\n",
            "        [0.1237],\n",
            "        [1.0000],\n",
            "        [0.1877],\n",
            "        [0.0228],\n",
            "        [0.0620],\n",
            "        [0.0360],\n",
            "        [0.0190],\n",
            "        [0.0359],\n",
            "        [1.0000],\n",
            "        [0.1933],\n",
            "        [0.1422],\n",
            "        [0.4407],\n",
            "        [0.3850],\n",
            "        [0.4445],\n",
            "        [0.1076],\n",
            "        [0.0118],\n",
            "        [0.9129],\n",
            "        [0.0531],\n",
            "        [0.1282],\n",
            "        [0.2476],\n",
            "        [0.0889],\n",
            "        [0.1460],\n",
            "        [0.0403],\n",
            "        [0.3762],\n",
            "        [0.4222],\n",
            "        [0.8270],\n",
            "        [0.5851],\n",
            "        [0.3215],\n",
            "        [0.1072],\n",
            "        [0.4636],\n",
            "        [0.1054],\n",
            "        [0.8156],\n",
            "        [0.7890],\n",
            "        [0.6570],\n",
            "        [0.3806],\n",
            "        [0.3416],\n",
            "        [0.4413],\n",
            "        [0.1779],\n",
            "        [0.4075],\n",
            "        [0.2169],\n",
            "        [1.0000],\n",
            "        [0.4967],\n",
            "        [0.4373],\n",
            "        [0.1869],\n",
            "        [0.4829],\n",
            "        [0.6098],\n",
            "        [0.0657],\n",
            "        [0.9624],\n",
            "        [0.0498],\n",
            "        [0.5223],\n",
            "        [0.7793],\n",
            "        [0.1453],\n",
            "        [0.0397],\n",
            "        [0.6209],\n",
            "        [0.4188],\n",
            "        [0.0990],\n",
            "        [1.0000],\n",
            "        [0.4010],\n",
            "        [0.4813],\n",
            "        [0.3114],\n",
            "        [0.2604],\n",
            "        [1.0000],\n",
            "        [0.1772],\n",
            "        [0.2613],\n",
            "        [0.1874],\n",
            "        [0.2576],\n",
            "        [0.0025],\n",
            "        [0.6538],\n",
            "        [0.5346],\n",
            "        [0.0989],\n",
            "        [0.1428],\n",
            "        [0.3265],\n",
            "        [0.9017],\n",
            "        [0.0539],\n",
            "        [0.4693],\n",
            "        [0.3366],\n",
            "        [0.2103],\n",
            "        [0.2440],\n",
            "        [0.0706],\n",
            "        [0.5123],\n",
            "        [0.9074],\n",
            "        [0.5136],\n",
            "        [0.7793],\n",
            "        [0.2562],\n",
            "        [0.1391],\n",
            "        [0.4527],\n",
            "        [0.0129],\n",
            "        [0.6433],\n",
            "        [0.0171],\n",
            "        [0.3953],\n",
            "        [0.2413],\n",
            "        [0.0738],\n",
            "        [1.0000],\n",
            "        [0.1853],\n",
            "        [0.3294],\n",
            "        [0.7567],\n",
            "        [0.1775],\n",
            "        [0.1036],\n",
            "        [1.0000],\n",
            "        [0.3665],\n",
            "        [0.9694],\n",
            "        [0.1885],\n",
            "        [0.0317],\n",
            "        [0.2455],\n",
            "        [0.6648],\n",
            "        [0.4269],\n",
            "        [0.2590],\n",
            "        [0.2987],\n",
            "        [0.9532],\n",
            "        [0.0826],\n",
            "        [0.0408],\n",
            "        [0.7859],\n",
            "        [0.4450],\n",
            "        [0.7816],\n",
            "        [0.0473],\n",
            "        [0.0377],\n",
            "        [0.1943],\n",
            "        [0.1328],\n",
            "        [0.0661],\n",
            "        [0.5315],\n",
            "        [0.1037],\n",
            "        [0.1577],\n",
            "        [0.5936],\n",
            "        [0.1237],\n",
            "        [0.2647],\n",
            "        [0.1817],\n",
            "        [0.8354],\n",
            "        [0.1770],\n",
            "        [0.1607],\n",
            "        [0.3526],\n",
            "        [0.5014],\n",
            "        [0.5175],\n",
            "        [0.3798],\n",
            "        [0.0930],\n",
            "        [0.5243],\n",
            "        [0.5124],\n",
            "        [0.0924],\n",
            "        [0.4939],\n",
            "        [0.5563],\n",
            "        [0.3920],\n",
            "        [0.2285],\n",
            "        [0.4212],\n",
            "        [0.1723],\n",
            "        [0.6358],\n",
            "        [0.9434],\n",
            "        [0.0982],\n",
            "        [0.0228],\n",
            "        [0.2217],\n",
            "        [0.1136],\n",
            "        [0.4089],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.0437],\n",
            "        [0.1724],\n",
            "        [0.6244],\n",
            "        [0.1964],\n",
            "        [0.3551],\n",
            "        [0.2972],\n",
            "        [0.2562],\n",
            "        [0.2121],\n",
            "        [0.0501],\n",
            "        [0.6816],\n",
            "        [0.5989],\n",
            "        [0.6726],\n",
            "        [0.2104],\n",
            "        [0.2923],\n",
            "        [0.1058],\n",
            "        [0.2335],\n",
            "        [0.2196],\n",
            "        [0.1930],\n",
            "        [0.2590],\n",
            "        [0.0788],\n",
            "        [0.4757],\n",
            "        [0.1454],\n",
            "        [0.1190],\n",
            "        [0.2494],\n",
            "        [0.4061],\n",
            "        [0.0910],\n",
            "        [0.4658],\n",
            "        [0.1930],\n",
            "        [0.6326],\n",
            "        [0.4888],\n",
            "        [0.1005],\n",
            "        [0.2478],\n",
            "        [0.0018],\n",
            "        [0.2249],\n",
            "        [0.7536],\n",
            "        [0.1505],\n",
            "        [0.1553],\n",
            "        [0.3978],\n",
            "        [0.4769],\n",
            "        [0.2891],\n",
            "        [0.1654],\n",
            "        [1.0000],\n",
            "        [0.2052],\n",
            "        [0.0638],\n",
            "        [0.5705],\n",
            "        [0.1071],\n",
            "        [0.4708],\n",
            "        [0.6598],\n",
            "        [0.1951],\n",
            "        [0.2322],\n",
            "        [0.2209],\n",
            "        [0.3357],\n",
            "        [0.1046],\n",
            "        [0.7737],\n",
            "        [0.1274],\n",
            "        [0.0779],\n",
            "        [0.1069],\n",
            "        [0.7015],\n",
            "        [0.9708],\n",
            "        [0.1301],\n",
            "        [0.2762],\n",
            "        [0.0959],\n",
            "        [0.0259],\n",
            "        [0.7080],\n",
            "        [0.0400],\n",
            "        [0.2310],\n",
            "        [0.7622],\n",
            "        [0.9172],\n",
            "        [1.0000],\n",
            "        [0.2985],\n",
            "        [1.0000],\n",
            "        [0.4041],\n",
            "        [0.7114],\n",
            "        [0.0363],\n",
            "        [0.0141],\n",
            "        [0.2857],\n",
            "        [0.0458],\n",
            "        [0.2116],\n",
            "        [0.2152],\n",
            "        [0.2761],\n",
            "        [0.5560],\n",
            "        [0.1955],\n",
            "        [0.0223],\n",
            "        [0.0852],\n",
            "        [0.0292],\n",
            "        [0.0024],\n",
            "        [0.0104],\n",
            "        [0.0211],\n",
            "        [0.8732],\n",
            "        [0.1959],\n",
            "        [0.3845],\n",
            "        [0.1260],\n",
            "        [0.1769],\n",
            "        [0.2238],\n",
            "        [0.0428],\n",
            "        [0.1085],\n",
            "        [0.0677],\n",
            "        [0.5095],\n",
            "        [0.1454],\n",
            "        [0.9673],\n",
            "        [0.2472],\n",
            "        [0.1108],\n",
            "        [0.1216],\n",
            "        [0.1773],\n",
            "        [0.0987],\n",
            "        [0.2681],\n",
            "        [0.6009],\n",
            "        [0.1177],\n",
            "        [0.2673],\n",
            "        [0.1533],\n",
            "        [0.3452],\n",
            "        [0.0840],\n",
            "        [0.3269],\n",
            "        [0.2839],\n",
            "        [0.1793],\n",
            "        [0.9559],\n",
            "        [0.3155],\n",
            "        [0.1336],\n",
            "        [0.4224],\n",
            "        [0.6924],\n",
            "        [0.8656],\n",
            "        [0.4098],\n",
            "        [0.1198],\n",
            "        [0.1573]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model specification that will trained using word2vec vectors\n",
        "linearRegressionForWordEmbedding =  nn.Linear(100,1)\n",
        "optimizerForWordEmbedding = torch.optim.SGD(linearRegressionForWordEmbedding.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "nSeng9Ebdzb1"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################################### Code for training linear model #######################################\n",
        "# train model with 100 epochs\n",
        "%time training(linearRegressionForWordEmbedding,optimizerForWordEmbedding,100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef325NoFYKe9",
        "outputId": "9e43d9d3-d604-4a76-fca9-45f6925c851c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0000 dev loss= 0.16285279\n",
            "Epoch: 0010 dev loss= 0.16140001\n",
            "Epoch: 0020 dev loss= 0.15997556\n",
            "Epoch: 0030 dev loss= 0.15857889\n",
            "Epoch: 0040 dev loss= 0.15720941\n",
            "Epoch: 0050 dev loss= 0.15586668\n",
            "Epoch: 0060 dev loss= 0.15455012\n",
            "Epoch: 0070 dev loss= 0.15325919\n",
            "Epoch: 0080 dev loss= 0.15199341\n",
            "Epoch: 0090 dev loss= 0.15075228\n",
            "=========================================================\n",
            "Optimised: training loss= 0.144883811\n",
            "Optimised: dev loss= 0.149655968\n",
            "=========================================================\n",
            "CPU times: user 112 ms, sys: 19 ms, total: 131 ms\n",
            "Wall time: 126 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj4ogp1Rq3Tq"
      },
      "source": [
        "## 3.1 Accuracy [1pt]\n",
        "\n",
        "Calculate the accuracy of your model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time testing(linearRegressionForWordEmbedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gvXqVJmgYmJ",
        "outputId": "dd6b82f8-c958-43b6-ff01-beb7d8da8fee"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================\n",
            "Optimised: training loss= 0.144883811\n",
            "Optimised: dev loss= 0.149655968\n",
            "=========================================================\n",
            "Testing loss= 0.128177151\n",
            "Absolute mean square loss difference: 0.021478817\n",
            "CPU times: user 1.98 ms, sys: 0 ns, total: 1.98 ms\n",
            "Wall time: 1.99 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVXaNbLlq3fJ"
      },
      "source": [
        "## 3.2 Speed [1pt]\n",
        "\n",
        "Calcualte how long it takes your model to be evaluated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "zp8q-nZOq3ko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "804de832-8c9b-4339-c14f-f4bbaec1572f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 300 µs, sys: 1.01 ms, total: 1.31 ms\n",
            "Wall time: 795 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1282, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# recording time taken to evaluate model\n",
        "%time mse(linearRegressionForWordEmbedding(x_test_data), y_test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total time taken is 1.31 milliseconds"
      ],
      "metadata": {
        "id": "ZpRDpxuGCOW1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOT_5vmFbGy1"
      },
      "source": [
        "# 4 - Open-Ended Improvement\n",
        "\n",
        "This section relates to content from **the week 1, 2, and 3 lectures and the week 1, 2, and 3 labs**.\n",
        "\n",
        "This section is an open-ended opportunity to find ways to make your model more accurate and/or faster (e.g., use WordNet to generalise words, try different word features, other optimisers, etc).\n",
        "\n",
        "We encourage you to try several ideas to provide scope for comparisons.\n",
        "\n",
        "If none of your ideas work you can still get full marks for this section. You just need to justify the ideas and discuss why they may not have improved performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zryd7CmcrIjU"
      },
      "source": [
        "## 4.1 Ideas and Motivation [1pt]\n",
        "\n",
        "In **this** box, describe your ideas and why you think they will improve accuracy and/or speed.\n",
        "\n",
        "*   Approch 1 :  removing stopwords and punctuation + increasing epochs to 1000 \n",
        "\n",
        "\n",
        "> Aim of removing stopwords is to remove tokens that have no meaning and no importance from the vocabulary. this would amount in the model being more meaningful hence more accurate. As model uses vectors of length 100 the time taken to train is around 100ms this indicates that a even better result can be acheived by training more and still gain results within reasonable time.\n",
        "\n",
        "\n",
        "*   Approch 2 :  Using the Fast Text instead of Word2Vec + increasing the learning rate\n",
        "\n",
        "\n",
        "> Aim to better the model by learning embeddings at an n-gram level instead of at the word level to increase accuracy + Aim to achieve better accuracy by increasing the gradiaent displacement in each learning cycle\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jn1aesgGrJSn"
      },
      "source": [
        "## 4.2 Implementation [2pt]\n",
        "\n",
        "Implement your ideas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Approch 1"
      ],
      "metadata": {
        "id": "BGTh36qpEtes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating list of tokens that need to be removed from the corpus\n",
        "stopwordsAndPunctuation = []\n",
        "stopwordsAndPunctuation.extend(string.punctuation)\n",
        "stopwordsAndPunctuation.extend(sw.words())"
      ],
      "metadata": {
        "id": "RwuYhv1Eu7iG"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to remove stopwords and punctuation from the provided list of tokens\n",
        "def removeStopwordsAndPunctuation(words): \n",
        "  return list(filter(lambda x:not x in stopwordsAndPunctuation, words))"
      ],
      "metadata": {
        "id": "tMymfhLYtx_2"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code for removing stopwords and punctuation from all datasets\n",
        "training_text_tokenized_new = [removeStopwordsAndPunctuation(tokens) for tokens in training_text_tokenized]\n",
        "dev_text_tokenized_new = [removeStopwordsAndPunctuation(tokens) for tokens in dev_text_tokenized]\n",
        "test_text_tokenized_new = [removeStopwordsAndPunctuation(tokens) for tokens in test_text_tokenized]"
      ],
      "metadata": {
        "id": "RwJFCadSgeLF"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# specification of model being trained on dataset with stopwords and punctuation removed\n",
        "linearRegressionForAp1 =  nn.Linear(100,1)\n",
        "optimizerForAp1 = torch.optim.SGD(linearRegressionForAp1.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "G4uUjQVL0mCf"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word2vec model learning word embedding from dataset with stopwords and punctuation removed\n",
        "word_embeddings_model_ap1 = Word2Vec(sentences=training_text_tokenized_new, size=100, window=5, min_count=10, workers=2, sg=0)"
      ],
      "metadata": {
        "id": "3rsG2WN7zV6a"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generating a mean word2vec vector for documents in each dataset\n",
        "x_training_word_embeddings_tensor_ap1 = getAvgVectors(training_text_tokenized_new,word_embeddings_model_ap1)\n",
        "x_dev_word_embeddings_tensor_ap1 = getAvgVectors(dev_text_tokenized_new,word_embeddings_model_ap1)\n",
        "x_test_word_embeddings_tensor_ap1 = getAvgVectors(test_text_tokenized_new,word_embeddings_model_ap1)"
      ],
      "metadata": {
        "id": "H02FaWTazcY9"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# populating data that will be used in training and testing of model\n",
        "x_data = x_training_word_embeddings_tensor_ap1.float()\n",
        "y_data = y_training_data_tensor.float()\n",
        "x_dev_data = x_dev_word_embeddings_tensor_ap1.float()\n",
        "y_dev_data = y_dev_data_tensor.float()\n",
        "x_test_data = x_test_word_embeddings_tensor_ap1.float()\n",
        "y_test_data = y_test_data_tensor.float()"
      ],
      "metadata": {
        "id": "38cKdbr8zeN2"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('x_data',x_data)\n",
        "print('x_dev_data',x_dev_data)\n",
        "print('x_test_data',x_test_data)"
      ],
      "metadata": {
        "id": "q3u7zhoQW0Gb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ed552b8-dc6b-47c7-869a-a2ef7b64338b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_data tensor([[-0.1702,  0.1000,  0.0085,  ...,  0.0720, -0.1330,  0.1746],\n",
            "        [-0.2561,  0.1278, -0.0843,  ...,  0.1324, -0.0095,  0.1355],\n",
            "        [-0.3705,  0.1042, -0.2515,  ...,  0.3621,  0.0111,  0.1001],\n",
            "        ...,\n",
            "        [-0.3415, -0.0035,  0.0352,  ...,  0.1716, -0.2742,  0.2558],\n",
            "        [-0.2405,  0.1128, -0.1940,  ...,  0.2752, -0.0928,  0.1537],\n",
            "        [-0.1679,  0.1122,  0.0311,  ...,  0.0565, -0.0539,  0.0962]])\n",
            "x_dev_data tensor([[-0.0047,  0.1255,  0.1215,  ..., -0.1362,  0.2402,  0.1910],\n",
            "        [-0.0896,  0.1010, -0.0394,  ...,  0.0113,  0.0367,  0.0370],\n",
            "        [-0.0291,  0.1147,  0.0927,  ..., -0.0941,  0.1721,  0.1373],\n",
            "        ...,\n",
            "        [-0.4617,  0.0448, -0.1124,  ...,  0.4191,  0.1006,  0.0458],\n",
            "        [ 0.0059,  0.1472,  0.1590,  ..., -0.1388,  0.2910,  0.1228],\n",
            "        [-0.0785,  0.0955,  0.1452,  ..., -0.0463,  0.2217,  0.1459]])\n",
            "x_test_data tensor([[-0.2756,  0.0254,  0.1546,  ...,  0.1448, -0.1768,  0.4000],\n",
            "        [-0.3451,  0.0397, -0.1065,  ...,  0.2935,  0.0240,  0.0674],\n",
            "        [-0.0102,  0.1305,  0.0576,  ..., -0.1044,  0.2471,  0.1305],\n",
            "        ...,\n",
            "        [-0.2371,  0.0343,  0.0667,  ...,  0.1108, -0.1735,  0.1873],\n",
            "        [-0.0987,  0.0834, -0.0476,  ...,  0.0087,  0.0260,  0.0926],\n",
            "        [-0.1105,  0.1093, -0.0553,  ...,  0.0311, -0.0253,  0.0592]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('y_data',y_data)\n",
        "print('y_dev_data',y_dev_data)\n",
        "print('y_test_data',y_test_data)"
      ],
      "metadata": {
        "id": "nEV6VdlnW04r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27dc3bb7-e164-4aae-c5dc-9e0dac4936d2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_data tensor([[0.6453],\n",
            "        [0.3528],\n",
            "        [0.1265],\n",
            "        ...,\n",
            "        [0.5215],\n",
            "        [0.0191],\n",
            "        [0.1101]])\n",
            "y_dev_data tensor([[0.0552],\n",
            "        [0.0999],\n",
            "        [0.1331],\n",
            "        [0.0461],\n",
            "        [0.5329],\n",
            "        [0.3803],\n",
            "        [0.7429],\n",
            "        [0.3737],\n",
            "        [0.1130],\n",
            "        [0.4459],\n",
            "        [0.8221],\n",
            "        [0.5769],\n",
            "        [0.0800],\n",
            "        [0.0039],\n",
            "        [0.8192],\n",
            "        [0.2340],\n",
            "        [0.3241],\n",
            "        [0.4813],\n",
            "        [0.1308],\n",
            "        [0.1061],\n",
            "        [0.0964],\n",
            "        [0.4800],\n",
            "        [0.3005],\n",
            "        [0.4446],\n",
            "        [0.6819],\n",
            "        [0.0624],\n",
            "        [0.0023],\n",
            "        [0.6516],\n",
            "        [0.1084],\n",
            "        [0.0338],\n",
            "        [0.1668],\n",
            "        [1.0000],\n",
            "        [0.0378],\n",
            "        [0.7162],\n",
            "        [1.0000],\n",
            "        [0.4729],\n",
            "        [0.1461],\n",
            "        [0.0339],\n",
            "        [0.1397],\n",
            "        [0.0467],\n",
            "        [0.0139],\n",
            "        [0.1381],\n",
            "        [0.0618],\n",
            "        [0.6992],\n",
            "        [0.0825],\n",
            "        [0.1998],\n",
            "        [0.3397],\n",
            "        [0.3242],\n",
            "        [0.8384],\n",
            "        [0.6603],\n",
            "        [0.1526],\n",
            "        [0.4454],\n",
            "        [0.5000],\n",
            "        [0.1777],\n",
            "        [0.3162],\n",
            "        [0.4711],\n",
            "        [1.0000],\n",
            "        [0.0682],\n",
            "        [1.0000],\n",
            "        [0.0045],\n",
            "        [0.1025],\n",
            "        [0.3801],\n",
            "        [0.4676],\n",
            "        [1.0000],\n",
            "        [0.0698],\n",
            "        [0.1510],\n",
            "        [0.1671],\n",
            "        [0.9450],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.1527],\n",
            "        [0.4708],\n",
            "        [0.1268],\n",
            "        [0.2870],\n",
            "        [0.3339],\n",
            "        [0.1383],\n",
            "        [0.5040],\n",
            "        [0.0370],\n",
            "        [0.1159],\n",
            "        [0.2667],\n",
            "        [0.6404],\n",
            "        [0.7743],\n",
            "        [0.7592],\n",
            "        [0.5285],\n",
            "        [0.7861],\n",
            "        [0.9499],\n",
            "        [0.3047],\n",
            "        [0.1033],\n",
            "        [0.0131],\n",
            "        [0.1359],\n",
            "        [1.0000],\n",
            "        [0.6687],\n",
            "        [0.3711],\n",
            "        [0.0019],\n",
            "        [0.1374],\n",
            "        [0.0550],\n",
            "        [0.4501],\n",
            "        [0.0871],\n",
            "        [0.0251],\n",
            "        [0.0958],\n",
            "        [0.7153],\n",
            "        [0.2709],\n",
            "        [0.0938],\n",
            "        [0.0630],\n",
            "        [0.5334],\n",
            "        [0.7670],\n",
            "        [0.2958],\n",
            "        [1.0000],\n",
            "        [0.0533],\n",
            "        [0.1070],\n",
            "        [1.0000],\n",
            "        [0.2736],\n",
            "        [0.1435],\n",
            "        [0.0660],\n",
            "        [0.0499],\n",
            "        [0.1667],\n",
            "        [0.0373],\n",
            "        [0.0993],\n",
            "        [0.0466],\n",
            "        [0.3042],\n",
            "        [0.1685],\n",
            "        [0.0732],\n",
            "        [0.0373],\n",
            "        [0.0412],\n",
            "        [1.0000],\n",
            "        [0.1720],\n",
            "        [1.0000],\n",
            "        [0.4960],\n",
            "        [0.1058],\n",
            "        [0.1516],\n",
            "        [0.1190],\n",
            "        [0.0278],\n",
            "        [0.0161],\n",
            "        [0.0811],\n",
            "        [0.0274],\n",
            "        [0.2107],\n",
            "        [0.2254],\n",
            "        [0.0354],\n",
            "        [0.0276],\n",
            "        [0.2861],\n",
            "        [0.4141],\n",
            "        [0.0063],\n",
            "        [0.1041],\n",
            "        [0.1422],\n",
            "        [0.0026],\n",
            "        [0.5488],\n",
            "        [0.0083],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.1772],\n",
            "        [0.1442],\n",
            "        [0.6086],\n",
            "        [0.1025],\n",
            "        [0.1059],\n",
            "        [0.5772],\n",
            "        [0.0464],\n",
            "        [0.3392],\n",
            "        [0.1572],\n",
            "        [0.2298],\n",
            "        [0.1472],\n",
            "        [0.1704],\n",
            "        [0.1909],\n",
            "        [0.5225],\n",
            "        [0.5311],\n",
            "        [0.0995],\n",
            "        [1.0000],\n",
            "        [0.9419],\n",
            "        [0.2544],\n",
            "        [0.1917],\n",
            "        [0.5731],\n",
            "        [0.0576],\n",
            "        [0.4418],\n",
            "        [0.4653],\n",
            "        [0.5705],\n",
            "        [0.1428],\n",
            "        [0.2416],\n",
            "        [0.9614],\n",
            "        [0.1927],\n",
            "        [0.2578],\n",
            "        [1.0000],\n",
            "        [0.0605],\n",
            "        [0.8633],\n",
            "        [0.2742],\n",
            "        [0.0922],\n",
            "        [0.1719],\n",
            "        [0.3184],\n",
            "        [0.5352],\n",
            "        [0.0855],\n",
            "        [0.2844],\n",
            "        [0.6468],\n",
            "        [0.2538],\n",
            "        [0.6768],\n",
            "        [0.1783],\n",
            "        [0.1734],\n",
            "        [1.0000],\n",
            "        [0.1903],\n",
            "        [0.3684],\n",
            "        [0.1791],\n",
            "        [0.5791],\n",
            "        [0.1715],\n",
            "        [0.2113],\n",
            "        [0.5502],\n",
            "        [0.0636],\n",
            "        [0.9030],\n",
            "        [0.9305],\n",
            "        [0.0810],\n",
            "        [0.5443],\n",
            "        [0.1210],\n",
            "        [0.0411],\n",
            "        [0.0696],\n",
            "        [0.0202],\n",
            "        [1.0000],\n",
            "        [0.1869],\n",
            "        [0.0955],\n",
            "        [0.2788],\n",
            "        [0.0526],\n",
            "        [0.2637],\n",
            "        [0.2653],\n",
            "        [0.5137],\n",
            "        [0.2417],\n",
            "        [0.5192],\n",
            "        [0.0616],\n",
            "        [0.0589],\n",
            "        [0.2975],\n",
            "        [0.1366],\n",
            "        [0.1460],\n",
            "        [1.0000],\n",
            "        [0.2907],\n",
            "        [0.0478],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.8466],\n",
            "        [1.0000],\n",
            "        [0.5458],\n",
            "        [0.0836],\n",
            "        [0.0661],\n",
            "        [0.5950],\n",
            "        [0.1564],\n",
            "        [0.7383],\n",
            "        [0.1482],\n",
            "        [0.0874],\n",
            "        [0.1036],\n",
            "        [0.0136],\n",
            "        [0.1710],\n",
            "        [0.3181],\n",
            "        [0.0932],\n",
            "        [0.1279],\n",
            "        [0.0738],\n",
            "        [0.5986],\n",
            "        [0.1309],\n",
            "        [0.5684],\n",
            "        [0.4329],\n",
            "        [0.4022],\n",
            "        [0.0509],\n",
            "        [1.0000],\n",
            "        [0.0930],\n",
            "        [0.3622],\n",
            "        [0.6285],\n",
            "        [0.0204],\n",
            "        [0.0400],\n",
            "        [0.4648],\n",
            "        [0.4888],\n",
            "        [0.0746],\n",
            "        [0.5997],\n",
            "        [0.1226],\n",
            "        [0.1428],\n",
            "        [1.0000],\n",
            "        [0.2761],\n",
            "        [0.8673],\n",
            "        [0.5736],\n",
            "        [0.0904],\n",
            "        [0.2847],\n",
            "        [0.1933],\n",
            "        [0.9925],\n",
            "        [0.0530],\n",
            "        [1.0000],\n",
            "        [0.3818],\n",
            "        [0.1926],\n",
            "        [0.2347],\n",
            "        [0.0495],\n",
            "        [0.1507],\n",
            "        [0.0944],\n",
            "        [0.6934],\n",
            "        [0.3214],\n",
            "        [0.0658],\n",
            "        [0.4168],\n",
            "        [0.0598],\n",
            "        [0.0755],\n",
            "        [0.3732],\n",
            "        [0.1074],\n",
            "        [0.1907],\n",
            "        [0.0793],\n",
            "        [0.0125],\n",
            "        [0.6042],\n",
            "        [0.2933],\n",
            "        [0.0921],\n",
            "        [0.1638],\n",
            "        [0.5166],\n",
            "        [0.1108],\n",
            "        [0.1479],\n",
            "        [0.6797],\n",
            "        [0.0729],\n",
            "        [0.3447],\n",
            "        [0.1113],\n",
            "        [0.0074],\n",
            "        [0.3192],\n",
            "        [0.0732],\n",
            "        [0.4896],\n",
            "        [0.0898],\n",
            "        [0.2058],\n",
            "        [0.1809],\n",
            "        [0.4949],\n",
            "        [0.1215],\n",
            "        [0.5396],\n",
            "        [0.3673],\n",
            "        [0.4221],\n",
            "        [0.5566],\n",
            "        [0.1831],\n",
            "        [0.1356],\n",
            "        [0.1146],\n",
            "        [0.2202],\n",
            "        [0.0026],\n",
            "        [0.2610],\n",
            "        [0.3612],\n",
            "        [0.2210],\n",
            "        [0.0115],\n",
            "        [0.1540],\n",
            "        [0.1382],\n",
            "        [0.0398],\n",
            "        [0.2324],\n",
            "        [0.0707],\n",
            "        [0.2244],\n",
            "        [0.3915],\n",
            "        [0.7267],\n",
            "        [0.0852],\n",
            "        [0.9519],\n",
            "        [0.8890],\n",
            "        [1.0000],\n",
            "        [0.0270],\n",
            "        [0.8057],\n",
            "        [0.2766],\n",
            "        [1.0000],\n",
            "        [0.3670],\n",
            "        [0.5905],\n",
            "        [0.8443],\n",
            "        [0.0209],\n",
            "        [0.0020],\n",
            "        [0.4240],\n",
            "        [0.1114],\n",
            "        [0.2551],\n",
            "        [1.0000],\n",
            "        [0.1128],\n",
            "        [0.0226],\n",
            "        [0.0706],\n",
            "        [0.1425],\n",
            "        [0.5396],\n",
            "        [0.2499],\n",
            "        [0.4385],\n",
            "        [0.0569],\n",
            "        [0.7493],\n",
            "        [0.4873],\n",
            "        [1.0000],\n",
            "        [0.0396],\n",
            "        [0.0212],\n",
            "        [0.0917],\n",
            "        [0.4900],\n",
            "        [0.3780],\n",
            "        [0.9537],\n",
            "        [0.5273],\n",
            "        [0.5015],\n",
            "        [0.4526],\n",
            "        [0.6640],\n",
            "        [0.9036],\n",
            "        [0.6609],\n",
            "        [0.6129],\n",
            "        [0.0723],\n",
            "        [0.4331],\n",
            "        [0.6472],\n",
            "        [0.3413],\n",
            "        [0.1697],\n",
            "        [0.5351],\n",
            "        [0.3211],\n",
            "        [0.0349],\n",
            "        [0.1421],\n",
            "        [0.0347],\n",
            "        [0.1976],\n",
            "        [1.0000],\n",
            "        [0.9426],\n",
            "        [0.3868],\n",
            "        [0.0022],\n",
            "        [0.9736],\n",
            "        [0.5517],\n",
            "        [1.0000],\n",
            "        [0.0039],\n",
            "        [0.4918],\n",
            "        [0.4659],\n",
            "        [1.0000],\n",
            "        [0.4971],\n",
            "        [1.0000],\n",
            "        [0.6098],\n",
            "        [0.1030],\n",
            "        [0.1271],\n",
            "        [0.4269],\n",
            "        [0.7659],\n",
            "        [0.4114],\n",
            "        [0.3915],\n",
            "        [0.4465],\n",
            "        [0.2480],\n",
            "        [0.0216],\n",
            "        [0.0492],\n",
            "        [0.0514],\n",
            "        [0.0448],\n",
            "        [0.1160],\n",
            "        [0.0409],\n",
            "        [0.0487],\n",
            "        [0.0296],\n",
            "        [0.1258],\n",
            "        [0.0222],\n",
            "        [0.0288],\n",
            "        [0.0175],\n",
            "        [0.0245],\n",
            "        [0.0724],\n",
            "        [0.0415],\n",
            "        [0.0395],\n",
            "        [0.0638],\n",
            "        [0.0335],\n",
            "        [0.0989],\n",
            "        [0.0658],\n",
            "        [0.2023],\n",
            "        [0.0483],\n",
            "        [0.0398],\n",
            "        [0.0274],\n",
            "        [0.0792],\n",
            "        [0.0168],\n",
            "        [0.1511],\n",
            "        [0.0379],\n",
            "        [0.2555],\n",
            "        [0.1387],\n",
            "        [0.1587],\n",
            "        [0.8037],\n",
            "        [0.7510],\n",
            "        [0.0354],\n",
            "        [0.4384],\n",
            "        [0.6548],\n",
            "        [0.1266],\n",
            "        [0.1825],\n",
            "        [0.1372],\n",
            "        [0.1137],\n",
            "        [0.0497],\n",
            "        [0.0733],\n",
            "        [0.2562],\n",
            "        [0.3874],\n",
            "        [0.3403],\n",
            "        [0.0549],\n",
            "        [0.0350],\n",
            "        [0.4400],\n",
            "        [0.0963],\n",
            "        [0.8298],\n",
            "        [0.2418],\n",
            "        [0.4063],\n",
            "        [0.0360],\n",
            "        [0.1896],\n",
            "        [1.0000],\n",
            "        [0.6663],\n",
            "        [0.4688],\n",
            "        [0.5476],\n",
            "        [0.3494],\n",
            "        [0.4552],\n",
            "        [1.0000],\n",
            "        [0.2076],\n",
            "        [0.7823],\n",
            "        [0.3434],\n",
            "        [0.4403],\n",
            "        [0.0955],\n",
            "        [0.5256],\n",
            "        [0.2341],\n",
            "        [0.0605],\n",
            "        [0.1107],\n",
            "        [0.0388],\n",
            "        [0.0744],\n",
            "        [1.0000],\n",
            "        [0.1375],\n",
            "        [0.0163],\n",
            "        [0.5064],\n",
            "        [0.7643],\n",
            "        [0.0667],\n",
            "        [0.1421],\n",
            "        [0.0856],\n",
            "        [0.1714],\n",
            "        [0.1683],\n",
            "        [0.2343],\n",
            "        [0.0763],\n",
            "        [0.4178],\n",
            "        [0.0972],\n",
            "        [0.2800],\n",
            "        [0.0735],\n",
            "        [0.2085],\n",
            "        [0.2189],\n",
            "        [0.3422],\n",
            "        [0.1604],\n",
            "        [0.9719],\n",
            "        [1.0000],\n",
            "        [0.4589],\n",
            "        [0.2066],\n",
            "        [0.0417],\n",
            "        [0.1853],\n",
            "        [0.0815],\n",
            "        [0.0218],\n",
            "        [0.2330],\n",
            "        [0.0394],\n",
            "        [0.2955],\n",
            "        [0.3204],\n",
            "        [0.5487],\n",
            "        [0.1723],\n",
            "        [0.2869],\n",
            "        [0.3066],\n",
            "        [0.3998],\n",
            "        [0.6446],\n",
            "        [0.3397],\n",
            "        [0.2826],\n",
            "        [0.3616],\n",
            "        [0.3954],\n",
            "        [0.4052],\n",
            "        [0.2708],\n",
            "        [0.1449],\n",
            "        [1.0000],\n",
            "        [0.1041],\n",
            "        [0.7139],\n",
            "        [0.1893],\n",
            "        [0.2629],\n",
            "        [0.4443],\n",
            "        [0.7169],\n",
            "        [1.0000],\n",
            "        [0.2719],\n",
            "        [0.0344],\n",
            "        [0.0747],\n",
            "        [0.0717],\n",
            "        [0.4316],\n",
            "        [0.7741],\n",
            "        [0.0089],\n",
            "        [0.0638],\n",
            "        [1.0000],\n",
            "        [0.2871],\n",
            "        [0.2995],\n",
            "        [0.4347],\n",
            "        [0.7895],\n",
            "        [0.1105],\n",
            "        [0.2477],\n",
            "        [0.8325],\n",
            "        [0.2359],\n",
            "        [0.5043],\n",
            "        [0.3333],\n",
            "        [0.1594],\n",
            "        [0.0142],\n",
            "        [0.0622],\n",
            "        [0.0902],\n",
            "        [0.0113],\n",
            "        [0.5932],\n",
            "        [0.7026],\n",
            "        [0.1338],\n",
            "        [0.0638],\n",
            "        [0.0552],\n",
            "        [0.1671],\n",
            "        [0.0713],\n",
            "        [0.0344],\n",
            "        [0.3230],\n",
            "        [0.0671],\n",
            "        [0.0612],\n",
            "        [0.1337],\n",
            "        [0.0247],\n",
            "        [0.0798],\n",
            "        [0.3528],\n",
            "        [0.5027],\n",
            "        [0.7039],\n",
            "        [1.0000],\n",
            "        [0.2878],\n",
            "        [0.0700],\n",
            "        [0.0375],\n",
            "        [0.6571],\n",
            "        [0.0395],\n",
            "        [0.0462],\n",
            "        [0.1186],\n",
            "        [0.0335],\n",
            "        [1.0000],\n",
            "        [0.2144],\n",
            "        [0.2182],\n",
            "        [0.2033],\n",
            "        [0.6828],\n",
            "        [0.0766],\n",
            "        [0.0718],\n",
            "        [0.0861],\n",
            "        [0.0228],\n",
            "        [0.9964],\n",
            "        [1.0000],\n",
            "        [0.3780],\n",
            "        [0.2425],\n",
            "        [0.9091],\n",
            "        [0.8175],\n",
            "        [0.1943],\n",
            "        [0.3286],\n",
            "        [0.7354],\n",
            "        [0.0882],\n",
            "        [0.5753],\n",
            "        [0.0409],\n",
            "        [0.0600],\n",
            "        [0.1799],\n",
            "        [0.2281],\n",
            "        [0.5863],\n",
            "        [0.0145],\n",
            "        [0.1333],\n",
            "        [0.1519],\n",
            "        [0.5058],\n",
            "        [0.2329],\n",
            "        [0.0166],\n",
            "        [0.0221],\n",
            "        [0.2844],\n",
            "        [0.6261],\n",
            "        [1.0000],\n",
            "        [0.0738],\n",
            "        [0.3613],\n",
            "        [0.1427],\n",
            "        [0.1559],\n",
            "        [0.4143],\n",
            "        [0.0767],\n",
            "        [0.3595],\n",
            "        [0.0934],\n",
            "        [0.0290],\n",
            "        [0.6909],\n",
            "        [1.0000],\n",
            "        [0.2044],\n",
            "        [0.8456],\n",
            "        [0.1570],\n",
            "        [0.6457],\n",
            "        [0.0064],\n",
            "        [0.1708],\n",
            "        [0.0633],\n",
            "        [0.9418],\n",
            "        [0.0281],\n",
            "        [0.0086],\n",
            "        [0.6039],\n",
            "        [0.2846],\n",
            "        [0.2821],\n",
            "        [0.0696],\n",
            "        [0.2283],\n",
            "        [0.2939],\n",
            "        [0.1087],\n",
            "        [0.4184],\n",
            "        [0.5101],\n",
            "        [0.7152],\n",
            "        [0.0320],\n",
            "        [0.0797],\n",
            "        [1.0000],\n",
            "        [0.2391],\n",
            "        [0.0575],\n",
            "        [0.3524],\n",
            "        [0.3337],\n",
            "        [0.1137],\n",
            "        [0.2390],\n",
            "        [0.2283],\n",
            "        [0.1761],\n",
            "        [0.1389],\n",
            "        [0.4430],\n",
            "        [0.0732],\n",
            "        [0.1607],\n",
            "        [1.0000],\n",
            "        [0.5644],\n",
            "        [0.1314],\n",
            "        [0.4022],\n",
            "        [0.2799],\n",
            "        [0.3263],\n",
            "        [0.2987],\n",
            "        [0.1683],\n",
            "        [0.9467],\n",
            "        [0.4441],\n",
            "        [0.5954],\n",
            "        [0.0029],\n",
            "        [0.1493],\n",
            "        [0.0576],\n",
            "        [0.5446],\n",
            "        [0.3687],\n",
            "        [0.1442],\n",
            "        [0.1071],\n",
            "        [0.1420],\n",
            "        [0.2088],\n",
            "        [0.5777],\n",
            "        [1.0000],\n",
            "        [0.3677],\n",
            "        [0.0383],\n",
            "        [0.0233],\n",
            "        [0.0387],\n",
            "        [0.6148],\n",
            "        [0.1195],\n",
            "        [0.1067],\n",
            "        [0.1600],\n",
            "        [0.0390],\n",
            "        [1.0000],\n",
            "        [0.0653],\n",
            "        [0.3330],\n",
            "        [0.1188],\n",
            "        [0.2913],\n",
            "        [0.0309],\n",
            "        [0.1120],\n",
            "        [0.1799],\n",
            "        [0.1419],\n",
            "        [0.1202],\n",
            "        [0.4585],\n",
            "        [0.0171],\n",
            "        [0.0464],\n",
            "        [0.5838],\n",
            "        [0.0470],\n",
            "        [0.1685],\n",
            "        [0.2367],\n",
            "        [0.7918],\n",
            "        [0.1420],\n",
            "        [0.1547],\n",
            "        [0.6156],\n",
            "        [0.1110],\n",
            "        [0.3763],\n",
            "        [0.0450],\n",
            "        [0.1245],\n",
            "        [0.1499],\n",
            "        [0.1167],\n",
            "        [0.3048],\n",
            "        [0.2895],\n",
            "        [0.0027],\n",
            "        [0.1653],\n",
            "        [0.3833],\n",
            "        [0.1507],\n",
            "        [0.0118],\n",
            "        [0.0961],\n",
            "        [0.4322],\n",
            "        [0.2814],\n",
            "        [0.4466],\n",
            "        [0.0375],\n",
            "        [0.4953],\n",
            "        [0.7260],\n",
            "        [0.2629],\n",
            "        [0.1448],\n",
            "        [0.1251],\n",
            "        [0.5530],\n",
            "        [0.6276],\n",
            "        [0.4577],\n",
            "        [0.3861],\n",
            "        [0.0430],\n",
            "        [0.1478],\n",
            "        [0.1538],\n",
            "        [0.3511],\n",
            "        [0.3679],\n",
            "        [0.1860],\n",
            "        [0.1101],\n",
            "        [1.0000],\n",
            "        [0.3395],\n",
            "        [0.4292],\n",
            "        [0.0981],\n",
            "        [0.0090],\n",
            "        [0.4104],\n",
            "        [0.5419],\n",
            "        [0.2914],\n",
            "        [1.0000],\n",
            "        [0.1407],\n",
            "        [0.7847],\n",
            "        [0.2228],\n",
            "        [0.0143],\n",
            "        [0.0894],\n",
            "        [0.1893],\n",
            "        [0.0037],\n",
            "        [0.6113],\n",
            "        [0.0227],\n",
            "        [0.0198],\n",
            "        [0.0371],\n",
            "        [0.5014],\n",
            "        [0.3955],\n",
            "        [0.1643],\n",
            "        [0.4345],\n",
            "        [0.0717],\n",
            "        [0.3588],\n",
            "        [0.1890],\n",
            "        [0.6763],\n",
            "        [0.3267],\n",
            "        [0.1317],\n",
            "        [0.0452],\n",
            "        [0.2685],\n",
            "        [0.1480],\n",
            "        [0.0739],\n",
            "        [0.0422],\n",
            "        [0.1160],\n",
            "        [0.1466],\n",
            "        [1.0000],\n",
            "        [0.2060],\n",
            "        [0.6097],\n",
            "        [1.0000],\n",
            "        [0.0402],\n",
            "        [0.0840],\n",
            "        [0.0543],\n",
            "        [0.0168],\n",
            "        [0.0684],\n",
            "        [0.3268],\n",
            "        [0.0292],\n",
            "        [0.0668],\n",
            "        [0.5577],\n",
            "        [0.1656],\n",
            "        [0.3260],\n",
            "        [0.0381],\n",
            "        [0.0306],\n",
            "        [0.0729],\n",
            "        [1.0000],\n",
            "        [0.0880],\n",
            "        [0.0707],\n",
            "        [0.1630],\n",
            "        [0.0152],\n",
            "        [0.0362],\n",
            "        [0.0739],\n",
            "        [0.0191],\n",
            "        [0.1827],\n",
            "        [0.5474],\n",
            "        [0.0467],\n",
            "        [0.7092],\n",
            "        [0.1145],\n",
            "        [0.1154],\n",
            "        [0.2286],\n",
            "        [0.0778],\n",
            "        [0.4654],\n",
            "        [0.1575],\n",
            "        [0.1722],\n",
            "        [0.1941],\n",
            "        [0.2205],\n",
            "        [0.0431],\n",
            "        [0.3764],\n",
            "        [0.3930],\n",
            "        [0.0414],\n",
            "        [0.0406],\n",
            "        [1.0000],\n",
            "        [0.4400],\n",
            "        [0.0989],\n",
            "        [0.0644],\n",
            "        [0.0305],\n",
            "        [0.4770],\n",
            "        [1.0000],\n",
            "        [0.0738],\n",
            "        [0.0432],\n",
            "        [0.1729],\n",
            "        [0.1052],\n",
            "        [0.1339],\n",
            "        [0.2162],\n",
            "        [0.0409],\n",
            "        [0.0209],\n",
            "        [0.0511],\n",
            "        [0.0054],\n",
            "        [0.0547],\n",
            "        [0.1053],\n",
            "        [0.3648],\n",
            "        [0.9354],\n",
            "        [0.4095],\n",
            "        [0.5391],\n",
            "        [0.5209],\n",
            "        [0.0213],\n",
            "        [0.0784],\n",
            "        [1.0000],\n",
            "        [0.0097],\n",
            "        [1.0000],\n",
            "        [0.0393],\n",
            "        [0.8295],\n",
            "        [0.3003],\n",
            "        [0.0799],\n",
            "        [0.2739],\n",
            "        [0.1823],\n",
            "        [0.6535],\n",
            "        [0.1375],\n",
            "        [0.5236],\n",
            "        [0.0345],\n",
            "        [0.0316],\n",
            "        [0.1064],\n",
            "        [0.1611],\n",
            "        [0.0916],\n",
            "        [0.0586],\n",
            "        [0.0865],\n",
            "        [0.7904],\n",
            "        [0.1418],\n",
            "        [0.1393],\n",
            "        [0.4854],\n",
            "        [0.3130],\n",
            "        [0.0940],\n",
            "        [0.1205],\n",
            "        [0.2234],\n",
            "        [0.3264],\n",
            "        [0.2004],\n",
            "        [0.0691],\n",
            "        [0.1346],\n",
            "        [0.1029],\n",
            "        [0.0401],\n",
            "        [0.1285],\n",
            "        [0.0555],\n",
            "        [0.2742],\n",
            "        [0.6522],\n",
            "        [0.1536],\n",
            "        [0.2144],\n",
            "        [0.0106],\n",
            "        [0.0881],\n",
            "        [0.6326],\n",
            "        [0.0255],\n",
            "        [0.0297],\n",
            "        [0.0342],\n",
            "        [0.0823],\n",
            "        [0.0510],\n",
            "        [0.0378],\n",
            "        [0.0410],\n",
            "        [0.1058],\n",
            "        [0.1704],\n",
            "        [0.0728],\n",
            "        [0.1260],\n",
            "        [0.3938],\n",
            "        [0.1562],\n",
            "        [0.5025],\n",
            "        [0.9346],\n",
            "        [0.1655],\n",
            "        [0.6490],\n",
            "        [1.0000],\n",
            "        [0.0665],\n",
            "        [0.0022],\n",
            "        [0.5275],\n",
            "        [0.1905],\n",
            "        [0.0442],\n",
            "        [0.5409],\n",
            "        [0.1910],\n",
            "        [0.4206],\n",
            "        [0.0203],\n",
            "        [0.0966],\n",
            "        [0.0752],\n",
            "        [0.0176],\n",
            "        [0.0521],\n",
            "        [0.0579],\n",
            "        [0.0392],\n",
            "        [0.0131],\n",
            "        [0.1045],\n",
            "        [0.5853],\n",
            "        [0.1313],\n",
            "        [0.1621],\n",
            "        [0.1919],\n",
            "        [0.2930],\n",
            "        [0.1693],\n",
            "        [0.0606],\n",
            "        [0.2769],\n",
            "        [0.1252],\n",
            "        [0.1136],\n",
            "        [0.2492],\n",
            "        [0.2440],\n",
            "        [0.7159],\n",
            "        [0.4882],\n",
            "        [0.3176],\n",
            "        [0.2892],\n",
            "        [0.1437],\n",
            "        [0.2928],\n",
            "        [0.1700],\n",
            "        [0.7412],\n",
            "        [0.9296],\n",
            "        [1.0000],\n",
            "        [0.6531],\n",
            "        [0.1073],\n",
            "        [0.0702],\n",
            "        [0.0782],\n",
            "        [0.1016],\n",
            "        [0.1579],\n",
            "        [0.3720],\n",
            "        [0.3677],\n",
            "        [0.3498],\n",
            "        [0.4528],\n",
            "        [0.1867],\n",
            "        [0.9082],\n",
            "        [0.1292],\n",
            "        [0.1013],\n",
            "        [0.3027],\n",
            "        [0.2353],\n",
            "        [0.5917],\n",
            "        [0.1775],\n",
            "        [0.5195],\n",
            "        [0.1134],\n",
            "        [0.2188],\n",
            "        [0.1856],\n",
            "        [0.1123],\n",
            "        [0.6131],\n",
            "        [0.6980],\n",
            "        [0.0725],\n",
            "        [0.5260],\n",
            "        [0.3009],\n",
            "        [0.1999],\n",
            "        [0.1379],\n",
            "        [1.0000],\n",
            "        [0.2219],\n",
            "        [0.2032],\n",
            "        [0.2687],\n",
            "        [0.1390],\n",
            "        [0.3186],\n",
            "        [0.1686],\n",
            "        [0.1953]])\n",
            "y_test_data tensor([[0.2905],\n",
            "        [0.4138],\n",
            "        [0.0558],\n",
            "        [0.0634],\n",
            "        [0.0414],\n",
            "        [0.0571],\n",
            "        [0.2096],\n",
            "        [0.3854],\n",
            "        [0.2260],\n",
            "        [0.1627],\n",
            "        [0.4779],\n",
            "        [1.0000],\n",
            "        [0.8417],\n",
            "        [0.4917],\n",
            "        [0.1004],\n",
            "        [0.7282],\n",
            "        [0.3487],\n",
            "        [0.2106],\n",
            "        [0.1163],\n",
            "        [0.1497],\n",
            "        [0.3482],\n",
            "        [0.0969],\n",
            "        [0.1787],\n",
            "        [0.0840],\n",
            "        [0.1663],\n",
            "        [0.1318],\n",
            "        [0.2430],\n",
            "        [0.1366],\n",
            "        [0.1876],\n",
            "        [0.0432],\n",
            "        [0.0761],\n",
            "        [0.0632],\n",
            "        [0.3013],\n",
            "        [0.5176],\n",
            "        [0.6209],\n",
            "        [0.0202],\n",
            "        [0.1058],\n",
            "        [1.0000],\n",
            "        [0.1024],\n",
            "        [0.3109],\n",
            "        [0.1410],\n",
            "        [0.0759],\n",
            "        [0.1623],\n",
            "        [0.1526],\n",
            "        [0.2695],\n",
            "        [0.3350],\n",
            "        [0.1012],\n",
            "        [0.0670],\n",
            "        [0.1031],\n",
            "        [0.1988],\n",
            "        [0.2438],\n",
            "        [0.0645],\n",
            "        [0.1019],\n",
            "        [0.1207],\n",
            "        [0.0450],\n",
            "        [0.0857],\n",
            "        [0.1981],\n",
            "        [0.1901],\n",
            "        [0.4734],\n",
            "        [0.3259],\n",
            "        [0.5425],\n",
            "        [0.0714],\n",
            "        [0.5765],\n",
            "        [0.4959],\n",
            "        [0.0094],\n",
            "        [0.9576],\n",
            "        [0.2494],\n",
            "        [0.0191],\n",
            "        [0.0207],\n",
            "        [0.1148],\n",
            "        [0.0868],\n",
            "        [0.1217],\n",
            "        [0.3807],\n",
            "        [0.4320],\n",
            "        [0.6002],\n",
            "        [0.0745],\n",
            "        [0.0402],\n",
            "        [0.0381],\n",
            "        [0.0341],\n",
            "        [0.2083],\n",
            "        [0.1927],\n",
            "        [0.1915],\n",
            "        [0.3305],\n",
            "        [0.0717],\n",
            "        [0.2285],\n",
            "        [0.0482],\n",
            "        [0.0984],\n",
            "        [0.4014],\n",
            "        [0.0396],\n",
            "        [0.0612],\n",
            "        [0.3275],\n",
            "        [0.2901],\n",
            "        [0.1572],\n",
            "        [0.0716],\n",
            "        [0.5070],\n",
            "        [0.4909],\n",
            "        [0.1147],\n",
            "        [0.2071],\n",
            "        [0.1169],\n",
            "        [0.0808],\n",
            "        [0.0394],\n",
            "        [0.0497],\n",
            "        [0.0473],\n",
            "        [0.2616],\n",
            "        [0.1531],\n",
            "        [0.2614],\n",
            "        [0.4656],\n",
            "        [1.0000],\n",
            "        [0.3236],\n",
            "        [0.0381],\n",
            "        [0.2265],\n",
            "        [0.0614],\n",
            "        [0.0415],\n",
            "        [0.0376],\n",
            "        [0.0255],\n",
            "        [0.0751],\n",
            "        [0.2396],\n",
            "        [0.1029],\n",
            "        [0.0383],\n",
            "        [0.2123],\n",
            "        [0.0393],\n",
            "        [0.4627],\n",
            "        [0.1200],\n",
            "        [0.2774],\n",
            "        [0.8199],\n",
            "        [0.1181],\n",
            "        [0.0667],\n",
            "        [0.4591],\n",
            "        [0.3566],\n",
            "        [0.3264],\n",
            "        [0.5491],\n",
            "        [0.0076],\n",
            "        [0.4509],\n",
            "        [0.2040],\n",
            "        [0.1600],\n",
            "        [0.0646],\n",
            "        [0.0454],\n",
            "        [0.1099],\n",
            "        [0.0997],\n",
            "        [0.1874],\n",
            "        [0.0126],\n",
            "        [0.2367],\n",
            "        [0.3920],\n",
            "        [0.1122],\n",
            "        [0.0362],\n",
            "        [0.3079],\n",
            "        [0.0974],\n",
            "        [0.2129],\n",
            "        [0.0347],\n",
            "        [0.6693],\n",
            "        [0.6996],\n",
            "        [1.0000],\n",
            "        [0.0024],\n",
            "        [0.7431],\n",
            "        [0.1548],\n",
            "        [0.3637],\n",
            "        [0.0655],\n",
            "        [0.1733],\n",
            "        [0.2460],\n",
            "        [0.0907],\n",
            "        [0.0999],\n",
            "        [0.3283],\n",
            "        [0.1964],\n",
            "        [0.0550],\n",
            "        [0.4847],\n",
            "        [0.5815],\n",
            "        [0.0146],\n",
            "        [0.0722],\n",
            "        [0.0898],\n",
            "        [0.4501],\n",
            "        [0.4386],\n",
            "        [0.1549],\n",
            "        [0.3573],\n",
            "        [0.3442],\n",
            "        [0.2468],\n",
            "        [0.2733],\n",
            "        [0.0047],\n",
            "        [0.4323],\n",
            "        [0.4736],\n",
            "        [1.0000],\n",
            "        [0.0478],\n",
            "        [0.1609],\n",
            "        [0.7323],\n",
            "        [0.0220],\n",
            "        [0.0260],\n",
            "        [0.0409],\n",
            "        [0.0581],\n",
            "        [0.2917],\n",
            "        [0.0709],\n",
            "        [0.0318],\n",
            "        [0.0035],\n",
            "        [0.0051],\n",
            "        [0.1708],\n",
            "        [0.2498],\n",
            "        [0.7912],\n",
            "        [0.0979],\n",
            "        [1.0000],\n",
            "        [0.3806],\n",
            "        [0.1529],\n",
            "        [0.2142],\n",
            "        [0.1303],\n",
            "        [0.1900],\n",
            "        [0.1355],\n",
            "        [0.7581],\n",
            "        [0.2362],\n",
            "        [0.2900],\n",
            "        [0.4483],\n",
            "        [0.9900],\n",
            "        [0.0384],\n",
            "        [0.0726],\n",
            "        [0.3724],\n",
            "        [0.4604],\n",
            "        [0.1505],\n",
            "        [0.0703],\n",
            "        [0.8946],\n",
            "        [0.1741],\n",
            "        [0.6558],\n",
            "        [0.0129],\n",
            "        [0.2217],\n",
            "        [0.3803],\n",
            "        [0.1291],\n",
            "        [0.3616],\n",
            "        [0.0353],\n",
            "        [0.0391],\n",
            "        [0.2902],\n",
            "        [0.1158],\n",
            "        [0.1629],\n",
            "        [0.0699],\n",
            "        [0.0265],\n",
            "        [1.0000],\n",
            "        [0.0830],\n",
            "        [0.3402],\n",
            "        [0.1002],\n",
            "        [0.8251],\n",
            "        [0.1671],\n",
            "        [0.1885],\n",
            "        [0.0022],\n",
            "        [0.6669],\n",
            "        [0.6698],\n",
            "        [0.0665],\n",
            "        [0.0937],\n",
            "        [0.2486],\n",
            "        [0.2830],\n",
            "        [1.0000],\n",
            "        [0.2115],\n",
            "        [0.6577],\n",
            "        [0.8638],\n",
            "        [0.6452],\n",
            "        [0.3605],\n",
            "        [0.0064],\n",
            "        [0.0978],\n",
            "        [0.0552],\n",
            "        [0.2200],\n",
            "        [0.5453],\n",
            "        [0.1490],\n",
            "        [0.0373],\n",
            "        [0.2637],\n",
            "        [0.2501],\n",
            "        [0.1805],\n",
            "        [0.2414],\n",
            "        [0.0137],\n",
            "        [0.7147],\n",
            "        [0.4024],\n",
            "        [0.2233],\n",
            "        [0.0974],\n",
            "        [0.4258],\n",
            "        [0.1569],\n",
            "        [0.1793],\n",
            "        [0.3297],\n",
            "        [0.0870],\n",
            "        [0.2088],\n",
            "        [0.0762],\n",
            "        [0.1747],\n",
            "        [0.3548],\n",
            "        [0.1214],\n",
            "        [0.3002],\n",
            "        [0.1897],\n",
            "        [0.4681],\n",
            "        [0.0633],\n",
            "        [0.0756],\n",
            "        [0.4083],\n",
            "        [0.0673],\n",
            "        [0.4281],\n",
            "        [0.0492],\n",
            "        [0.2128],\n",
            "        [0.0999],\n",
            "        [0.1571],\n",
            "        [0.1993],\n",
            "        [0.2387],\n",
            "        [0.1563],\n",
            "        [0.1363],\n",
            "        [0.3970],\n",
            "        [0.0250],\n",
            "        [0.4429],\n",
            "        [0.1005],\n",
            "        [0.1046],\n",
            "        [0.1660],\n",
            "        [0.0113],\n",
            "        [0.1196],\n",
            "        [0.0740],\n",
            "        [0.1615],\n",
            "        [0.0513],\n",
            "        [0.1033],\n",
            "        [0.1496],\n",
            "        [0.0524],\n",
            "        [0.0654],\n",
            "        [0.0763],\n",
            "        [0.0911],\n",
            "        [0.4934],\n",
            "        [0.1520],\n",
            "        [0.5364],\n",
            "        [0.2513],\n",
            "        [0.2667],\n",
            "        [0.1155],\n",
            "        [0.6917],\n",
            "        [0.1897],\n",
            "        [0.4272],\n",
            "        [0.1916],\n",
            "        [0.1487],\n",
            "        [0.1962],\n",
            "        [0.2396],\n",
            "        [0.2856],\n",
            "        [0.0476],\n",
            "        [0.2017],\n",
            "        [0.2115],\n",
            "        [0.1002],\n",
            "        [0.0037],\n",
            "        [0.0050],\n",
            "        [0.0036],\n",
            "        [0.0607],\n",
            "        [0.1948],\n",
            "        [0.4711],\n",
            "        [0.2258],\n",
            "        [0.0834],\n",
            "        [0.0165],\n",
            "        [0.0978],\n",
            "        [0.7646],\n",
            "        [0.0269],\n",
            "        [0.5491],\n",
            "        [0.0389],\n",
            "        [0.7723],\n",
            "        [0.1679],\n",
            "        [0.0201],\n",
            "        [0.3911],\n",
            "        [0.3414],\n",
            "        [0.0985],\n",
            "        [0.1994],\n",
            "        [0.0367],\n",
            "        [0.0427],\n",
            "        [0.1667],\n",
            "        [0.6906],\n",
            "        [0.4803],\n",
            "        [0.0545],\n",
            "        [0.5769],\n",
            "        [0.0428],\n",
            "        [0.0021],\n",
            "        [0.2898],\n",
            "        [0.1730],\n",
            "        [0.0153],\n",
            "        [0.0210],\n",
            "        [0.3894],\n",
            "        [0.1854],\n",
            "        [0.0516],\n",
            "        [0.2722],\n",
            "        [0.3443],\n",
            "        [0.1148],\n",
            "        [0.4934],\n",
            "        [1.0000],\n",
            "        [0.5383],\n",
            "        [0.1455],\n",
            "        [0.2760],\n",
            "        [0.0028],\n",
            "        [0.1421],\n",
            "        [0.3106],\n",
            "        [0.4408],\n",
            "        [0.0960],\n",
            "        [0.2385],\n",
            "        [0.8496],\n",
            "        [0.2474],\n",
            "        [0.2162],\n",
            "        [0.4042],\n",
            "        [0.1009],\n",
            "        [0.2154],\n",
            "        [0.0889],\n",
            "        [0.0663],\n",
            "        [0.7277],\n",
            "        [0.2739],\n",
            "        [0.0870],\n",
            "        [0.3906],\n",
            "        [0.2752],\n",
            "        [0.3292],\n",
            "        [0.2592],\n",
            "        [0.1591],\n",
            "        [0.3442],\n",
            "        [0.1681],\n",
            "        [0.4459],\n",
            "        [0.3542],\n",
            "        [0.4263],\n",
            "        [0.0800],\n",
            "        [0.3990],\n",
            "        [0.3342],\n",
            "        [0.3115],\n",
            "        [0.0710],\n",
            "        [0.1136],\n",
            "        [0.0623],\n",
            "        [0.1175],\n",
            "        [0.1139],\n",
            "        [0.0421],\n",
            "        [0.0958],\n",
            "        [0.6308],\n",
            "        [0.2213],\n",
            "        [0.1770],\n",
            "        [0.0563],\n",
            "        [0.1296],\n",
            "        [0.6989],\n",
            "        [0.1038],\n",
            "        [0.0892],\n",
            "        [0.2267],\n",
            "        [0.0548],\n",
            "        [0.7630],\n",
            "        [0.0263],\n",
            "        [0.3782],\n",
            "        [0.0946],\n",
            "        [0.8948],\n",
            "        [0.8158],\n",
            "        [0.1882],\n",
            "        [0.9363],\n",
            "        [0.0693],\n",
            "        [0.4388],\n",
            "        [0.0809],\n",
            "        [0.1139],\n",
            "        [0.2955],\n",
            "        [0.1044],\n",
            "        [0.2508],\n",
            "        [0.8290],\n",
            "        [0.0637],\n",
            "        [0.1320],\n",
            "        [0.0382],\n",
            "        [0.4277],\n",
            "        [0.1713],\n",
            "        [0.4515],\n",
            "        [0.1211],\n",
            "        [0.0703],\n",
            "        [0.3160],\n",
            "        [0.1439],\n",
            "        [0.3067],\n",
            "        [1.0000],\n",
            "        [0.5652],\n",
            "        [0.2088],\n",
            "        [0.4383],\n",
            "        [0.0696],\n",
            "        [0.0551],\n",
            "        [0.3407],\n",
            "        [0.4540],\n",
            "        [0.6390],\n",
            "        [0.6172],\n",
            "        [0.1149],\n",
            "        [0.2921],\n",
            "        [0.1667],\n",
            "        [0.7880],\n",
            "        [0.9166],\n",
            "        [0.1608],\n",
            "        [0.3438],\n",
            "        [0.0675],\n",
            "        [0.0427],\n",
            "        [0.0031],\n",
            "        [0.0656],\n",
            "        [0.1080],\n",
            "        [0.0447],\n",
            "        [0.1571],\n",
            "        [0.1522],\n",
            "        [0.8334],\n",
            "        [0.0600],\n",
            "        [0.0564],\n",
            "        [0.1052],\n",
            "        [0.2234],\n",
            "        [0.0549],\n",
            "        [0.0563],\n",
            "        [1.0000],\n",
            "        [0.7691],\n",
            "        [0.3375],\n",
            "        [0.0387],\n",
            "        [0.4271],\n",
            "        [0.1287],\n",
            "        [0.0882],\n",
            "        [0.2780],\n",
            "        [0.1247],\n",
            "        [0.0581],\n",
            "        [0.1767],\n",
            "        [0.2115],\n",
            "        [0.6352],\n",
            "        [0.2878],\n",
            "        [0.0602],\n",
            "        [1.0000],\n",
            "        [0.3529],\n",
            "        [0.1817],\n",
            "        [0.1019],\n",
            "        [0.3930],\n",
            "        [0.0609],\n",
            "        [0.5716],\n",
            "        [0.1380],\n",
            "        [0.0528],\n",
            "        [0.0726],\n",
            "        [1.0000],\n",
            "        [0.1635],\n",
            "        [0.0899],\n",
            "        [0.6695],\n",
            "        [0.0930],\n",
            "        [0.0329],\n",
            "        [0.0640],\n",
            "        [0.0723],\n",
            "        [0.3651],\n",
            "        [0.2055],\n",
            "        [0.2768],\n",
            "        [0.6159],\n",
            "        [0.1454],\n",
            "        [0.4062],\n",
            "        [0.0988],\n",
            "        [0.0151],\n",
            "        [0.1494],\n",
            "        [0.2207],\n",
            "        [0.4739],\n",
            "        [0.5913],\n",
            "        [0.0646],\n",
            "        [0.2138],\n",
            "        [0.2294],\n",
            "        [0.1562],\n",
            "        [0.2331],\n",
            "        [0.0083],\n",
            "        [0.0346],\n",
            "        [0.0035],\n",
            "        [0.1289],\n",
            "        [0.3022],\n",
            "        [0.1016],\n",
            "        [0.0571],\n",
            "        [0.7405],\n",
            "        [0.1064],\n",
            "        [0.3778],\n",
            "        [0.0906],\n",
            "        [0.3961],\n",
            "        [0.1140],\n",
            "        [0.1763],\n",
            "        [0.1190],\n",
            "        [0.8663],\n",
            "        [0.1318],\n",
            "        [0.0657],\n",
            "        [0.2610],\n",
            "        [0.2635],\n",
            "        [0.0218],\n",
            "        [0.0622],\n",
            "        [0.1012],\n",
            "        [0.1834],\n",
            "        [0.0973],\n",
            "        [0.2746],\n",
            "        [0.6565],\n",
            "        [0.3646],\n",
            "        [0.1873],\n",
            "        [0.0958],\n",
            "        [0.2886],\n",
            "        [0.1409],\n",
            "        [0.7882],\n",
            "        [0.3627],\n",
            "        [0.3659],\n",
            "        [0.2959],\n",
            "        [0.5024],\n",
            "        [0.2041],\n",
            "        [0.2827],\n",
            "        [0.1028],\n",
            "        [0.3271],\n",
            "        [0.4351],\n",
            "        [0.2734],\n",
            "        [0.0868],\n",
            "        [0.0434],\n",
            "        [0.7601],\n",
            "        [0.4859],\n",
            "        [0.0898],\n",
            "        [0.0343],\n",
            "        [0.1080],\n",
            "        [0.0026],\n",
            "        [0.1511],\n",
            "        [0.0408],\n",
            "        [0.7346],\n",
            "        [0.0364],\n",
            "        [0.1725],\n",
            "        [0.0418],\n",
            "        [0.3718],\n",
            "        [0.1438],\n",
            "        [0.7239],\n",
            "        [0.4759],\n",
            "        [0.4037],\n",
            "        [0.1645],\n",
            "        [0.0528],\n",
            "        [0.4105],\n",
            "        [0.2687],\n",
            "        [0.5844],\n",
            "        [0.2843],\n",
            "        [0.4874],\n",
            "        [0.0639],\n",
            "        [0.5438],\n",
            "        [0.1183],\n",
            "        [0.2572],\n",
            "        [0.1292],\n",
            "        [0.0502],\n",
            "        [0.2799],\n",
            "        [0.0220],\n",
            "        [0.0551],\n",
            "        [0.1749],\n",
            "        [1.0000],\n",
            "        [0.2985],\n",
            "        [0.2746],\n",
            "        [0.1210],\n",
            "        [0.2282],\n",
            "        [0.1563],\n",
            "        [0.0044],\n",
            "        [0.0947],\n",
            "        [0.0024],\n",
            "        [0.0898],\n",
            "        [0.6397],\n",
            "        [0.1816],\n",
            "        [0.1595],\n",
            "        [0.0505],\n",
            "        [0.0332],\n",
            "        [0.2777],\n",
            "        [0.2316],\n",
            "        [0.4605],\n",
            "        [0.4327],\n",
            "        [0.9659],\n",
            "        [1.0000],\n",
            "        [0.5618],\n",
            "        [1.0000],\n",
            "        [0.2377],\n",
            "        [1.0000],\n",
            "        [0.2695],\n",
            "        [0.2265],\n",
            "        [1.0000],\n",
            "        [0.8716],\n",
            "        [0.9072],\n",
            "        [0.4918],\n",
            "        [0.7141],\n",
            "        [0.6613],\n",
            "        [0.1570],\n",
            "        [0.0376],\n",
            "        [0.7293],\n",
            "        [1.0000],\n",
            "        [0.0412],\n",
            "        [0.9940],\n",
            "        [0.7583],\n",
            "        [0.6002],\n",
            "        [0.9257],\n",
            "        [1.0000],\n",
            "        [0.2289],\n",
            "        [0.4206],\n",
            "        [1.0000],\n",
            "        [0.2817],\n",
            "        [1.0000],\n",
            "        [0.8942],\n",
            "        [0.2719],\n",
            "        [0.4605],\n",
            "        [0.4810],\n",
            "        [1.0000],\n",
            "        [0.3921],\n",
            "        [0.0718],\n",
            "        [1.0000],\n",
            "        [0.1449],\n",
            "        [0.0614],\n",
            "        [0.4447],\n",
            "        [0.1322],\n",
            "        [0.0595],\n",
            "        [0.0228],\n",
            "        [0.1957],\n",
            "        [0.5333],\n",
            "        [0.5391],\n",
            "        [0.5046],\n",
            "        [0.0473],\n",
            "        [0.0665],\n",
            "        [0.0315],\n",
            "        [0.1070],\n",
            "        [0.0525],\n",
            "        [0.0399],\n",
            "        [0.0603],\n",
            "        [0.0274],\n",
            "        [0.4739],\n",
            "        [1.0000],\n",
            "        [0.4302],\n",
            "        [0.2647],\n",
            "        [0.6847],\n",
            "        [0.0183],\n",
            "        [0.4492],\n",
            "        [0.7767],\n",
            "        [0.4579],\n",
            "        [0.6582],\n",
            "        [1.0000],\n",
            "        [0.2856],\n",
            "        [0.1948],\n",
            "        [0.9992],\n",
            "        [0.1265],\n",
            "        [0.6090],\n",
            "        [0.6852],\n",
            "        [0.3240],\n",
            "        [0.2183],\n",
            "        [0.0434],\n",
            "        [0.3677],\n",
            "        [0.2207],\n",
            "        [0.3095],\n",
            "        [0.2036],\n",
            "        [0.4368],\n",
            "        [0.2408],\n",
            "        [0.7867],\n",
            "        [0.2307],\n",
            "        [0.0076],\n",
            "        [0.0100],\n",
            "        [0.0456],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.0895],\n",
            "        [0.1237],\n",
            "        [1.0000],\n",
            "        [0.1877],\n",
            "        [0.0228],\n",
            "        [0.0620],\n",
            "        [0.0360],\n",
            "        [0.0190],\n",
            "        [0.0359],\n",
            "        [1.0000],\n",
            "        [0.1933],\n",
            "        [0.1422],\n",
            "        [0.4407],\n",
            "        [0.3850],\n",
            "        [0.4445],\n",
            "        [0.1076],\n",
            "        [0.0118],\n",
            "        [0.9129],\n",
            "        [0.0531],\n",
            "        [0.1282],\n",
            "        [0.2476],\n",
            "        [0.0889],\n",
            "        [0.1460],\n",
            "        [0.0403],\n",
            "        [0.3762],\n",
            "        [0.4222],\n",
            "        [0.8270],\n",
            "        [0.5851],\n",
            "        [0.3215],\n",
            "        [0.1072],\n",
            "        [0.4636],\n",
            "        [0.1054],\n",
            "        [0.8156],\n",
            "        [0.7890],\n",
            "        [0.6570],\n",
            "        [0.3806],\n",
            "        [0.3416],\n",
            "        [0.4413],\n",
            "        [0.1779],\n",
            "        [0.4075],\n",
            "        [0.2169],\n",
            "        [1.0000],\n",
            "        [0.4967],\n",
            "        [0.4373],\n",
            "        [0.1869],\n",
            "        [0.4829],\n",
            "        [0.6098],\n",
            "        [0.0657],\n",
            "        [0.9624],\n",
            "        [0.0498],\n",
            "        [0.5223],\n",
            "        [0.7793],\n",
            "        [0.1453],\n",
            "        [0.0397],\n",
            "        [0.6209],\n",
            "        [0.4188],\n",
            "        [0.0990],\n",
            "        [1.0000],\n",
            "        [0.4010],\n",
            "        [0.4813],\n",
            "        [0.3114],\n",
            "        [0.2604],\n",
            "        [1.0000],\n",
            "        [0.1772],\n",
            "        [0.2613],\n",
            "        [0.1874],\n",
            "        [0.2576],\n",
            "        [0.0025],\n",
            "        [0.6538],\n",
            "        [0.5346],\n",
            "        [0.0989],\n",
            "        [0.1428],\n",
            "        [0.3265],\n",
            "        [0.9017],\n",
            "        [0.0539],\n",
            "        [0.4693],\n",
            "        [0.3366],\n",
            "        [0.2103],\n",
            "        [0.2440],\n",
            "        [0.0706],\n",
            "        [0.5123],\n",
            "        [0.9074],\n",
            "        [0.5136],\n",
            "        [0.7793],\n",
            "        [0.2562],\n",
            "        [0.1391],\n",
            "        [0.4527],\n",
            "        [0.0129],\n",
            "        [0.6433],\n",
            "        [0.0171],\n",
            "        [0.3953],\n",
            "        [0.2413],\n",
            "        [0.0738],\n",
            "        [1.0000],\n",
            "        [0.1853],\n",
            "        [0.3294],\n",
            "        [0.7567],\n",
            "        [0.1775],\n",
            "        [0.1036],\n",
            "        [1.0000],\n",
            "        [0.3665],\n",
            "        [0.9694],\n",
            "        [0.1885],\n",
            "        [0.0317],\n",
            "        [0.2455],\n",
            "        [0.6648],\n",
            "        [0.4269],\n",
            "        [0.2590],\n",
            "        [0.2987],\n",
            "        [0.9532],\n",
            "        [0.0826],\n",
            "        [0.0408],\n",
            "        [0.7859],\n",
            "        [0.4450],\n",
            "        [0.7816],\n",
            "        [0.0473],\n",
            "        [0.0377],\n",
            "        [0.1943],\n",
            "        [0.1328],\n",
            "        [0.0661],\n",
            "        [0.5315],\n",
            "        [0.1037],\n",
            "        [0.1577],\n",
            "        [0.5936],\n",
            "        [0.1237],\n",
            "        [0.2647],\n",
            "        [0.1817],\n",
            "        [0.8354],\n",
            "        [0.1770],\n",
            "        [0.1607],\n",
            "        [0.3526],\n",
            "        [0.5014],\n",
            "        [0.5175],\n",
            "        [0.3798],\n",
            "        [0.0930],\n",
            "        [0.5243],\n",
            "        [0.5124],\n",
            "        [0.0924],\n",
            "        [0.4939],\n",
            "        [0.5563],\n",
            "        [0.3920],\n",
            "        [0.2285],\n",
            "        [0.4212],\n",
            "        [0.1723],\n",
            "        [0.6358],\n",
            "        [0.9434],\n",
            "        [0.0982],\n",
            "        [0.0228],\n",
            "        [0.2217],\n",
            "        [0.1136],\n",
            "        [0.4089],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.0437],\n",
            "        [0.1724],\n",
            "        [0.6244],\n",
            "        [0.1964],\n",
            "        [0.3551],\n",
            "        [0.2972],\n",
            "        [0.2562],\n",
            "        [0.2121],\n",
            "        [0.0501],\n",
            "        [0.6816],\n",
            "        [0.5989],\n",
            "        [0.6726],\n",
            "        [0.2104],\n",
            "        [0.2923],\n",
            "        [0.1058],\n",
            "        [0.2335],\n",
            "        [0.2196],\n",
            "        [0.1930],\n",
            "        [0.2590],\n",
            "        [0.0788],\n",
            "        [0.4757],\n",
            "        [0.1454],\n",
            "        [0.1190],\n",
            "        [0.2494],\n",
            "        [0.4061],\n",
            "        [0.0910],\n",
            "        [0.4658],\n",
            "        [0.1930],\n",
            "        [0.6326],\n",
            "        [0.4888],\n",
            "        [0.1005],\n",
            "        [0.2478],\n",
            "        [0.0018],\n",
            "        [0.2249],\n",
            "        [0.7536],\n",
            "        [0.1505],\n",
            "        [0.1553],\n",
            "        [0.3978],\n",
            "        [0.4769],\n",
            "        [0.2891],\n",
            "        [0.1654],\n",
            "        [1.0000],\n",
            "        [0.2052],\n",
            "        [0.0638],\n",
            "        [0.5705],\n",
            "        [0.1071],\n",
            "        [0.4708],\n",
            "        [0.6598],\n",
            "        [0.1951],\n",
            "        [0.2322],\n",
            "        [0.2209],\n",
            "        [0.3357],\n",
            "        [0.1046],\n",
            "        [0.7737],\n",
            "        [0.1274],\n",
            "        [0.0779],\n",
            "        [0.1069],\n",
            "        [0.7015],\n",
            "        [0.9708],\n",
            "        [0.1301],\n",
            "        [0.2762],\n",
            "        [0.0959],\n",
            "        [0.0259],\n",
            "        [0.7080],\n",
            "        [0.0400],\n",
            "        [0.2310],\n",
            "        [0.7622],\n",
            "        [0.9172],\n",
            "        [1.0000],\n",
            "        [0.2985],\n",
            "        [1.0000],\n",
            "        [0.4041],\n",
            "        [0.7114],\n",
            "        [0.0363],\n",
            "        [0.0141],\n",
            "        [0.2857],\n",
            "        [0.0458],\n",
            "        [0.2116],\n",
            "        [0.2152],\n",
            "        [0.2761],\n",
            "        [0.5560],\n",
            "        [0.1955],\n",
            "        [0.0223],\n",
            "        [0.0852],\n",
            "        [0.0292],\n",
            "        [0.0024],\n",
            "        [0.0104],\n",
            "        [0.0211],\n",
            "        [0.8732],\n",
            "        [0.1959],\n",
            "        [0.3845],\n",
            "        [0.1260],\n",
            "        [0.1769],\n",
            "        [0.2238],\n",
            "        [0.0428],\n",
            "        [0.1085],\n",
            "        [0.0677],\n",
            "        [0.5095],\n",
            "        [0.1454],\n",
            "        [0.9673],\n",
            "        [0.2472],\n",
            "        [0.1108],\n",
            "        [0.1216],\n",
            "        [0.1773],\n",
            "        [0.0987],\n",
            "        [0.2681],\n",
            "        [0.6009],\n",
            "        [0.1177],\n",
            "        [0.2673],\n",
            "        [0.1533],\n",
            "        [0.3452],\n",
            "        [0.0840],\n",
            "        [0.3269],\n",
            "        [0.2839],\n",
            "        [0.1793],\n",
            "        [0.9559],\n",
            "        [0.3155],\n",
            "        [0.1336],\n",
            "        [0.4224],\n",
            "        [0.6924],\n",
            "        [0.8656],\n",
            "        [0.4098],\n",
            "        [0.1198],\n",
            "        [0.1573]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time training(linearRegressionForAp1,optimizerForAp1,1000)"
      ],
      "metadata": {
        "id": "YSs-9j_r3yhK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2705bcaa-0fef-48c2-abde-ad68dc45c291"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0000 dev loss= 0.16549142\n",
            "Epoch: 0100 dev loss= 0.15135138\n",
            "Epoch: 0200 dev loss= 0.13972367\n",
            "Epoch: 0300 dev loss= 0.13015531\n",
            "Epoch: 0400 dev loss= 0.12227534\n",
            "Epoch: 0500 dev loss= 0.11578003\n",
            "Epoch: 0600 dev loss= 0.11042059\n",
            "Epoch: 0700 dev loss= 0.10599336\n",
            "Epoch: 0800 dev loss= 0.10233136\n",
            "Epoch: 0900 dev loss= 0.09929790\n",
            "=========================================================\n",
            "Optimised: training loss= 0.093802556\n",
            "Optimised: dev loss= 0.096803851\n",
            "=========================================================\n",
            "CPU times: user 1.05 s, sys: 8.72 ms, total: 1.06 s\n",
            "Wall time: 1.13 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time testing(linearRegressionForAp1)"
      ],
      "metadata": {
        "id": "NRRKCt-7303I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a30e2140-e8c5-4be8-9d1c-a7fe82f4557b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================\n",
            "Optimised: training loss= 0.093802556\n",
            "Optimised: dev loss= 0.096803851\n",
            "=========================================================\n",
            "Testing loss= 0.082667157\n",
            "Absolute mean square loss difference: 0.014136694\n",
            "CPU times: user 5.28 ms, sys: 3 µs, total: 5.28 ms\n",
            "Wall time: 9.44 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Approch 2"
      ],
      "metadata": {
        "id": "Ho1S6UBfAXqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fast text vector to learn n-gram embbeding from dataset(stopwords and punctuation removed)\n",
        "from gensim.models import FastText\n",
        "word_embeddings_model_ft = FastText(sentences=training_text_tokenized_new, size=100, window=5, min_count=10, workers=2, sg=0)"
      ],
      "metadata": {
        "id": "xzfcS2buisoC"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# specification of model being trained using fast text vectors\n",
        "linearRegressionForAp2 =  nn.Linear(100,1)\n",
        "optimizerForAp2 = torch.optim.SGD(linearRegressionForAp2.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "tZJNWLAe-ZKF"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generating a mean fast text vector for documents in each dataset\n",
        "x_training_fasttext_tensor_ap2 = getAvgVectors(training_text_tokenized_new,word_embeddings_model_ft)\n",
        "x_dev_fasttext_tensor_ap2 = getAvgVectors(dev_text_tokenized_new,word_embeddings_model_ft)\n",
        "x_test_fasttext_tensor_ap2 = getAvgVectors(test_text_tokenized_new,word_embeddings_model_ft)"
      ],
      "metadata": {
        "id": "8VKnciJldFBO"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# populating data that will be used in training and testing of model\n",
        "x_data = x_training_fasttext_tensor_ap2.float()\n",
        "y_data = y_training_data_tensor.float()\n",
        "x_dev_data = x_dev_fasttext_tensor_ap2.float()\n",
        "y_dev_data = y_dev_data_tensor.float()\n",
        "x_test_data = x_test_fasttext_tensor_ap2.float()\n",
        "y_test_data = y_test_data_tensor.float()"
      ],
      "metadata": {
        "id": "FP9s73rR-eYG"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('x_data',x_data)\n",
        "print('x_dev_data',x_dev_data)\n",
        "print('x_test_data',x_test_data)"
      ],
      "metadata": {
        "id": "k60wRvCPW8ry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2deaeb3-2539-418a-8867-c91c3c717063"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_data tensor([[-1.6640e-01,  2.9206e-01, -4.2247e-01,  ...,  3.4840e-01,\n",
            "          1.5143e-01,  4.3527e-01],\n",
            "        [ 4.6573e-01,  1.9362e-01, -3.8290e-01,  ...,  3.8650e-01,\n",
            "         -1.4027e-01,  5.4531e-01],\n",
            "        [ 8.2157e-01,  6.2583e-02, -3.3494e-01,  ...,  4.3443e-01,\n",
            "          5.2901e-01,  8.3186e-01],\n",
            "        ...,\n",
            "        [-2.6867e-01,  6.0831e-01, -4.3429e-01,  ...,  4.0811e-01,\n",
            "          6.1082e-01,  6.6706e-01],\n",
            "        [ 5.3086e-01,  1.7527e-01, -4.0932e-01,  ...,  5.0237e-01,\n",
            "          1.8469e-01,  6.7536e-01],\n",
            "        [ 2.1045e-01,  2.2887e-01, -4.7201e-01,  ...,  2.8749e-01,\n",
            "          3.0694e-04,  1.6014e-01]])\n",
            "x_dev_data tensor([[-0.2387,  0.6382, -0.2250,  ...,  0.0288,  0.6768,  0.2630],\n",
            "        [ 0.2172,  0.2514, -0.3168,  ...,  0.1638,  0.0610,  0.1788],\n",
            "        [-0.1816,  0.5649, -0.2809,  ...,  0.0792,  0.5635,  0.2617],\n",
            "        ...,\n",
            "        [ 1.5462,  0.3827, -0.4995,  ...,  0.4265,  1.0051,  0.8364],\n",
            "        [-0.0868,  0.5643, -0.3162,  ...,  0.0463,  0.6748,  0.2057],\n",
            "        [ 0.1295,  0.6018, -0.3844,  ...,  0.1547,  0.7237,  0.2781]])\n",
            "x_test_data tensor([[-0.6619,  0.7136, -0.7163,  ...,  0.5974,  0.6183,  0.5302],\n",
            "        [ 1.1336,  0.0890, -0.4369,  ...,  0.4562,  0.4252,  0.7740],\n",
            "        [-0.0439,  0.4424, -0.2147,  ...,  0.0371,  0.5023,  0.2778],\n",
            "        ...,\n",
            "        [-0.2505,  0.5788, -0.4954,  ...,  0.3931,  0.4422,  0.4584],\n",
            "        [ 0.1139,  0.0884, -0.3142,  ...,  0.3034, -0.1486,  0.4090],\n",
            "        [ 0.1793,  0.0587, -0.4410,  ...,  0.4062, -0.3072,  0.3929]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('y_data',y_data)\n",
        "print('y_dev_data',y_dev_data)\n",
        "print('y_test_data',y_test_data)"
      ],
      "metadata": {
        "id": "_rupdxrRW9aD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c92690e2-f3a4-4e00-c871-ffbdbdbcc17a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_data tensor([[0.6453],\n",
            "        [0.3528],\n",
            "        [0.1265],\n",
            "        ...,\n",
            "        [0.5215],\n",
            "        [0.0191],\n",
            "        [0.1101]])\n",
            "y_dev_data tensor([[0.0552],\n",
            "        [0.0999],\n",
            "        [0.1331],\n",
            "        [0.0461],\n",
            "        [0.5329],\n",
            "        [0.3803],\n",
            "        [0.7429],\n",
            "        [0.3737],\n",
            "        [0.1130],\n",
            "        [0.4459],\n",
            "        [0.8221],\n",
            "        [0.5769],\n",
            "        [0.0800],\n",
            "        [0.0039],\n",
            "        [0.8192],\n",
            "        [0.2340],\n",
            "        [0.3241],\n",
            "        [0.4813],\n",
            "        [0.1308],\n",
            "        [0.1061],\n",
            "        [0.0964],\n",
            "        [0.4800],\n",
            "        [0.3005],\n",
            "        [0.4446],\n",
            "        [0.6819],\n",
            "        [0.0624],\n",
            "        [0.0023],\n",
            "        [0.6516],\n",
            "        [0.1084],\n",
            "        [0.0338],\n",
            "        [0.1668],\n",
            "        [1.0000],\n",
            "        [0.0378],\n",
            "        [0.7162],\n",
            "        [1.0000],\n",
            "        [0.4729],\n",
            "        [0.1461],\n",
            "        [0.0339],\n",
            "        [0.1397],\n",
            "        [0.0467],\n",
            "        [0.0139],\n",
            "        [0.1381],\n",
            "        [0.0618],\n",
            "        [0.6992],\n",
            "        [0.0825],\n",
            "        [0.1998],\n",
            "        [0.3397],\n",
            "        [0.3242],\n",
            "        [0.8384],\n",
            "        [0.6603],\n",
            "        [0.1526],\n",
            "        [0.4454],\n",
            "        [0.5000],\n",
            "        [0.1777],\n",
            "        [0.3162],\n",
            "        [0.4711],\n",
            "        [1.0000],\n",
            "        [0.0682],\n",
            "        [1.0000],\n",
            "        [0.0045],\n",
            "        [0.1025],\n",
            "        [0.3801],\n",
            "        [0.4676],\n",
            "        [1.0000],\n",
            "        [0.0698],\n",
            "        [0.1510],\n",
            "        [0.1671],\n",
            "        [0.9450],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.1527],\n",
            "        [0.4708],\n",
            "        [0.1268],\n",
            "        [0.2870],\n",
            "        [0.3339],\n",
            "        [0.1383],\n",
            "        [0.5040],\n",
            "        [0.0370],\n",
            "        [0.1159],\n",
            "        [0.2667],\n",
            "        [0.6404],\n",
            "        [0.7743],\n",
            "        [0.7592],\n",
            "        [0.5285],\n",
            "        [0.7861],\n",
            "        [0.9499],\n",
            "        [0.3047],\n",
            "        [0.1033],\n",
            "        [0.0131],\n",
            "        [0.1359],\n",
            "        [1.0000],\n",
            "        [0.6687],\n",
            "        [0.3711],\n",
            "        [0.0019],\n",
            "        [0.1374],\n",
            "        [0.0550],\n",
            "        [0.4501],\n",
            "        [0.0871],\n",
            "        [0.0251],\n",
            "        [0.0958],\n",
            "        [0.7153],\n",
            "        [0.2709],\n",
            "        [0.0938],\n",
            "        [0.0630],\n",
            "        [0.5334],\n",
            "        [0.7670],\n",
            "        [0.2958],\n",
            "        [1.0000],\n",
            "        [0.0533],\n",
            "        [0.1070],\n",
            "        [1.0000],\n",
            "        [0.2736],\n",
            "        [0.1435],\n",
            "        [0.0660],\n",
            "        [0.0499],\n",
            "        [0.1667],\n",
            "        [0.0373],\n",
            "        [0.0993],\n",
            "        [0.0466],\n",
            "        [0.3042],\n",
            "        [0.1685],\n",
            "        [0.0732],\n",
            "        [0.0373],\n",
            "        [0.0412],\n",
            "        [1.0000],\n",
            "        [0.1720],\n",
            "        [1.0000],\n",
            "        [0.4960],\n",
            "        [0.1058],\n",
            "        [0.1516],\n",
            "        [0.1190],\n",
            "        [0.0278],\n",
            "        [0.0161],\n",
            "        [0.0811],\n",
            "        [0.0274],\n",
            "        [0.2107],\n",
            "        [0.2254],\n",
            "        [0.0354],\n",
            "        [0.0276],\n",
            "        [0.2861],\n",
            "        [0.4141],\n",
            "        [0.0063],\n",
            "        [0.1041],\n",
            "        [0.1422],\n",
            "        [0.0026],\n",
            "        [0.5488],\n",
            "        [0.0083],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.1772],\n",
            "        [0.1442],\n",
            "        [0.6086],\n",
            "        [0.1025],\n",
            "        [0.1059],\n",
            "        [0.5772],\n",
            "        [0.0464],\n",
            "        [0.3392],\n",
            "        [0.1572],\n",
            "        [0.2298],\n",
            "        [0.1472],\n",
            "        [0.1704],\n",
            "        [0.1909],\n",
            "        [0.5225],\n",
            "        [0.5311],\n",
            "        [0.0995],\n",
            "        [1.0000],\n",
            "        [0.9419],\n",
            "        [0.2544],\n",
            "        [0.1917],\n",
            "        [0.5731],\n",
            "        [0.0576],\n",
            "        [0.4418],\n",
            "        [0.4653],\n",
            "        [0.5705],\n",
            "        [0.1428],\n",
            "        [0.2416],\n",
            "        [0.9614],\n",
            "        [0.1927],\n",
            "        [0.2578],\n",
            "        [1.0000],\n",
            "        [0.0605],\n",
            "        [0.8633],\n",
            "        [0.2742],\n",
            "        [0.0922],\n",
            "        [0.1719],\n",
            "        [0.3184],\n",
            "        [0.5352],\n",
            "        [0.0855],\n",
            "        [0.2844],\n",
            "        [0.6468],\n",
            "        [0.2538],\n",
            "        [0.6768],\n",
            "        [0.1783],\n",
            "        [0.1734],\n",
            "        [1.0000],\n",
            "        [0.1903],\n",
            "        [0.3684],\n",
            "        [0.1791],\n",
            "        [0.5791],\n",
            "        [0.1715],\n",
            "        [0.2113],\n",
            "        [0.5502],\n",
            "        [0.0636],\n",
            "        [0.9030],\n",
            "        [0.9305],\n",
            "        [0.0810],\n",
            "        [0.5443],\n",
            "        [0.1210],\n",
            "        [0.0411],\n",
            "        [0.0696],\n",
            "        [0.0202],\n",
            "        [1.0000],\n",
            "        [0.1869],\n",
            "        [0.0955],\n",
            "        [0.2788],\n",
            "        [0.0526],\n",
            "        [0.2637],\n",
            "        [0.2653],\n",
            "        [0.5137],\n",
            "        [0.2417],\n",
            "        [0.5192],\n",
            "        [0.0616],\n",
            "        [0.0589],\n",
            "        [0.2975],\n",
            "        [0.1366],\n",
            "        [0.1460],\n",
            "        [1.0000],\n",
            "        [0.2907],\n",
            "        [0.0478],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.8466],\n",
            "        [1.0000],\n",
            "        [0.5458],\n",
            "        [0.0836],\n",
            "        [0.0661],\n",
            "        [0.5950],\n",
            "        [0.1564],\n",
            "        [0.7383],\n",
            "        [0.1482],\n",
            "        [0.0874],\n",
            "        [0.1036],\n",
            "        [0.0136],\n",
            "        [0.1710],\n",
            "        [0.3181],\n",
            "        [0.0932],\n",
            "        [0.1279],\n",
            "        [0.0738],\n",
            "        [0.5986],\n",
            "        [0.1309],\n",
            "        [0.5684],\n",
            "        [0.4329],\n",
            "        [0.4022],\n",
            "        [0.0509],\n",
            "        [1.0000],\n",
            "        [0.0930],\n",
            "        [0.3622],\n",
            "        [0.6285],\n",
            "        [0.0204],\n",
            "        [0.0400],\n",
            "        [0.4648],\n",
            "        [0.4888],\n",
            "        [0.0746],\n",
            "        [0.5997],\n",
            "        [0.1226],\n",
            "        [0.1428],\n",
            "        [1.0000],\n",
            "        [0.2761],\n",
            "        [0.8673],\n",
            "        [0.5736],\n",
            "        [0.0904],\n",
            "        [0.2847],\n",
            "        [0.1933],\n",
            "        [0.9925],\n",
            "        [0.0530],\n",
            "        [1.0000],\n",
            "        [0.3818],\n",
            "        [0.1926],\n",
            "        [0.2347],\n",
            "        [0.0495],\n",
            "        [0.1507],\n",
            "        [0.0944],\n",
            "        [0.6934],\n",
            "        [0.3214],\n",
            "        [0.0658],\n",
            "        [0.4168],\n",
            "        [0.0598],\n",
            "        [0.0755],\n",
            "        [0.3732],\n",
            "        [0.1074],\n",
            "        [0.1907],\n",
            "        [0.0793],\n",
            "        [0.0125],\n",
            "        [0.6042],\n",
            "        [0.2933],\n",
            "        [0.0921],\n",
            "        [0.1638],\n",
            "        [0.5166],\n",
            "        [0.1108],\n",
            "        [0.1479],\n",
            "        [0.6797],\n",
            "        [0.0729],\n",
            "        [0.3447],\n",
            "        [0.1113],\n",
            "        [0.0074],\n",
            "        [0.3192],\n",
            "        [0.0732],\n",
            "        [0.4896],\n",
            "        [0.0898],\n",
            "        [0.2058],\n",
            "        [0.1809],\n",
            "        [0.4949],\n",
            "        [0.1215],\n",
            "        [0.5396],\n",
            "        [0.3673],\n",
            "        [0.4221],\n",
            "        [0.5566],\n",
            "        [0.1831],\n",
            "        [0.1356],\n",
            "        [0.1146],\n",
            "        [0.2202],\n",
            "        [0.0026],\n",
            "        [0.2610],\n",
            "        [0.3612],\n",
            "        [0.2210],\n",
            "        [0.0115],\n",
            "        [0.1540],\n",
            "        [0.1382],\n",
            "        [0.0398],\n",
            "        [0.2324],\n",
            "        [0.0707],\n",
            "        [0.2244],\n",
            "        [0.3915],\n",
            "        [0.7267],\n",
            "        [0.0852],\n",
            "        [0.9519],\n",
            "        [0.8890],\n",
            "        [1.0000],\n",
            "        [0.0270],\n",
            "        [0.8057],\n",
            "        [0.2766],\n",
            "        [1.0000],\n",
            "        [0.3670],\n",
            "        [0.5905],\n",
            "        [0.8443],\n",
            "        [0.0209],\n",
            "        [0.0020],\n",
            "        [0.4240],\n",
            "        [0.1114],\n",
            "        [0.2551],\n",
            "        [1.0000],\n",
            "        [0.1128],\n",
            "        [0.0226],\n",
            "        [0.0706],\n",
            "        [0.1425],\n",
            "        [0.5396],\n",
            "        [0.2499],\n",
            "        [0.4385],\n",
            "        [0.0569],\n",
            "        [0.7493],\n",
            "        [0.4873],\n",
            "        [1.0000],\n",
            "        [0.0396],\n",
            "        [0.0212],\n",
            "        [0.0917],\n",
            "        [0.4900],\n",
            "        [0.3780],\n",
            "        [0.9537],\n",
            "        [0.5273],\n",
            "        [0.5015],\n",
            "        [0.4526],\n",
            "        [0.6640],\n",
            "        [0.9036],\n",
            "        [0.6609],\n",
            "        [0.6129],\n",
            "        [0.0723],\n",
            "        [0.4331],\n",
            "        [0.6472],\n",
            "        [0.3413],\n",
            "        [0.1697],\n",
            "        [0.5351],\n",
            "        [0.3211],\n",
            "        [0.0349],\n",
            "        [0.1421],\n",
            "        [0.0347],\n",
            "        [0.1976],\n",
            "        [1.0000],\n",
            "        [0.9426],\n",
            "        [0.3868],\n",
            "        [0.0022],\n",
            "        [0.9736],\n",
            "        [0.5517],\n",
            "        [1.0000],\n",
            "        [0.0039],\n",
            "        [0.4918],\n",
            "        [0.4659],\n",
            "        [1.0000],\n",
            "        [0.4971],\n",
            "        [1.0000],\n",
            "        [0.6098],\n",
            "        [0.1030],\n",
            "        [0.1271],\n",
            "        [0.4269],\n",
            "        [0.7659],\n",
            "        [0.4114],\n",
            "        [0.3915],\n",
            "        [0.4465],\n",
            "        [0.2480],\n",
            "        [0.0216],\n",
            "        [0.0492],\n",
            "        [0.0514],\n",
            "        [0.0448],\n",
            "        [0.1160],\n",
            "        [0.0409],\n",
            "        [0.0487],\n",
            "        [0.0296],\n",
            "        [0.1258],\n",
            "        [0.0222],\n",
            "        [0.0288],\n",
            "        [0.0175],\n",
            "        [0.0245],\n",
            "        [0.0724],\n",
            "        [0.0415],\n",
            "        [0.0395],\n",
            "        [0.0638],\n",
            "        [0.0335],\n",
            "        [0.0989],\n",
            "        [0.0658],\n",
            "        [0.2023],\n",
            "        [0.0483],\n",
            "        [0.0398],\n",
            "        [0.0274],\n",
            "        [0.0792],\n",
            "        [0.0168],\n",
            "        [0.1511],\n",
            "        [0.0379],\n",
            "        [0.2555],\n",
            "        [0.1387],\n",
            "        [0.1587],\n",
            "        [0.8037],\n",
            "        [0.7510],\n",
            "        [0.0354],\n",
            "        [0.4384],\n",
            "        [0.6548],\n",
            "        [0.1266],\n",
            "        [0.1825],\n",
            "        [0.1372],\n",
            "        [0.1137],\n",
            "        [0.0497],\n",
            "        [0.0733],\n",
            "        [0.2562],\n",
            "        [0.3874],\n",
            "        [0.3403],\n",
            "        [0.0549],\n",
            "        [0.0350],\n",
            "        [0.4400],\n",
            "        [0.0963],\n",
            "        [0.8298],\n",
            "        [0.2418],\n",
            "        [0.4063],\n",
            "        [0.0360],\n",
            "        [0.1896],\n",
            "        [1.0000],\n",
            "        [0.6663],\n",
            "        [0.4688],\n",
            "        [0.5476],\n",
            "        [0.3494],\n",
            "        [0.4552],\n",
            "        [1.0000],\n",
            "        [0.2076],\n",
            "        [0.7823],\n",
            "        [0.3434],\n",
            "        [0.4403],\n",
            "        [0.0955],\n",
            "        [0.5256],\n",
            "        [0.2341],\n",
            "        [0.0605],\n",
            "        [0.1107],\n",
            "        [0.0388],\n",
            "        [0.0744],\n",
            "        [1.0000],\n",
            "        [0.1375],\n",
            "        [0.0163],\n",
            "        [0.5064],\n",
            "        [0.7643],\n",
            "        [0.0667],\n",
            "        [0.1421],\n",
            "        [0.0856],\n",
            "        [0.1714],\n",
            "        [0.1683],\n",
            "        [0.2343],\n",
            "        [0.0763],\n",
            "        [0.4178],\n",
            "        [0.0972],\n",
            "        [0.2800],\n",
            "        [0.0735],\n",
            "        [0.2085],\n",
            "        [0.2189],\n",
            "        [0.3422],\n",
            "        [0.1604],\n",
            "        [0.9719],\n",
            "        [1.0000],\n",
            "        [0.4589],\n",
            "        [0.2066],\n",
            "        [0.0417],\n",
            "        [0.1853],\n",
            "        [0.0815],\n",
            "        [0.0218],\n",
            "        [0.2330],\n",
            "        [0.0394],\n",
            "        [0.2955],\n",
            "        [0.3204],\n",
            "        [0.5487],\n",
            "        [0.1723],\n",
            "        [0.2869],\n",
            "        [0.3066],\n",
            "        [0.3998],\n",
            "        [0.6446],\n",
            "        [0.3397],\n",
            "        [0.2826],\n",
            "        [0.3616],\n",
            "        [0.3954],\n",
            "        [0.4052],\n",
            "        [0.2708],\n",
            "        [0.1449],\n",
            "        [1.0000],\n",
            "        [0.1041],\n",
            "        [0.7139],\n",
            "        [0.1893],\n",
            "        [0.2629],\n",
            "        [0.4443],\n",
            "        [0.7169],\n",
            "        [1.0000],\n",
            "        [0.2719],\n",
            "        [0.0344],\n",
            "        [0.0747],\n",
            "        [0.0717],\n",
            "        [0.4316],\n",
            "        [0.7741],\n",
            "        [0.0089],\n",
            "        [0.0638],\n",
            "        [1.0000],\n",
            "        [0.2871],\n",
            "        [0.2995],\n",
            "        [0.4347],\n",
            "        [0.7895],\n",
            "        [0.1105],\n",
            "        [0.2477],\n",
            "        [0.8325],\n",
            "        [0.2359],\n",
            "        [0.5043],\n",
            "        [0.3333],\n",
            "        [0.1594],\n",
            "        [0.0142],\n",
            "        [0.0622],\n",
            "        [0.0902],\n",
            "        [0.0113],\n",
            "        [0.5932],\n",
            "        [0.7026],\n",
            "        [0.1338],\n",
            "        [0.0638],\n",
            "        [0.0552],\n",
            "        [0.1671],\n",
            "        [0.0713],\n",
            "        [0.0344],\n",
            "        [0.3230],\n",
            "        [0.0671],\n",
            "        [0.0612],\n",
            "        [0.1337],\n",
            "        [0.0247],\n",
            "        [0.0798],\n",
            "        [0.3528],\n",
            "        [0.5027],\n",
            "        [0.7039],\n",
            "        [1.0000],\n",
            "        [0.2878],\n",
            "        [0.0700],\n",
            "        [0.0375],\n",
            "        [0.6571],\n",
            "        [0.0395],\n",
            "        [0.0462],\n",
            "        [0.1186],\n",
            "        [0.0335],\n",
            "        [1.0000],\n",
            "        [0.2144],\n",
            "        [0.2182],\n",
            "        [0.2033],\n",
            "        [0.6828],\n",
            "        [0.0766],\n",
            "        [0.0718],\n",
            "        [0.0861],\n",
            "        [0.0228],\n",
            "        [0.9964],\n",
            "        [1.0000],\n",
            "        [0.3780],\n",
            "        [0.2425],\n",
            "        [0.9091],\n",
            "        [0.8175],\n",
            "        [0.1943],\n",
            "        [0.3286],\n",
            "        [0.7354],\n",
            "        [0.0882],\n",
            "        [0.5753],\n",
            "        [0.0409],\n",
            "        [0.0600],\n",
            "        [0.1799],\n",
            "        [0.2281],\n",
            "        [0.5863],\n",
            "        [0.0145],\n",
            "        [0.1333],\n",
            "        [0.1519],\n",
            "        [0.5058],\n",
            "        [0.2329],\n",
            "        [0.0166],\n",
            "        [0.0221],\n",
            "        [0.2844],\n",
            "        [0.6261],\n",
            "        [1.0000],\n",
            "        [0.0738],\n",
            "        [0.3613],\n",
            "        [0.1427],\n",
            "        [0.1559],\n",
            "        [0.4143],\n",
            "        [0.0767],\n",
            "        [0.3595],\n",
            "        [0.0934],\n",
            "        [0.0290],\n",
            "        [0.6909],\n",
            "        [1.0000],\n",
            "        [0.2044],\n",
            "        [0.8456],\n",
            "        [0.1570],\n",
            "        [0.6457],\n",
            "        [0.0064],\n",
            "        [0.1708],\n",
            "        [0.0633],\n",
            "        [0.9418],\n",
            "        [0.0281],\n",
            "        [0.0086],\n",
            "        [0.6039],\n",
            "        [0.2846],\n",
            "        [0.2821],\n",
            "        [0.0696],\n",
            "        [0.2283],\n",
            "        [0.2939],\n",
            "        [0.1087],\n",
            "        [0.4184],\n",
            "        [0.5101],\n",
            "        [0.7152],\n",
            "        [0.0320],\n",
            "        [0.0797],\n",
            "        [1.0000],\n",
            "        [0.2391],\n",
            "        [0.0575],\n",
            "        [0.3524],\n",
            "        [0.3337],\n",
            "        [0.1137],\n",
            "        [0.2390],\n",
            "        [0.2283],\n",
            "        [0.1761],\n",
            "        [0.1389],\n",
            "        [0.4430],\n",
            "        [0.0732],\n",
            "        [0.1607],\n",
            "        [1.0000],\n",
            "        [0.5644],\n",
            "        [0.1314],\n",
            "        [0.4022],\n",
            "        [0.2799],\n",
            "        [0.3263],\n",
            "        [0.2987],\n",
            "        [0.1683],\n",
            "        [0.9467],\n",
            "        [0.4441],\n",
            "        [0.5954],\n",
            "        [0.0029],\n",
            "        [0.1493],\n",
            "        [0.0576],\n",
            "        [0.5446],\n",
            "        [0.3687],\n",
            "        [0.1442],\n",
            "        [0.1071],\n",
            "        [0.1420],\n",
            "        [0.2088],\n",
            "        [0.5777],\n",
            "        [1.0000],\n",
            "        [0.3677],\n",
            "        [0.0383],\n",
            "        [0.0233],\n",
            "        [0.0387],\n",
            "        [0.6148],\n",
            "        [0.1195],\n",
            "        [0.1067],\n",
            "        [0.1600],\n",
            "        [0.0390],\n",
            "        [1.0000],\n",
            "        [0.0653],\n",
            "        [0.3330],\n",
            "        [0.1188],\n",
            "        [0.2913],\n",
            "        [0.0309],\n",
            "        [0.1120],\n",
            "        [0.1799],\n",
            "        [0.1419],\n",
            "        [0.1202],\n",
            "        [0.4585],\n",
            "        [0.0171],\n",
            "        [0.0464],\n",
            "        [0.5838],\n",
            "        [0.0470],\n",
            "        [0.1685],\n",
            "        [0.2367],\n",
            "        [0.7918],\n",
            "        [0.1420],\n",
            "        [0.1547],\n",
            "        [0.6156],\n",
            "        [0.1110],\n",
            "        [0.3763],\n",
            "        [0.0450],\n",
            "        [0.1245],\n",
            "        [0.1499],\n",
            "        [0.1167],\n",
            "        [0.3048],\n",
            "        [0.2895],\n",
            "        [0.0027],\n",
            "        [0.1653],\n",
            "        [0.3833],\n",
            "        [0.1507],\n",
            "        [0.0118],\n",
            "        [0.0961],\n",
            "        [0.4322],\n",
            "        [0.2814],\n",
            "        [0.4466],\n",
            "        [0.0375],\n",
            "        [0.4953],\n",
            "        [0.7260],\n",
            "        [0.2629],\n",
            "        [0.1448],\n",
            "        [0.1251],\n",
            "        [0.5530],\n",
            "        [0.6276],\n",
            "        [0.4577],\n",
            "        [0.3861],\n",
            "        [0.0430],\n",
            "        [0.1478],\n",
            "        [0.1538],\n",
            "        [0.3511],\n",
            "        [0.3679],\n",
            "        [0.1860],\n",
            "        [0.1101],\n",
            "        [1.0000],\n",
            "        [0.3395],\n",
            "        [0.4292],\n",
            "        [0.0981],\n",
            "        [0.0090],\n",
            "        [0.4104],\n",
            "        [0.5419],\n",
            "        [0.2914],\n",
            "        [1.0000],\n",
            "        [0.1407],\n",
            "        [0.7847],\n",
            "        [0.2228],\n",
            "        [0.0143],\n",
            "        [0.0894],\n",
            "        [0.1893],\n",
            "        [0.0037],\n",
            "        [0.6113],\n",
            "        [0.0227],\n",
            "        [0.0198],\n",
            "        [0.0371],\n",
            "        [0.5014],\n",
            "        [0.3955],\n",
            "        [0.1643],\n",
            "        [0.4345],\n",
            "        [0.0717],\n",
            "        [0.3588],\n",
            "        [0.1890],\n",
            "        [0.6763],\n",
            "        [0.3267],\n",
            "        [0.1317],\n",
            "        [0.0452],\n",
            "        [0.2685],\n",
            "        [0.1480],\n",
            "        [0.0739],\n",
            "        [0.0422],\n",
            "        [0.1160],\n",
            "        [0.1466],\n",
            "        [1.0000],\n",
            "        [0.2060],\n",
            "        [0.6097],\n",
            "        [1.0000],\n",
            "        [0.0402],\n",
            "        [0.0840],\n",
            "        [0.0543],\n",
            "        [0.0168],\n",
            "        [0.0684],\n",
            "        [0.3268],\n",
            "        [0.0292],\n",
            "        [0.0668],\n",
            "        [0.5577],\n",
            "        [0.1656],\n",
            "        [0.3260],\n",
            "        [0.0381],\n",
            "        [0.0306],\n",
            "        [0.0729],\n",
            "        [1.0000],\n",
            "        [0.0880],\n",
            "        [0.0707],\n",
            "        [0.1630],\n",
            "        [0.0152],\n",
            "        [0.0362],\n",
            "        [0.0739],\n",
            "        [0.0191],\n",
            "        [0.1827],\n",
            "        [0.5474],\n",
            "        [0.0467],\n",
            "        [0.7092],\n",
            "        [0.1145],\n",
            "        [0.1154],\n",
            "        [0.2286],\n",
            "        [0.0778],\n",
            "        [0.4654],\n",
            "        [0.1575],\n",
            "        [0.1722],\n",
            "        [0.1941],\n",
            "        [0.2205],\n",
            "        [0.0431],\n",
            "        [0.3764],\n",
            "        [0.3930],\n",
            "        [0.0414],\n",
            "        [0.0406],\n",
            "        [1.0000],\n",
            "        [0.4400],\n",
            "        [0.0989],\n",
            "        [0.0644],\n",
            "        [0.0305],\n",
            "        [0.4770],\n",
            "        [1.0000],\n",
            "        [0.0738],\n",
            "        [0.0432],\n",
            "        [0.1729],\n",
            "        [0.1052],\n",
            "        [0.1339],\n",
            "        [0.2162],\n",
            "        [0.0409],\n",
            "        [0.0209],\n",
            "        [0.0511],\n",
            "        [0.0054],\n",
            "        [0.0547],\n",
            "        [0.1053],\n",
            "        [0.3648],\n",
            "        [0.9354],\n",
            "        [0.4095],\n",
            "        [0.5391],\n",
            "        [0.5209],\n",
            "        [0.0213],\n",
            "        [0.0784],\n",
            "        [1.0000],\n",
            "        [0.0097],\n",
            "        [1.0000],\n",
            "        [0.0393],\n",
            "        [0.8295],\n",
            "        [0.3003],\n",
            "        [0.0799],\n",
            "        [0.2739],\n",
            "        [0.1823],\n",
            "        [0.6535],\n",
            "        [0.1375],\n",
            "        [0.5236],\n",
            "        [0.0345],\n",
            "        [0.0316],\n",
            "        [0.1064],\n",
            "        [0.1611],\n",
            "        [0.0916],\n",
            "        [0.0586],\n",
            "        [0.0865],\n",
            "        [0.7904],\n",
            "        [0.1418],\n",
            "        [0.1393],\n",
            "        [0.4854],\n",
            "        [0.3130],\n",
            "        [0.0940],\n",
            "        [0.1205],\n",
            "        [0.2234],\n",
            "        [0.3264],\n",
            "        [0.2004],\n",
            "        [0.0691],\n",
            "        [0.1346],\n",
            "        [0.1029],\n",
            "        [0.0401],\n",
            "        [0.1285],\n",
            "        [0.0555],\n",
            "        [0.2742],\n",
            "        [0.6522],\n",
            "        [0.1536],\n",
            "        [0.2144],\n",
            "        [0.0106],\n",
            "        [0.0881],\n",
            "        [0.6326],\n",
            "        [0.0255],\n",
            "        [0.0297],\n",
            "        [0.0342],\n",
            "        [0.0823],\n",
            "        [0.0510],\n",
            "        [0.0378],\n",
            "        [0.0410],\n",
            "        [0.1058],\n",
            "        [0.1704],\n",
            "        [0.0728],\n",
            "        [0.1260],\n",
            "        [0.3938],\n",
            "        [0.1562],\n",
            "        [0.5025],\n",
            "        [0.9346],\n",
            "        [0.1655],\n",
            "        [0.6490],\n",
            "        [1.0000],\n",
            "        [0.0665],\n",
            "        [0.0022],\n",
            "        [0.5275],\n",
            "        [0.1905],\n",
            "        [0.0442],\n",
            "        [0.5409],\n",
            "        [0.1910],\n",
            "        [0.4206],\n",
            "        [0.0203],\n",
            "        [0.0966],\n",
            "        [0.0752],\n",
            "        [0.0176],\n",
            "        [0.0521],\n",
            "        [0.0579],\n",
            "        [0.0392],\n",
            "        [0.0131],\n",
            "        [0.1045],\n",
            "        [0.5853],\n",
            "        [0.1313],\n",
            "        [0.1621],\n",
            "        [0.1919],\n",
            "        [0.2930],\n",
            "        [0.1693],\n",
            "        [0.0606],\n",
            "        [0.2769],\n",
            "        [0.1252],\n",
            "        [0.1136],\n",
            "        [0.2492],\n",
            "        [0.2440],\n",
            "        [0.7159],\n",
            "        [0.4882],\n",
            "        [0.3176],\n",
            "        [0.2892],\n",
            "        [0.1437],\n",
            "        [0.2928],\n",
            "        [0.1700],\n",
            "        [0.7412],\n",
            "        [0.9296],\n",
            "        [1.0000],\n",
            "        [0.6531],\n",
            "        [0.1073],\n",
            "        [0.0702],\n",
            "        [0.0782],\n",
            "        [0.1016],\n",
            "        [0.1579],\n",
            "        [0.3720],\n",
            "        [0.3677],\n",
            "        [0.3498],\n",
            "        [0.4528],\n",
            "        [0.1867],\n",
            "        [0.9082],\n",
            "        [0.1292],\n",
            "        [0.1013],\n",
            "        [0.3027],\n",
            "        [0.2353],\n",
            "        [0.5917],\n",
            "        [0.1775],\n",
            "        [0.5195],\n",
            "        [0.1134],\n",
            "        [0.2188],\n",
            "        [0.1856],\n",
            "        [0.1123],\n",
            "        [0.6131],\n",
            "        [0.6980],\n",
            "        [0.0725],\n",
            "        [0.5260],\n",
            "        [0.3009],\n",
            "        [0.1999],\n",
            "        [0.1379],\n",
            "        [1.0000],\n",
            "        [0.2219],\n",
            "        [0.2032],\n",
            "        [0.2687],\n",
            "        [0.1390],\n",
            "        [0.3186],\n",
            "        [0.1686],\n",
            "        [0.1953]])\n",
            "y_test_data tensor([[0.2905],\n",
            "        [0.4138],\n",
            "        [0.0558],\n",
            "        [0.0634],\n",
            "        [0.0414],\n",
            "        [0.0571],\n",
            "        [0.2096],\n",
            "        [0.3854],\n",
            "        [0.2260],\n",
            "        [0.1627],\n",
            "        [0.4779],\n",
            "        [1.0000],\n",
            "        [0.8417],\n",
            "        [0.4917],\n",
            "        [0.1004],\n",
            "        [0.7282],\n",
            "        [0.3487],\n",
            "        [0.2106],\n",
            "        [0.1163],\n",
            "        [0.1497],\n",
            "        [0.3482],\n",
            "        [0.0969],\n",
            "        [0.1787],\n",
            "        [0.0840],\n",
            "        [0.1663],\n",
            "        [0.1318],\n",
            "        [0.2430],\n",
            "        [0.1366],\n",
            "        [0.1876],\n",
            "        [0.0432],\n",
            "        [0.0761],\n",
            "        [0.0632],\n",
            "        [0.3013],\n",
            "        [0.5176],\n",
            "        [0.6209],\n",
            "        [0.0202],\n",
            "        [0.1058],\n",
            "        [1.0000],\n",
            "        [0.1024],\n",
            "        [0.3109],\n",
            "        [0.1410],\n",
            "        [0.0759],\n",
            "        [0.1623],\n",
            "        [0.1526],\n",
            "        [0.2695],\n",
            "        [0.3350],\n",
            "        [0.1012],\n",
            "        [0.0670],\n",
            "        [0.1031],\n",
            "        [0.1988],\n",
            "        [0.2438],\n",
            "        [0.0645],\n",
            "        [0.1019],\n",
            "        [0.1207],\n",
            "        [0.0450],\n",
            "        [0.0857],\n",
            "        [0.1981],\n",
            "        [0.1901],\n",
            "        [0.4734],\n",
            "        [0.3259],\n",
            "        [0.5425],\n",
            "        [0.0714],\n",
            "        [0.5765],\n",
            "        [0.4959],\n",
            "        [0.0094],\n",
            "        [0.9576],\n",
            "        [0.2494],\n",
            "        [0.0191],\n",
            "        [0.0207],\n",
            "        [0.1148],\n",
            "        [0.0868],\n",
            "        [0.1217],\n",
            "        [0.3807],\n",
            "        [0.4320],\n",
            "        [0.6002],\n",
            "        [0.0745],\n",
            "        [0.0402],\n",
            "        [0.0381],\n",
            "        [0.0341],\n",
            "        [0.2083],\n",
            "        [0.1927],\n",
            "        [0.1915],\n",
            "        [0.3305],\n",
            "        [0.0717],\n",
            "        [0.2285],\n",
            "        [0.0482],\n",
            "        [0.0984],\n",
            "        [0.4014],\n",
            "        [0.0396],\n",
            "        [0.0612],\n",
            "        [0.3275],\n",
            "        [0.2901],\n",
            "        [0.1572],\n",
            "        [0.0716],\n",
            "        [0.5070],\n",
            "        [0.4909],\n",
            "        [0.1147],\n",
            "        [0.2071],\n",
            "        [0.1169],\n",
            "        [0.0808],\n",
            "        [0.0394],\n",
            "        [0.0497],\n",
            "        [0.0473],\n",
            "        [0.2616],\n",
            "        [0.1531],\n",
            "        [0.2614],\n",
            "        [0.4656],\n",
            "        [1.0000],\n",
            "        [0.3236],\n",
            "        [0.0381],\n",
            "        [0.2265],\n",
            "        [0.0614],\n",
            "        [0.0415],\n",
            "        [0.0376],\n",
            "        [0.0255],\n",
            "        [0.0751],\n",
            "        [0.2396],\n",
            "        [0.1029],\n",
            "        [0.0383],\n",
            "        [0.2123],\n",
            "        [0.0393],\n",
            "        [0.4627],\n",
            "        [0.1200],\n",
            "        [0.2774],\n",
            "        [0.8199],\n",
            "        [0.1181],\n",
            "        [0.0667],\n",
            "        [0.4591],\n",
            "        [0.3566],\n",
            "        [0.3264],\n",
            "        [0.5491],\n",
            "        [0.0076],\n",
            "        [0.4509],\n",
            "        [0.2040],\n",
            "        [0.1600],\n",
            "        [0.0646],\n",
            "        [0.0454],\n",
            "        [0.1099],\n",
            "        [0.0997],\n",
            "        [0.1874],\n",
            "        [0.0126],\n",
            "        [0.2367],\n",
            "        [0.3920],\n",
            "        [0.1122],\n",
            "        [0.0362],\n",
            "        [0.3079],\n",
            "        [0.0974],\n",
            "        [0.2129],\n",
            "        [0.0347],\n",
            "        [0.6693],\n",
            "        [0.6996],\n",
            "        [1.0000],\n",
            "        [0.0024],\n",
            "        [0.7431],\n",
            "        [0.1548],\n",
            "        [0.3637],\n",
            "        [0.0655],\n",
            "        [0.1733],\n",
            "        [0.2460],\n",
            "        [0.0907],\n",
            "        [0.0999],\n",
            "        [0.3283],\n",
            "        [0.1964],\n",
            "        [0.0550],\n",
            "        [0.4847],\n",
            "        [0.5815],\n",
            "        [0.0146],\n",
            "        [0.0722],\n",
            "        [0.0898],\n",
            "        [0.4501],\n",
            "        [0.4386],\n",
            "        [0.1549],\n",
            "        [0.3573],\n",
            "        [0.3442],\n",
            "        [0.2468],\n",
            "        [0.2733],\n",
            "        [0.0047],\n",
            "        [0.4323],\n",
            "        [0.4736],\n",
            "        [1.0000],\n",
            "        [0.0478],\n",
            "        [0.1609],\n",
            "        [0.7323],\n",
            "        [0.0220],\n",
            "        [0.0260],\n",
            "        [0.0409],\n",
            "        [0.0581],\n",
            "        [0.2917],\n",
            "        [0.0709],\n",
            "        [0.0318],\n",
            "        [0.0035],\n",
            "        [0.0051],\n",
            "        [0.1708],\n",
            "        [0.2498],\n",
            "        [0.7912],\n",
            "        [0.0979],\n",
            "        [1.0000],\n",
            "        [0.3806],\n",
            "        [0.1529],\n",
            "        [0.2142],\n",
            "        [0.1303],\n",
            "        [0.1900],\n",
            "        [0.1355],\n",
            "        [0.7581],\n",
            "        [0.2362],\n",
            "        [0.2900],\n",
            "        [0.4483],\n",
            "        [0.9900],\n",
            "        [0.0384],\n",
            "        [0.0726],\n",
            "        [0.3724],\n",
            "        [0.4604],\n",
            "        [0.1505],\n",
            "        [0.0703],\n",
            "        [0.8946],\n",
            "        [0.1741],\n",
            "        [0.6558],\n",
            "        [0.0129],\n",
            "        [0.2217],\n",
            "        [0.3803],\n",
            "        [0.1291],\n",
            "        [0.3616],\n",
            "        [0.0353],\n",
            "        [0.0391],\n",
            "        [0.2902],\n",
            "        [0.1158],\n",
            "        [0.1629],\n",
            "        [0.0699],\n",
            "        [0.0265],\n",
            "        [1.0000],\n",
            "        [0.0830],\n",
            "        [0.3402],\n",
            "        [0.1002],\n",
            "        [0.8251],\n",
            "        [0.1671],\n",
            "        [0.1885],\n",
            "        [0.0022],\n",
            "        [0.6669],\n",
            "        [0.6698],\n",
            "        [0.0665],\n",
            "        [0.0937],\n",
            "        [0.2486],\n",
            "        [0.2830],\n",
            "        [1.0000],\n",
            "        [0.2115],\n",
            "        [0.6577],\n",
            "        [0.8638],\n",
            "        [0.6452],\n",
            "        [0.3605],\n",
            "        [0.0064],\n",
            "        [0.0978],\n",
            "        [0.0552],\n",
            "        [0.2200],\n",
            "        [0.5453],\n",
            "        [0.1490],\n",
            "        [0.0373],\n",
            "        [0.2637],\n",
            "        [0.2501],\n",
            "        [0.1805],\n",
            "        [0.2414],\n",
            "        [0.0137],\n",
            "        [0.7147],\n",
            "        [0.4024],\n",
            "        [0.2233],\n",
            "        [0.0974],\n",
            "        [0.4258],\n",
            "        [0.1569],\n",
            "        [0.1793],\n",
            "        [0.3297],\n",
            "        [0.0870],\n",
            "        [0.2088],\n",
            "        [0.0762],\n",
            "        [0.1747],\n",
            "        [0.3548],\n",
            "        [0.1214],\n",
            "        [0.3002],\n",
            "        [0.1897],\n",
            "        [0.4681],\n",
            "        [0.0633],\n",
            "        [0.0756],\n",
            "        [0.4083],\n",
            "        [0.0673],\n",
            "        [0.4281],\n",
            "        [0.0492],\n",
            "        [0.2128],\n",
            "        [0.0999],\n",
            "        [0.1571],\n",
            "        [0.1993],\n",
            "        [0.2387],\n",
            "        [0.1563],\n",
            "        [0.1363],\n",
            "        [0.3970],\n",
            "        [0.0250],\n",
            "        [0.4429],\n",
            "        [0.1005],\n",
            "        [0.1046],\n",
            "        [0.1660],\n",
            "        [0.0113],\n",
            "        [0.1196],\n",
            "        [0.0740],\n",
            "        [0.1615],\n",
            "        [0.0513],\n",
            "        [0.1033],\n",
            "        [0.1496],\n",
            "        [0.0524],\n",
            "        [0.0654],\n",
            "        [0.0763],\n",
            "        [0.0911],\n",
            "        [0.4934],\n",
            "        [0.1520],\n",
            "        [0.5364],\n",
            "        [0.2513],\n",
            "        [0.2667],\n",
            "        [0.1155],\n",
            "        [0.6917],\n",
            "        [0.1897],\n",
            "        [0.4272],\n",
            "        [0.1916],\n",
            "        [0.1487],\n",
            "        [0.1962],\n",
            "        [0.2396],\n",
            "        [0.2856],\n",
            "        [0.0476],\n",
            "        [0.2017],\n",
            "        [0.2115],\n",
            "        [0.1002],\n",
            "        [0.0037],\n",
            "        [0.0050],\n",
            "        [0.0036],\n",
            "        [0.0607],\n",
            "        [0.1948],\n",
            "        [0.4711],\n",
            "        [0.2258],\n",
            "        [0.0834],\n",
            "        [0.0165],\n",
            "        [0.0978],\n",
            "        [0.7646],\n",
            "        [0.0269],\n",
            "        [0.5491],\n",
            "        [0.0389],\n",
            "        [0.7723],\n",
            "        [0.1679],\n",
            "        [0.0201],\n",
            "        [0.3911],\n",
            "        [0.3414],\n",
            "        [0.0985],\n",
            "        [0.1994],\n",
            "        [0.0367],\n",
            "        [0.0427],\n",
            "        [0.1667],\n",
            "        [0.6906],\n",
            "        [0.4803],\n",
            "        [0.0545],\n",
            "        [0.5769],\n",
            "        [0.0428],\n",
            "        [0.0021],\n",
            "        [0.2898],\n",
            "        [0.1730],\n",
            "        [0.0153],\n",
            "        [0.0210],\n",
            "        [0.3894],\n",
            "        [0.1854],\n",
            "        [0.0516],\n",
            "        [0.2722],\n",
            "        [0.3443],\n",
            "        [0.1148],\n",
            "        [0.4934],\n",
            "        [1.0000],\n",
            "        [0.5383],\n",
            "        [0.1455],\n",
            "        [0.2760],\n",
            "        [0.0028],\n",
            "        [0.1421],\n",
            "        [0.3106],\n",
            "        [0.4408],\n",
            "        [0.0960],\n",
            "        [0.2385],\n",
            "        [0.8496],\n",
            "        [0.2474],\n",
            "        [0.2162],\n",
            "        [0.4042],\n",
            "        [0.1009],\n",
            "        [0.2154],\n",
            "        [0.0889],\n",
            "        [0.0663],\n",
            "        [0.7277],\n",
            "        [0.2739],\n",
            "        [0.0870],\n",
            "        [0.3906],\n",
            "        [0.2752],\n",
            "        [0.3292],\n",
            "        [0.2592],\n",
            "        [0.1591],\n",
            "        [0.3442],\n",
            "        [0.1681],\n",
            "        [0.4459],\n",
            "        [0.3542],\n",
            "        [0.4263],\n",
            "        [0.0800],\n",
            "        [0.3990],\n",
            "        [0.3342],\n",
            "        [0.3115],\n",
            "        [0.0710],\n",
            "        [0.1136],\n",
            "        [0.0623],\n",
            "        [0.1175],\n",
            "        [0.1139],\n",
            "        [0.0421],\n",
            "        [0.0958],\n",
            "        [0.6308],\n",
            "        [0.2213],\n",
            "        [0.1770],\n",
            "        [0.0563],\n",
            "        [0.1296],\n",
            "        [0.6989],\n",
            "        [0.1038],\n",
            "        [0.0892],\n",
            "        [0.2267],\n",
            "        [0.0548],\n",
            "        [0.7630],\n",
            "        [0.0263],\n",
            "        [0.3782],\n",
            "        [0.0946],\n",
            "        [0.8948],\n",
            "        [0.8158],\n",
            "        [0.1882],\n",
            "        [0.9363],\n",
            "        [0.0693],\n",
            "        [0.4388],\n",
            "        [0.0809],\n",
            "        [0.1139],\n",
            "        [0.2955],\n",
            "        [0.1044],\n",
            "        [0.2508],\n",
            "        [0.8290],\n",
            "        [0.0637],\n",
            "        [0.1320],\n",
            "        [0.0382],\n",
            "        [0.4277],\n",
            "        [0.1713],\n",
            "        [0.4515],\n",
            "        [0.1211],\n",
            "        [0.0703],\n",
            "        [0.3160],\n",
            "        [0.1439],\n",
            "        [0.3067],\n",
            "        [1.0000],\n",
            "        [0.5652],\n",
            "        [0.2088],\n",
            "        [0.4383],\n",
            "        [0.0696],\n",
            "        [0.0551],\n",
            "        [0.3407],\n",
            "        [0.4540],\n",
            "        [0.6390],\n",
            "        [0.6172],\n",
            "        [0.1149],\n",
            "        [0.2921],\n",
            "        [0.1667],\n",
            "        [0.7880],\n",
            "        [0.9166],\n",
            "        [0.1608],\n",
            "        [0.3438],\n",
            "        [0.0675],\n",
            "        [0.0427],\n",
            "        [0.0031],\n",
            "        [0.0656],\n",
            "        [0.1080],\n",
            "        [0.0447],\n",
            "        [0.1571],\n",
            "        [0.1522],\n",
            "        [0.8334],\n",
            "        [0.0600],\n",
            "        [0.0564],\n",
            "        [0.1052],\n",
            "        [0.2234],\n",
            "        [0.0549],\n",
            "        [0.0563],\n",
            "        [1.0000],\n",
            "        [0.7691],\n",
            "        [0.3375],\n",
            "        [0.0387],\n",
            "        [0.4271],\n",
            "        [0.1287],\n",
            "        [0.0882],\n",
            "        [0.2780],\n",
            "        [0.1247],\n",
            "        [0.0581],\n",
            "        [0.1767],\n",
            "        [0.2115],\n",
            "        [0.6352],\n",
            "        [0.2878],\n",
            "        [0.0602],\n",
            "        [1.0000],\n",
            "        [0.3529],\n",
            "        [0.1817],\n",
            "        [0.1019],\n",
            "        [0.3930],\n",
            "        [0.0609],\n",
            "        [0.5716],\n",
            "        [0.1380],\n",
            "        [0.0528],\n",
            "        [0.0726],\n",
            "        [1.0000],\n",
            "        [0.1635],\n",
            "        [0.0899],\n",
            "        [0.6695],\n",
            "        [0.0930],\n",
            "        [0.0329],\n",
            "        [0.0640],\n",
            "        [0.0723],\n",
            "        [0.3651],\n",
            "        [0.2055],\n",
            "        [0.2768],\n",
            "        [0.6159],\n",
            "        [0.1454],\n",
            "        [0.4062],\n",
            "        [0.0988],\n",
            "        [0.0151],\n",
            "        [0.1494],\n",
            "        [0.2207],\n",
            "        [0.4739],\n",
            "        [0.5913],\n",
            "        [0.0646],\n",
            "        [0.2138],\n",
            "        [0.2294],\n",
            "        [0.1562],\n",
            "        [0.2331],\n",
            "        [0.0083],\n",
            "        [0.0346],\n",
            "        [0.0035],\n",
            "        [0.1289],\n",
            "        [0.3022],\n",
            "        [0.1016],\n",
            "        [0.0571],\n",
            "        [0.7405],\n",
            "        [0.1064],\n",
            "        [0.3778],\n",
            "        [0.0906],\n",
            "        [0.3961],\n",
            "        [0.1140],\n",
            "        [0.1763],\n",
            "        [0.1190],\n",
            "        [0.8663],\n",
            "        [0.1318],\n",
            "        [0.0657],\n",
            "        [0.2610],\n",
            "        [0.2635],\n",
            "        [0.0218],\n",
            "        [0.0622],\n",
            "        [0.1012],\n",
            "        [0.1834],\n",
            "        [0.0973],\n",
            "        [0.2746],\n",
            "        [0.6565],\n",
            "        [0.3646],\n",
            "        [0.1873],\n",
            "        [0.0958],\n",
            "        [0.2886],\n",
            "        [0.1409],\n",
            "        [0.7882],\n",
            "        [0.3627],\n",
            "        [0.3659],\n",
            "        [0.2959],\n",
            "        [0.5024],\n",
            "        [0.2041],\n",
            "        [0.2827],\n",
            "        [0.1028],\n",
            "        [0.3271],\n",
            "        [0.4351],\n",
            "        [0.2734],\n",
            "        [0.0868],\n",
            "        [0.0434],\n",
            "        [0.7601],\n",
            "        [0.4859],\n",
            "        [0.0898],\n",
            "        [0.0343],\n",
            "        [0.1080],\n",
            "        [0.0026],\n",
            "        [0.1511],\n",
            "        [0.0408],\n",
            "        [0.7346],\n",
            "        [0.0364],\n",
            "        [0.1725],\n",
            "        [0.0418],\n",
            "        [0.3718],\n",
            "        [0.1438],\n",
            "        [0.7239],\n",
            "        [0.4759],\n",
            "        [0.4037],\n",
            "        [0.1645],\n",
            "        [0.0528],\n",
            "        [0.4105],\n",
            "        [0.2687],\n",
            "        [0.5844],\n",
            "        [0.2843],\n",
            "        [0.4874],\n",
            "        [0.0639],\n",
            "        [0.5438],\n",
            "        [0.1183],\n",
            "        [0.2572],\n",
            "        [0.1292],\n",
            "        [0.0502],\n",
            "        [0.2799],\n",
            "        [0.0220],\n",
            "        [0.0551],\n",
            "        [0.1749],\n",
            "        [1.0000],\n",
            "        [0.2985],\n",
            "        [0.2746],\n",
            "        [0.1210],\n",
            "        [0.2282],\n",
            "        [0.1563],\n",
            "        [0.0044],\n",
            "        [0.0947],\n",
            "        [0.0024],\n",
            "        [0.0898],\n",
            "        [0.6397],\n",
            "        [0.1816],\n",
            "        [0.1595],\n",
            "        [0.0505],\n",
            "        [0.0332],\n",
            "        [0.2777],\n",
            "        [0.2316],\n",
            "        [0.4605],\n",
            "        [0.4327],\n",
            "        [0.9659],\n",
            "        [1.0000],\n",
            "        [0.5618],\n",
            "        [1.0000],\n",
            "        [0.2377],\n",
            "        [1.0000],\n",
            "        [0.2695],\n",
            "        [0.2265],\n",
            "        [1.0000],\n",
            "        [0.8716],\n",
            "        [0.9072],\n",
            "        [0.4918],\n",
            "        [0.7141],\n",
            "        [0.6613],\n",
            "        [0.1570],\n",
            "        [0.0376],\n",
            "        [0.7293],\n",
            "        [1.0000],\n",
            "        [0.0412],\n",
            "        [0.9940],\n",
            "        [0.7583],\n",
            "        [0.6002],\n",
            "        [0.9257],\n",
            "        [1.0000],\n",
            "        [0.2289],\n",
            "        [0.4206],\n",
            "        [1.0000],\n",
            "        [0.2817],\n",
            "        [1.0000],\n",
            "        [0.8942],\n",
            "        [0.2719],\n",
            "        [0.4605],\n",
            "        [0.4810],\n",
            "        [1.0000],\n",
            "        [0.3921],\n",
            "        [0.0718],\n",
            "        [1.0000],\n",
            "        [0.1449],\n",
            "        [0.0614],\n",
            "        [0.4447],\n",
            "        [0.1322],\n",
            "        [0.0595],\n",
            "        [0.0228],\n",
            "        [0.1957],\n",
            "        [0.5333],\n",
            "        [0.5391],\n",
            "        [0.5046],\n",
            "        [0.0473],\n",
            "        [0.0665],\n",
            "        [0.0315],\n",
            "        [0.1070],\n",
            "        [0.0525],\n",
            "        [0.0399],\n",
            "        [0.0603],\n",
            "        [0.0274],\n",
            "        [0.4739],\n",
            "        [1.0000],\n",
            "        [0.4302],\n",
            "        [0.2647],\n",
            "        [0.6847],\n",
            "        [0.0183],\n",
            "        [0.4492],\n",
            "        [0.7767],\n",
            "        [0.4579],\n",
            "        [0.6582],\n",
            "        [1.0000],\n",
            "        [0.2856],\n",
            "        [0.1948],\n",
            "        [0.9992],\n",
            "        [0.1265],\n",
            "        [0.6090],\n",
            "        [0.6852],\n",
            "        [0.3240],\n",
            "        [0.2183],\n",
            "        [0.0434],\n",
            "        [0.3677],\n",
            "        [0.2207],\n",
            "        [0.3095],\n",
            "        [0.2036],\n",
            "        [0.4368],\n",
            "        [0.2408],\n",
            "        [0.7867],\n",
            "        [0.2307],\n",
            "        [0.0076],\n",
            "        [0.0100],\n",
            "        [0.0456],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.0895],\n",
            "        [0.1237],\n",
            "        [1.0000],\n",
            "        [0.1877],\n",
            "        [0.0228],\n",
            "        [0.0620],\n",
            "        [0.0360],\n",
            "        [0.0190],\n",
            "        [0.0359],\n",
            "        [1.0000],\n",
            "        [0.1933],\n",
            "        [0.1422],\n",
            "        [0.4407],\n",
            "        [0.3850],\n",
            "        [0.4445],\n",
            "        [0.1076],\n",
            "        [0.0118],\n",
            "        [0.9129],\n",
            "        [0.0531],\n",
            "        [0.1282],\n",
            "        [0.2476],\n",
            "        [0.0889],\n",
            "        [0.1460],\n",
            "        [0.0403],\n",
            "        [0.3762],\n",
            "        [0.4222],\n",
            "        [0.8270],\n",
            "        [0.5851],\n",
            "        [0.3215],\n",
            "        [0.1072],\n",
            "        [0.4636],\n",
            "        [0.1054],\n",
            "        [0.8156],\n",
            "        [0.7890],\n",
            "        [0.6570],\n",
            "        [0.3806],\n",
            "        [0.3416],\n",
            "        [0.4413],\n",
            "        [0.1779],\n",
            "        [0.4075],\n",
            "        [0.2169],\n",
            "        [1.0000],\n",
            "        [0.4967],\n",
            "        [0.4373],\n",
            "        [0.1869],\n",
            "        [0.4829],\n",
            "        [0.6098],\n",
            "        [0.0657],\n",
            "        [0.9624],\n",
            "        [0.0498],\n",
            "        [0.5223],\n",
            "        [0.7793],\n",
            "        [0.1453],\n",
            "        [0.0397],\n",
            "        [0.6209],\n",
            "        [0.4188],\n",
            "        [0.0990],\n",
            "        [1.0000],\n",
            "        [0.4010],\n",
            "        [0.4813],\n",
            "        [0.3114],\n",
            "        [0.2604],\n",
            "        [1.0000],\n",
            "        [0.1772],\n",
            "        [0.2613],\n",
            "        [0.1874],\n",
            "        [0.2576],\n",
            "        [0.0025],\n",
            "        [0.6538],\n",
            "        [0.5346],\n",
            "        [0.0989],\n",
            "        [0.1428],\n",
            "        [0.3265],\n",
            "        [0.9017],\n",
            "        [0.0539],\n",
            "        [0.4693],\n",
            "        [0.3366],\n",
            "        [0.2103],\n",
            "        [0.2440],\n",
            "        [0.0706],\n",
            "        [0.5123],\n",
            "        [0.9074],\n",
            "        [0.5136],\n",
            "        [0.7793],\n",
            "        [0.2562],\n",
            "        [0.1391],\n",
            "        [0.4527],\n",
            "        [0.0129],\n",
            "        [0.6433],\n",
            "        [0.0171],\n",
            "        [0.3953],\n",
            "        [0.2413],\n",
            "        [0.0738],\n",
            "        [1.0000],\n",
            "        [0.1853],\n",
            "        [0.3294],\n",
            "        [0.7567],\n",
            "        [0.1775],\n",
            "        [0.1036],\n",
            "        [1.0000],\n",
            "        [0.3665],\n",
            "        [0.9694],\n",
            "        [0.1885],\n",
            "        [0.0317],\n",
            "        [0.2455],\n",
            "        [0.6648],\n",
            "        [0.4269],\n",
            "        [0.2590],\n",
            "        [0.2987],\n",
            "        [0.9532],\n",
            "        [0.0826],\n",
            "        [0.0408],\n",
            "        [0.7859],\n",
            "        [0.4450],\n",
            "        [0.7816],\n",
            "        [0.0473],\n",
            "        [0.0377],\n",
            "        [0.1943],\n",
            "        [0.1328],\n",
            "        [0.0661],\n",
            "        [0.5315],\n",
            "        [0.1037],\n",
            "        [0.1577],\n",
            "        [0.5936],\n",
            "        [0.1237],\n",
            "        [0.2647],\n",
            "        [0.1817],\n",
            "        [0.8354],\n",
            "        [0.1770],\n",
            "        [0.1607],\n",
            "        [0.3526],\n",
            "        [0.5014],\n",
            "        [0.5175],\n",
            "        [0.3798],\n",
            "        [0.0930],\n",
            "        [0.5243],\n",
            "        [0.5124],\n",
            "        [0.0924],\n",
            "        [0.4939],\n",
            "        [0.5563],\n",
            "        [0.3920],\n",
            "        [0.2285],\n",
            "        [0.4212],\n",
            "        [0.1723],\n",
            "        [0.6358],\n",
            "        [0.9434],\n",
            "        [0.0982],\n",
            "        [0.0228],\n",
            "        [0.2217],\n",
            "        [0.1136],\n",
            "        [0.4089],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.0437],\n",
            "        [0.1724],\n",
            "        [0.6244],\n",
            "        [0.1964],\n",
            "        [0.3551],\n",
            "        [0.2972],\n",
            "        [0.2562],\n",
            "        [0.2121],\n",
            "        [0.0501],\n",
            "        [0.6816],\n",
            "        [0.5989],\n",
            "        [0.6726],\n",
            "        [0.2104],\n",
            "        [0.2923],\n",
            "        [0.1058],\n",
            "        [0.2335],\n",
            "        [0.2196],\n",
            "        [0.1930],\n",
            "        [0.2590],\n",
            "        [0.0788],\n",
            "        [0.4757],\n",
            "        [0.1454],\n",
            "        [0.1190],\n",
            "        [0.2494],\n",
            "        [0.4061],\n",
            "        [0.0910],\n",
            "        [0.4658],\n",
            "        [0.1930],\n",
            "        [0.6326],\n",
            "        [0.4888],\n",
            "        [0.1005],\n",
            "        [0.2478],\n",
            "        [0.0018],\n",
            "        [0.2249],\n",
            "        [0.7536],\n",
            "        [0.1505],\n",
            "        [0.1553],\n",
            "        [0.3978],\n",
            "        [0.4769],\n",
            "        [0.2891],\n",
            "        [0.1654],\n",
            "        [1.0000],\n",
            "        [0.2052],\n",
            "        [0.0638],\n",
            "        [0.5705],\n",
            "        [0.1071],\n",
            "        [0.4708],\n",
            "        [0.6598],\n",
            "        [0.1951],\n",
            "        [0.2322],\n",
            "        [0.2209],\n",
            "        [0.3357],\n",
            "        [0.1046],\n",
            "        [0.7737],\n",
            "        [0.1274],\n",
            "        [0.0779],\n",
            "        [0.1069],\n",
            "        [0.7015],\n",
            "        [0.9708],\n",
            "        [0.1301],\n",
            "        [0.2762],\n",
            "        [0.0959],\n",
            "        [0.0259],\n",
            "        [0.7080],\n",
            "        [0.0400],\n",
            "        [0.2310],\n",
            "        [0.7622],\n",
            "        [0.9172],\n",
            "        [1.0000],\n",
            "        [0.2985],\n",
            "        [1.0000],\n",
            "        [0.4041],\n",
            "        [0.7114],\n",
            "        [0.0363],\n",
            "        [0.0141],\n",
            "        [0.2857],\n",
            "        [0.0458],\n",
            "        [0.2116],\n",
            "        [0.2152],\n",
            "        [0.2761],\n",
            "        [0.5560],\n",
            "        [0.1955],\n",
            "        [0.0223],\n",
            "        [0.0852],\n",
            "        [0.0292],\n",
            "        [0.0024],\n",
            "        [0.0104],\n",
            "        [0.0211],\n",
            "        [0.8732],\n",
            "        [0.1959],\n",
            "        [0.3845],\n",
            "        [0.1260],\n",
            "        [0.1769],\n",
            "        [0.2238],\n",
            "        [0.0428],\n",
            "        [0.1085],\n",
            "        [0.0677],\n",
            "        [0.5095],\n",
            "        [0.1454],\n",
            "        [0.9673],\n",
            "        [0.2472],\n",
            "        [0.1108],\n",
            "        [0.1216],\n",
            "        [0.1773],\n",
            "        [0.0987],\n",
            "        [0.2681],\n",
            "        [0.6009],\n",
            "        [0.1177],\n",
            "        [0.2673],\n",
            "        [0.1533],\n",
            "        [0.3452],\n",
            "        [0.0840],\n",
            "        [0.3269],\n",
            "        [0.2839],\n",
            "        [0.1793],\n",
            "        [0.9559],\n",
            "        [0.3155],\n",
            "        [0.1336],\n",
            "        [0.4224],\n",
            "        [0.6924],\n",
            "        [0.8656],\n",
            "        [0.4098],\n",
            "        [0.1198],\n",
            "        [0.1573]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time training(linearRegressionForAp2,optimizerForAp2,1000)"
      ],
      "metadata": {
        "id": "W3s2MkIH-v13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "866e577a-64e0-4412-d01f-ded29191819b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0000 dev loss= 0.14912276\n",
            "Epoch: 0100 dev loss= 0.10009476\n",
            "Epoch: 0200 dev loss= 0.08687051\n",
            "Epoch: 0300 dev loss= 0.08225392\n",
            "Epoch: 0400 dev loss= 0.08056862\n",
            "Epoch: 0500 dev loss= 0.07993797\n",
            "Epoch: 0600 dev loss= 0.07970515\n",
            "Epoch: 0700 dev loss= 0.07962994\n",
            "Epoch: 0800 dev loss= 0.07961952\n",
            "Epoch: 0900 dev loss= 0.07963561\n",
            "=========================================================\n",
            "Optimised: training loss= 0.078452975\n",
            "Optimised: dev loss= 0.079661146\n",
            "=========================================================\n",
            "CPU times: user 824 ms, sys: 11 ms, total: 835 ms\n",
            "Wall time: 838 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time testing(linearRegressionForAp2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JD2uL6U6m-EF",
        "outputId": "c8149f79-e4c0-4096-f654-d8c4617085aa"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================\n",
            "Optimised: training loss= 0.078452975\n",
            "Optimised: dev loss= 0.079661146\n",
            "=========================================================\n",
            "Testing loss= 0.069427423\n",
            "Absolute mean square loss difference: 0.010233723\n",
            "CPU times: user 7.44 ms, sys: 1 ms, total: 8.44 ms\n",
            "Wall time: 8.24 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btzsdyCTrW1D"
      },
      "source": [
        "## 4.3 Evaluation [1pt]\n",
        "\n",
        "Evaluate the speed and accuracy of the model with your ideas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBTz8zwRRLVQ"
      },
      "source": [
        "In **this** text box, briefly describe the results. Did your improvement work? Why / Why not?\n",
        "\n",
        "Approach 1 : \n",
        "\n",
        "Removing stopwords from the vocabulary lead to and inreasing number of epochs lead to a significant decrease in tesing loss 0.12817 -> 0.08266\n",
        "\n",
        "Training takes more time than before 131ms -> 1.06ms but this increase is very reasonable\n",
        "\n",
        "The improvement seen is because removal of stopwords improved the quality of training data in turn providing a better model which produced a better result because it trained more which let the model keep adjusting its parameters to gain better results\n",
        "\n",
        "\n",
        "Approch 2 : \n",
        "\n",
        "Changing to Fasttext model and increasing the learning rate led to a slight improvement in testing cost 0.08266 -> 0.069427\n",
        "\n",
        "There is a slight drop in the training time 1.06s -> 835ms\n",
        "\n",
        "This improvement has been done in addition to Approch 1.The slight improvement we see is because fast text uses n-gram to learn embeddings, a larger learning rate was required for this model to provide improved results because the training loss for the model was initially very large. Both contributed in the improvement of the model.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}